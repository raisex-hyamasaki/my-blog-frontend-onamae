<!DOCTYPE html><html><head><meta charSet="utf-8"/><link rel="icon" href="/favicon.ico"/><meta name="viewport" content="width=device-width, initial-scale=1"/><meta name="description" content="最新の技術トレンド、プログラミング、ソフトウェア開発、ツールのレビュー、プロジェクト管理等についての考察をお届け"/><meta property="og:url" content="https://blog.raisex.jp/articles/nyg7h5f0xw60bpk88glrh4zo"/><meta property="og:title" content="LLMファインチューニングのチュートリアル | レイズクロスTechBlog"/><meta property="og:description" content="最新の技術トレンド、プログラミング、ソフトウェア開発、ツールのレビュー、プロジェクト管理等についての考察をお届け"/><meta property="og:image" content="https://blog.raisex.jphttps://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_15_a017e8a63e.png"/><meta property="og:type" content="article"/><meta name="twitter:card" content="summary_large_image"/><title>LLMファインチューニングのチュートリアル<!-- --> | レイズクロス Tech Blog</title><meta name="next-head-count" content="11"/><link rel="preload" href="/_next/static/css/7d757bdfdfb985a7.css" as="style"/><link rel="stylesheet" href="/_next/static/css/7d757bdfdfb985a7.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-2c547fd4592db0a6.js" defer=""></script><script src="/_next/static/chunks/framework-e952fed463eb8e34.js" defer=""></script><script src="/_next/static/chunks/main-72cf801a60c05482.js" defer=""></script><script src="/_next/static/chunks/pages/_app-b6737859a806843a.js" defer=""></script><script src="/_next/static/chunks/a2bf56a3-f921f321ae1e0e8d.js" defer=""></script><script src="/_next/static/chunks/61-43a5fb199f2ef164.js" defer=""></script><script src="/_next/static/chunks/257-c12ad0b16790f4c5.js" defer=""></script><script src="/_next/static/chunks/pages/articles/%5Bid%5D-1f9ae5c384ab52dd.js" defer=""></script><script src="/_next/static/wdcbjCbp8DYGqTQVAi4UF/_buildManifest.js" defer=""></script><script src="/_next/static/wdcbjCbp8DYGqTQVAi4UF/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="max-w-[1024px] mx-auto px-4"><header class="sticky top-0 z-20 bg-white border-b border-gray-200 h-12 flex items-center justify-between px-4"><a class="text-blue-600 no-underline hover:text-gray-600 text-lg font-bold" href="/">📋 レイズクロス Tech Blog</a><div class="flex gap-3"><a href="https://twitter.com/share" target="_blank" rel="noopener noreferrer"><img src="/icons/x.svg" alt="Share on X" class="h-7 w-7"/></a><a href="https://www.facebook.com/sharer/sharer.php" target="_blank" rel="noopener noreferrer"><img src="/icons/facebook.svg" alt="Share on Facebook" class="h-7 w-7"/></a><a href="https://social-plugins.line.me/lineit/share" target="_blank" rel="noopener noreferrer"><img src="/icons/line.svg" alt="Share on LINE" class="h-7 w-7"/></a></div></header><article class="prose prose-slate max-w-none pt-6"><h1 class="text-3xl font-bold border-b pb-2">LLMファインチューニングのチュートリアル</h1><div class="text-sm text-gray-500 mb-4">投稿更新日: <!-- -->2025/6/6 8:56:30</div><div class="flex flex-wrap gap-2 mb-4"><span class="bg-blue-100 text-blue-800 text-xs font-semibold px-2 py-1 rounded-full">#<!-- -->LLM</span><span class="bg-blue-100 text-blue-800 text-xs font-semibold px-2 py-1 rounded-full">#<!-- -->Tutorial</span><span class="bg-blue-100 text-blue-800 text-xs font-semibold px-2 py-1 rounded-full">#<!-- -->生成AI</span></div><div class="w-full flex justify-center mb-6"><img src="https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_15_a017e8a63e.png" alt="サムネイル" class="w-full max-w-[800px] h-auto rounded"/></div><p>近年、自然言語処理（NLP）の分野では大規模言語モデル（LLM）の活用が急速に進んでいます。特に、特定のタスク向けにモデルの性能を向上させる「ファインチューニング」は、プロジェクトでの需要が増えつつあります。</p>
<p>本記事では、初心者の方でも理解しやすいように、ファインチューニングの基本的な流れを体験できるチュートリアルを用意しました。</p>
<hr/>
<h1>環境設定と事前準備</h1>
<p>このチュートリアルは、macOS環境（例: M2 MacBook Pro）をベースにしています。以下のコマンドで仮想環境を作成し、必要なライブラリをインストールしましょう。</p>
<h3>仮想環境のセットアップ</h3>
<pre><div class="relative my-4"><button class="absolute top-2 right-2 text-xs bg-gray-700 text-white px-2 py-1 rounded hover:bg-gray-600">Copy</button><pre style="background:transparent;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:break-word;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:0.75rem;margin:0;overflow:auto;border-radius:0.5rem;overflow-x:auto"><code class="language-bash" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>python -m venv .env
</span><span></span><span class="token" style="color:hsl(29, 54%, 61%)">source</span><span> .env/bin/activate</span></code></pre></div></pre>
<h3>必要なライブラリのインストール</h3>
<p>以下のコマンドを実行して、必要なPythonライブラリをインストールします。</p>
<pre><div class="relative my-4"><button class="absolute top-2 right-2 text-xs bg-gray-700 text-white px-2 py-1 rounded hover:bg-gray-600">Copy</button><pre style="background:transparent;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:break-word;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:0.75rem;margin:0;overflow:auto;border-radius:0.5rem;overflow-x:auto"><code class="language-bash" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>pip </span><span class="token" style="color:hsl(207, 82%, 66%)">install</span><span> transformers datasets evaluate accelerate scikit-learn torch
</span></code></pre></div></pre>
<h3>動作確認</h3>
<p>ライブラリが正しくインストールされたか確認するために、以下のテストコードを実行します。</p>
<pre><div class="relative my-4"><button class="absolute top-2 right-2 text-xs bg-gray-700 text-white px-2 py-1 rounded hover:bg-gray-600">Copy</button><pre style="background:transparent;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:break-word;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:0.75rem;margin:0;overflow:auto;border-radius:0.5rem;overflow-x:auto"><code class="language-bash" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>python -c </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;from transformers import pipeline; print(pipeline(&#x27;sentiment-analysis&#x27;)(&#x27;we love you&#x27;))&quot;</span><span>
</span></code></pre></div></pre>
<p>期待される出力：</p>
<pre><div class="relative my-4"><button class="absolute top-2 right-2 text-xs bg-gray-700 text-white px-2 py-1 rounded hover:bg-gray-600">Copy</button><pre style="background:transparent;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:break-word;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:0.75rem;margin:0;overflow:auto;border-radius:0.5rem;overflow-x:auto"><code class="language-bash" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;label&#x27;</span><span class="token" style="color:hsl(29, 54%, 61%)">:</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;POSITIVE&#x27;</span><span>, </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;score&#x27;</span><span class="token" style="color:hsl(29, 54%, 61%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.9998704195022583</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>
</span></code></pre></div></pre>
<hr/>
<h1>ファインチューニングスクリプトの作成と実行</h1>
<p>ファインチューニングの手順を示したPythonスクリプト（<code class="bg-yellow-200 font-mono px-[0.3rem] py-[0.1rem] rounded whitespace-nowrap text-inherit">finetune.py</code>）を以下に示します。このスクリプトでは、<a href="https://huggingface.co/datasets/Yelp/yelp_review_full" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline">Yelpレビューのデータセット</a>を使用します。</p>
<h3><code class="bg-yellow-200 font-mono px-[0.3rem] py-[0.1rem] rounded whitespace-nowrap text-inherit">finetune.py</code></h3>
<pre><div class="relative my-4"><button class="absolute top-2 right-2 text-xs bg-gray-700 text-white px-2 py-1 rounded hover:bg-gray-600">Copy</button><pre style="background:transparent;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:break-word;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:0.75rem;margin:0;overflow:auto;border-radius:0.5rem;overflow-x:auto"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> datasets </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> load_dataset
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> transformers </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> AutoTokenizer</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> AutoModelForSequenceClassification</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> TrainingArguments</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> Trainer
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> numpy </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> np
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> evaluate
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># データセットの準備</span><span>
</span><span>dataset </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> load_dataset</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;yelp_review_full&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># トークナイザーによるトークナイズ</span><span>
</span><span>tokenizer </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> AutoTokenizer</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>from_pretrained</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;google-bert/bert-base-cased&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">tokenize_function</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>examples</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> tokenizer</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>examples</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;text&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> padding</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;max_length&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> truncation</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>tokenized_datasets </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> dataset</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">map</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>tokenize_function</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> batched</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># 学習データとテストデータ作成</span><span>
</span><span>small_train_dataset </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> tokenized_datasets</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;train&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>shuffle</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>seed</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">42</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>select</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">range</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">500</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>small_eval_dataset </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> tokenized_datasets</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;test&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>shuffle</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>seed</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">42</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>select</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">range</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">500</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># モデルのロード</span><span>
</span><span>model </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> AutoModelForSequenceClassification</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>from_pretrained</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;google-bert/bert-base-cased&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> num_labels</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">5</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> torch_dtype</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;auto&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># 評価関数</span><span>
</span><span>metric </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> evaluate</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>load</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;accuracy&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">compute_metrics</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>eval_pred</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    logits</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> labels </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> eval_pred
</span><span>    predictions </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> np</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>argmax</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>logits</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> axis</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> metric</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>compute</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>predictions</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>predictions</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> references</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>labels</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># 学習設定</span><span>
</span><span>training_args </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> TrainingArguments</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>output_dir</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;test_trainer&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> eval_strategy</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;epoch&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>trainer </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> Trainer</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    args</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>training_args</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    train_dataset</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>small_train_dataset</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    eval_dataset</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>small_eval_dataset</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    compute_metrics</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>compute_metrics</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># 学習の実行</span><span>
</span><span>trainer</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>train</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># モデルとトークナイザーの保存</span><span>
</span><span>save_dir </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;./finetuned/bert-base-cased&#x27;</span><span>
</span><span>tokenizer</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>save_pretrained</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>save_dir</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>save_pretrained</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>save_dir</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3>実行結果</h3>
<p>スクリプトを実行すると、以下のような評価結果が表示されます。</p>
<pre><div class="relative my-4"><button class="absolute top-2 right-2 text-xs bg-gray-700 text-white px-2 py-1 rounded hover:bg-gray-600">Copy</button><pre style="background:transparent;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:break-word;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:0.75rem;margin:0;overflow:auto;border-radius:0.5rem;overflow-x:auto"><code class="language-bash" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>python3 finetune.py
</span>
<span></span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;eval_loss&#x27;</span><span class="token" style="color:hsl(29, 54%, 61%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1.5970934629440308</span><span>, </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;eval_accuracy&#x27;</span><span class="token" style="color:hsl(29, 54%, 61%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.242</span><span>, </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;eval_runtime&#x27;</span><span class="token" style="color:hsl(29, 54%, 61%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">39.0603</span><span>, </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;eval_samples_per_second&#x27;</span><span class="token" style="color:hsl(29, 54%, 61%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">12.801</span><span>, </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;eval_steps_per_second&#x27;</span><span class="token" style="color:hsl(29, 54%, 61%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1.613</span><span>, </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;epoch&#x27;</span><span class="token" style="color:hsl(29, 54%, 61%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1.0</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>                                                                               
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;eval_loss&#x27;</span><span class="token" style="color:hsl(29, 54%, 61%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1.468526840209961</span><span>, </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;eval_accuracy&#x27;</span><span class="token" style="color:hsl(29, 54%, 61%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.346</span><span>, </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;eval_runtime&#x27;</span><span class="token" style="color:hsl(29, 54%, 61%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">36.1194</span><span>, </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;eval_samples_per_second&#x27;</span><span class="token" style="color:hsl(29, 54%, 61%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">13.843</span><span>, </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;eval_steps_per_second&#x27;</span><span class="token" style="color:hsl(29, 54%, 61%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1.744</span><span>, </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;epoch&#x27;</span><span class="token" style="color:hsl(29, 54%, 61%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">2.0</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>                                                                                
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;eval_loss&#x27;</span><span class="token" style="color:hsl(29, 54%, 61%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1.4037985801696777</span><span>, </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;eval_accuracy&#x27;</span><span class="token" style="color:hsl(29, 54%, 61%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.368</span><span>, </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;eval_runtime&#x27;</span><span class="token" style="color:hsl(29, 54%, 61%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">35.7517</span><span>, </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;eval_samples_per_second&#x27;</span><span class="token" style="color:hsl(29, 54%, 61%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">13.985</span><span>, </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;eval_steps_per_second&#x27;</span><span class="token" style="color:hsl(29, 54%, 61%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1.762</span><span>, </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;epoch&#x27;</span><span class="token" style="color:hsl(29, 54%, 61%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">3.0</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>                                                                               
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">{</span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;train_runtime&#x27;</span><span class="token" style="color:hsl(29, 54%, 61%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">467.6126</span><span>, </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;train_samples_per_second&#x27;</span><span class="token" style="color:hsl(29, 54%, 61%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">3.208</span><span>, </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;train_steps_per_second&#x27;</span><span class="token" style="color:hsl(29, 54%, 61%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">0.404</span><span>, </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;train_loss&#x27;</span><span class="token" style="color:hsl(29, 54%, 61%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">1.5324497121982474</span><span>, </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;epoch&#x27;</span><span class="token" style="color:hsl(29, 54%, 61%)">:</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">3.0</span><span class="token" style="color:hsl(220, 14%, 71%)">}</span><span>                                                                                                   
</span><span></span><span class="token" style="color:hsl(29, 54%, 61%)">100</span><span>%</span><span class="token" style="color:hsl(207, 82%, 66%)">|</span><span>██████████████████████████████████████████████████████████████████████████████████</span><span class="token" style="color:hsl(207, 82%, 66%)">|</span><span> </span><span class="token" style="color:hsl(29, 54%, 61%)">189</span><span>/189 </span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span>07:4</span><span class="token file-descriptor" style="color:hsl(355, 65%, 65%)">7</span><span class="token" style="color:hsl(207, 82%, 66%)">&lt;</span><span>00:00,  </span><span class="token" style="color:hsl(29, 54%, 61%)">2</span><span>.47s/it</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span></code></pre></div></pre>
<hr/>
<h2>ファインチューニングスクリプトの解説</h2>
<p>以下は、ファインチューニングスクリプト <code class="bg-yellow-200 font-mono px-[0.3rem] py-[0.1rem] rounded whitespace-nowrap text-inherit">finetune.py</code> の各パートを詳しく解説しまとめたものです。</p>
<hr/>
<h3>1. データセットのロード</h3>
<pre><div class="relative my-4"><button class="absolute top-2 right-2 text-xs bg-gray-700 text-white px-2 py-1 rounded hover:bg-gray-600">Copy</button><pre style="background:transparent;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:break-word;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:0.75rem;margin:0;overflow:auto;border-radius:0.5rem;overflow-x:auto"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>dataset </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> load_dataset</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;yelp_review_full&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3>解説：</h3>
<ul>
<li>Hugging Faceの<code class="bg-yellow-200 font-mono px-[0.3rem] py-[0.1rem] rounded whitespace-nowrap text-inherit">datasets</code>ライブラリを使用して、Yelpのレビューコメントデータセットをロードします。このデータセットにはレビューコメントと1~5の評価スコアが含まれています。</li>
</ul>
<h3>ポイント：</h3>
<ul>
<li><strong>データセットの種類</strong>：Hugging Faceの<code class="bg-yellow-200 font-mono px-[0.3rem] py-[0.1rem] rounded whitespace-nowrap text-inherit">load_dataset</code>を使えば、豊富な事前構築データセットに簡単にアクセス可能。</li>
<li><strong>カスタムデータの利用</strong>：自分のデータを使いたい場合、CSVやJSON形式で読み込むことも可能です。</li>
</ul>
<hr/>
<h3>2. トークナイズ</h3>
<pre><div class="relative my-4"><button class="absolute top-2 right-2 text-xs bg-gray-700 text-white px-2 py-1 rounded hover:bg-gray-600">Copy</button><pre style="background:transparent;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:break-word;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:0.75rem;margin:0;overflow:auto;border-radius:0.5rem;overflow-x:auto"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>tokenizer </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> AutoTokenizer</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>from_pretrained</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;google-bert/bert-base-cased&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">tokenize_function</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>examples</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> tokenizer</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>examples</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;text&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> padding</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;max_length&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> truncation</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>tokenized_datasets </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> dataset</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span class="token" style="color:hsl(95, 38%, 62%)">map</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>tokenize_function</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> batched</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3>解説：</h3>
<ul>
<li>トークナイザーを使ってテキストを数値データに変換します。これにより、モデルが扱える形式に整えられます。</li>
<li><code class="bg-yellow-200 font-mono px-[0.3rem] py-[0.1rem] rounded whitespace-nowrap text-inherit">padding=&quot;max_length&quot;</code>で固定長の入力に揃え、<code class="bg-yellow-200 font-mono px-[0.3rem] py-[0.1rem] rounded whitespace-nowrap text-inherit">truncation=True</code>で最大トークン数を超えた部分をカットします。</li>
</ul>
<h3>ポイント：</h3>
<ul>
<li><strong>トークナイザーの選択</strong>：モデルに対応するトークナイザーを使用することが重要（例: BERTモデルならBERT用のトークナイザー）。</li>
<li><strong>効率化</strong>：<code class="bg-yellow-200 font-mono px-[0.3rem] py-[0.1rem] rounded whitespace-nowrap text-inherit">batched=True</code>を指定することで、複数のデータを一度にトークナイズして処理速度を向上。</li>
</ul>
<hr/>
<h3>3. データの分割と縮小</h3>
<pre><div class="relative my-4"><button class="absolute top-2 right-2 text-xs bg-gray-700 text-white px-2 py-1 rounded hover:bg-gray-600">Copy</button><pre style="background:transparent;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:break-word;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:0.75rem;margin:0;overflow:auto;border-radius:0.5rem;overflow-x:auto"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>small_train_dataset </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> tokenized_datasets</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;train&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>shuffle</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>seed</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">42</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>select</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">range</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">500</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>small_eval_dataset </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> tokenized_datasets</span><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;test&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>shuffle</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>seed</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">42</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>select</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">range</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(29, 54%, 61%)">500</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span></code></pre></div></pre>
<h3>解説：</h3>
<ul>
<li>訓練データと評価データを分割し、ファインチューニング用にサブセット（500件）を作成します。</li>
<li><code class="bg-yellow-200 font-mono px-[0.3rem] py-[0.1rem] rounded whitespace-nowrap text-inherit">shuffle(seed=42)</code>はデータをランダムに並び替えますが、同じ結果を再現するためシード値を設定しています。</li>
</ul>
<h3>ポイント：</h3>
<ul>
<li><strong>データサイズの調整</strong>：学習時間やリソースの制約に合わせてデータサイズを選択できます。</li>
<li><strong>小規模学習のメリット</strong>：小規模データでもモデルの動作確認や理解が可能。</li>
</ul>
<hr/>
<h3>4. モデルのロード</h3>
<pre><div class="relative my-4"><button class="absolute top-2 right-2 text-xs bg-gray-700 text-white px-2 py-1 rounded hover:bg-gray-600">Copy</button><pre style="background:transparent;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:break-word;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:0.75rem;margin:0;overflow:auto;border-radius:0.5rem;overflow-x:auto"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>model </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> AutoModelForSequenceClassification</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>from_pretrained</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;google-bert/bert-base-cased&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    num_labels</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">5</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    torch_dtype</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;auto&quot;</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3>解説：</h3>
<ul>
<li>Hugging Faceから事前学習済みのBERTモデルをロードし、分類タスク用に調整します。</li>
<li><code class="bg-yellow-200 font-mono px-[0.3rem] py-[0.1rem] rounded whitespace-nowrap text-inherit">num_labels=5</code>は分類クラスの数（Yelpの評価スコア1~5）を指定しています。</li>
</ul>
<h3>ポイント：</h3>
<ul>
<li><strong>事前学習モデルの再利用</strong>：大規模な事前学習済みモデルを活用することで、少ないデータでも良い結果が得られる。</li>
<li><strong>モデルのカスタマイズ</strong>：分類クラス数や出力層を調整して特定のタスクに適応。</li>
</ul>
<hr/>
<h3>5. 評価関数の設定</h3>
<pre><div class="relative my-4"><button class="absolute top-2 right-2 text-xs bg-gray-700 text-white px-2 py-1 rounded hover:bg-gray-600">Copy</button><pre style="background:transparent;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:break-word;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:0.75rem;margin:0;overflow:auto;border-radius:0.5rem;overflow-x:auto"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>metric </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> evaluate</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>load</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;accuracy&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">def</span><span> </span><span class="token" style="color:hsl(207, 82%, 66%)">compute_metrics</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>eval_pred</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">:</span><span>
</span><span>    logits</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> labels </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> eval_pred
</span><span>    predictions </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> np</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>argmax</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>logits</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> axis</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>    </span><span class="token" style="color:hsl(286, 60%, 67%)">return</span><span> metric</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>compute</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>predictions</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>predictions</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> references</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>labels</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3>解説：</h3>
<ul>
<li><code class="bg-yellow-200 font-mono px-[0.3rem] py-[0.1rem] rounded whitespace-nowrap text-inherit">evaluate</code>ライブラリを使用して、モデルの精度（accuracy）を評価する関数を定義しています。</li>
<li>推論結果（<code class="bg-yellow-200 font-mono px-[0.3rem] py-[0.1rem] rounded whitespace-nowrap text-inherit">logits</code>）を<code class="bg-yellow-200 font-mono px-[0.3rem] py-[0.1rem] rounded whitespace-nowrap text-inherit">argmax</code>で予測ラベルに変換し、実際のラベルと比較してスコアを計算します。</li>
</ul>
<h3>ポイント：</h3>
<ul>
<li><strong>評価指標の選択</strong>：分類タスクでは<code class="bg-yellow-200 font-mono px-[0.3rem] py-[0.1rem] rounded whitespace-nowrap text-inherit">accuracy</code>が一般的ですが、タスクに応じて<code class="bg-yellow-200 font-mono px-[0.3rem] py-[0.1rem] rounded whitespace-nowrap text-inherit">precision</code>や<code class="bg-yellow-200 font-mono px-[0.3rem] py-[0.1rem] rounded whitespace-nowrap text-inherit">recall</code>も検討すべきです。</li>
<li><strong>簡単な実装</strong>：<code class="bg-yellow-200 font-mono px-[0.3rem] py-[0.1rem] rounded whitespace-nowrap text-inherit">evaluate</code>ライブラリを使うと、一般的な評価指標を簡単に利用可能。</li>
</ul>
<hr/>
<h3>6. 学習設定</h3>
<pre><div class="relative my-4"><button class="absolute top-2 right-2 text-xs bg-gray-700 text-white px-2 py-1 rounded hover:bg-gray-600">Copy</button><pre style="background:transparent;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:break-word;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:0.75rem;margin:0;overflow:auto;border-radius:0.5rem;overflow-x:auto"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>training_args </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> TrainingArguments</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    output_dir</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;test_trainer&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    eval_strategy</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;epoch&quot;</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span>trainer </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> Trainer</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>
</span><span>    model</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    args</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>training_args</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    train_dataset</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>small_train_dataset</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    eval_dataset</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>small_eval_dataset</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span>    compute_metrics</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span>compute_metrics</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span>
</span><span></span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span></code></pre></div></pre>
<h3>解説：</h3>
<ul>
<li><code class="bg-yellow-200 font-mono px-[0.3rem] py-[0.1rem] rounded whitespace-nowrap text-inherit">TrainingArguments</code>で学習パラメータを指定します。ここでは、モデル保存先（<code class="bg-yellow-200 font-mono px-[0.3rem] py-[0.1rem] rounded whitespace-nowrap text-inherit">output_dir</code>）と評価タイミング（<code class="bg-yellow-200 font-mono px-[0.3rem] py-[0.1rem] rounded whitespace-nowrap text-inherit">eval_strategy=&quot;epoch&quot;</code>）を設定。</li>
<li><code class="bg-yellow-200 font-mono px-[0.3rem] py-[0.1rem] rounded whitespace-nowrap text-inherit">Trainer</code>クラスは、学習プロセスを簡略化するための高レベルAPIです。</li>
</ul>
<h3>ポイント：</h3>
<ul>
<li><strong>簡単な学習管理</strong>：<code class="bg-yellow-200 font-mono px-[0.3rem] py-[0.1rem] rounded whitespace-nowrap text-inherit">Trainer</code>を使うと、ループの作成や勾配計算の実装を気にする必要がありません。</li>
<li><strong>設定の柔軟性</strong>：学習率やバッチサイズなどの詳細設定も可能です。</li>
</ul>
<hr/>
<h3>7. モデルの保存</h3>
<pre><div class="relative my-4"><button class="absolute top-2 right-2 text-xs bg-gray-700 text-white px-2 py-1 rounded hover:bg-gray-600">Copy</button><pre style="background:transparent;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:break-word;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:0.75rem;margin:0;overflow:auto;border-radius:0.5rem;overflow-x:auto"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>tokenizer</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>save_pretrained</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;./finetuned/bert-base-cased&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>model</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>save_pretrained</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;./finetuned/bert-base-cased&#x27;</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span></code></pre></div></pre>
<h3>解説：</h3>
<ul>
<li>ファインチューニング後のトークナイザーとモデルを保存します。この保存済みモデルは、将来的に推論やさらなる調整に使用できます。</li>
</ul>
<h3>ポイント：</h3>
<ul>
<li><strong>再利用性の向上</strong>：モデルを保存しておくことで、他のプロジェクトやデプロイメントに活用可能。</li>
<li><strong>Hugging Face互換</strong>：保存形式はHugging Faceライブラリでの再利用に最適化されています。</li>
</ul>
<hr/>
<h2>チューニング前後のモデル性能比較</h2>
<p>ファインチューニングによる効果を確認するため、同じ入力データを使ってモデルの予測結果を比較します。</p>
<h3>チューニング前のモデルで推論</h3>
<p>以下のスクリプトで推論を行います。</p>
<pre><div class="relative my-4"><button class="absolute top-2 right-2 text-xs bg-gray-700 text-white px-2 py-1 rounded hover:bg-gray-600">Copy</button><pre style="background:transparent;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:break-word;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:0.75rem;margin:0;overflow:auto;border-radius:0.5rem;overflow-x:auto"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(286, 60%, 67%)">from</span><span> transformers </span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> AutoTokenizer</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> AutoModelForSequenceClassification
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">import</span><span> numpy </span><span class="token" style="color:hsl(286, 60%, 67%)">as</span><span> np
</span>
<span>model_path </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;google-bert/bert-base-cased&#x27;</span><span>
</span><span>tokenizer </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> AutoTokenizer</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>from_pretrained</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model_path</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>model </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> AutoModelForSequenceClassification</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>from_pretrained</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model_path</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span>text </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;I visit this bar at first time. Service is good. Making drinks and talking with Bartender is also good. I spend good 2 hours. I will come again next month.&quot;</span><span>
</span><span>inputs </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> tokenizer</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>text</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> return_tensors</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;pt&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> padding</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> truncation</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>outputs </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(207, 82%, 66%)">**</span><span>inputs</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>predicted_class </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> np</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>argmax</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>outputs</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>logits</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>detach</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>numpy</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> axis</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>predicted_class</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span></code></pre></div></pre>
<p>出力結果：</p>
<pre><div class="relative my-4"><button class="absolute top-2 right-2 text-xs bg-gray-700 text-white px-2 py-1 rounded hover:bg-gray-600">Copy</button><pre style="background:transparent;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:break-word;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:0.75rem;margin:0;overflow:auto;border-radius:0.5rem;overflow-x:auto"><code class="language-bash" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">0</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span> </span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># 配列なので0始まり。0は評価1。</span></code></pre></div></pre>
<p>inputのtextからは4か5の高評価を期待しますが、評価が「1」となりました。</p>
<h3>チューニング後のモデルで推論</h3>
<p>同じテキストを以下のスクリプトで推論します。</p>
<pre><div class="relative my-4"><button class="absolute top-2 right-2 text-xs bg-gray-700 text-white px-2 py-1 rounded hover:bg-gray-600">Copy</button><pre style="background:transparent;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:break-word;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:0.75rem;margin:0;overflow:auto;border-radius:0.5rem;overflow-x:auto"><code class="language-python" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>model_path </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&#x27;./finetuned/bert-base-cased&#x27;</span><span>
</span><span>tokenizer </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> AutoTokenizer</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>from_pretrained</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model_path</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>model </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> AutoModelForSequenceClassification</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>from_pretrained</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>model_path</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span>
<span>text </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> </span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;I visit this bar at first time. Service is good. Making drinks and talking with Bartender is also good. I spend good 2 hours. I will come again next month.&quot;</span><span>
</span><span>inputs </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> tokenizer</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>text</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> return_tensors</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(95, 38%, 62%)">&quot;pt&quot;</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> padding</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> truncation</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(29, 54%, 61%)">True</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>outputs </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> model</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(207, 82%, 66%)">**</span><span>inputs</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span>predicted_class </span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span> np</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>argmax</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>outputs</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>logits</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>detach</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">.</span><span>numpy</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span class="token" style="color:hsl(220, 14%, 71%)">,</span><span> axis</span><span class="token" style="color:hsl(207, 82%, 66%)">=</span><span class="token" style="color:hsl(207, 82%, 66%)">-</span><span class="token" style="color:hsl(29, 54%, 61%)">1</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span><span></span><span class="token" style="color:hsl(286, 60%, 67%)">print</span><span class="token" style="color:hsl(220, 14%, 71%)">(</span><span>predicted_class</span><span class="token" style="color:hsl(220, 14%, 71%)">)</span><span>
</span></code></pre></div></pre>
<p>出力結果：</p>
<pre><div class="relative my-4"><button class="absolute top-2 right-2 text-xs bg-gray-700 text-white px-2 py-1 rounded hover:bg-gray-600">Copy</button><pre style="background:transparent;color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre-wrap;word-spacing:normal;word-break:break-word;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:0.75rem;margin:0;overflow:auto;border-radius:0.5rem;overflow-x:auto"><code class="language-bash" style="white-space:pre;background:hsl(220, 13%, 18%);color:hsl(220, 14%, 71%);text-shadow:0 1px rgba(0, 0, 0, 0.3);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span class="token" style="color:hsl(220, 14%, 71%)">[</span><span class="token" style="color:hsl(29, 54%, 61%)">4</span><span class="token" style="color:hsl(220, 14%, 71%)">]</span><span>　</span><span class="token" style="color:hsl(220, 10%, 40%);font-style:italic"># 配列なので0始まり。4は評価5。</span></code></pre></div></pre>
<p>この結果は、より正確な評価となっており、モデルが改善されたことを示しています。</p>
<h2>まとめ</h2>
<p>このチュートリアルでは、<code class="bg-yellow-200 font-mono px-[0.3rem] py-[0.1rem] rounded whitespace-nowrap text-inherit">transformers</code>ライブラリを使用してLLMのファインチューニングを行い、わずか500件のデータでもモデルの性能が向上することを確認できました。</p>
<p>本記事で紹介した手順は、あくまで学習目的です。</p>
<p>本格的な案件では、より大規模なデータセットや高性能なハードウェアを利用することを推奨します。</p>
<h3>学びのポイント</h3>
<ol>
<li>LLMの基本操作とトークナイズの仕組みが理解できる。</li>
<li>Hugging Faceのエコシステムを活用する方法が習得できる。</li>
<li>簡単なファインチューニングによるモデルの改善効果を確認できる。</li>
</ol>
<p>今後のプロジェクトや個人学習にぜひ役立ててください。</p>
<hr/>
<h1>参考</h1>
<ul>
<li><a href="https://huggingface.co/docs/transformers/training" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline">https://huggingface.co/docs/transformers/training</a></li>
<li><a href="https://huggingface.co/docs/transformers/installation" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline">https://huggingface.co/docs/transformers/installation</a></li>
<li><a href="https://huggingface.co/datasets/Yelp/yelp_review_full" target="_blank" rel="noopener noreferrer" class="text-blue-600 underline">https://huggingface.co/datasets/Yelp/yelp_review_full</a></li>
</ul>
<hr/><div class="text-center mt-8"><a class="inline-block bg-gray-800 text-white no-underline px-4 py-2 rounded hover:bg-gray-700" href="/">← 記事一覧に戻る</a></div><div class="my-12 text-center"><p class="font-bold text-gray-800">合同会社raisexでは一緒に働く仲間を募集中です。</p><p class="text-sm text-gray-600 mb-4">ご興味のある方は以下の採用情報をご確認ください。</p><div class="flex justify-center"><div class="engage-recruit-widget" data-height="300" data-width="500" data-url="https://en-gage.net/raisex_jobs/widget/?banner=1"></div></div></div></article></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"article":{"id":263,"documentId":"nyg7h5f0xw60bpk88glrh4zo","title":"LLMファインチューニングのチュートリアル","content":"近年、自然言語処理（NLP）の分野では大規模言語モデル（LLM）の活用が急速に進んでいます。特に、特定のタスク向けにモデルの性能を向上させる「ファインチューニング」は、プロジェクトでの需要が増えつつあります。\n\n本記事では、初心者の方でも理解しやすいように、ファインチューニングの基本的な流れを体験できるチュートリアルを用意しました。\n\n---\n\n# 環境設定と事前準備\n\nこのチュートリアルは、macOS環境（例: M2 MacBook Pro）をベースにしています。以下のコマンドで仮想環境を作成し、必要なライブラリをインストールしましょう。\n\n### 仮想環境のセットアップ\n\n```bash\npython -m venv .env\nsource .env/bin/activate\n```\n\n### 必要なライブラリのインストール\n\n以下のコマンドを実行して、必要なPythonライブラリをインストールします。\n\n```bash\npip install transformers datasets evaluate accelerate scikit-learn torch\n\n```\n\n### 動作確認\n\nライブラリが正しくインストールされたか確認するために、以下のテストコードを実行します。\n\n```bash\npython -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))\"\n\n```\n\n期待される出力：\n\n```bash\n[{'label': 'POSITIVE', 'score': 0.9998704195022583}]\n\n```\n---\n\n# ファインチューニングスクリプトの作成と実行\n\nファインチューニングの手順を示したPythonスクリプト（`finetune.py`）を以下に示します。このスクリプトでは、[Yelpレビューのデータセット](https://huggingface.co/datasets/Yelp/yelp_review_full)を使用します。\n\n### `finetune.py`\n\n```python\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\nimport numpy as np\nimport evaluate\n\n# データセットの準備\ndataset = load_dataset(\"yelp_review_full\")\n\n# トークナイザーによるトークナイズ\ntokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\n\n# 学習データとテストデータ作成\nsmall_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(500))\nsmall_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(500))\n\n# モデルのロード\nmodel = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\", num_labels=5, torch_dtype=\"auto\")\n\n# 評価関数\nmetric = evaluate.load(\"accuracy\")\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)\n\n# 学習設定\ntraining_args = TrainingArguments(output_dir=\"test_trainer\", eval_strategy=\"epoch\")\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=small_train_dataset,\n    eval_dataset=small_eval_dataset,\n    compute_metrics=compute_metrics,\n)\n\n# 学習の実行\ntrainer.train()\n\n# モデルとトークナイザーの保存\nsave_dir = './finetuned/bert-base-cased'\ntokenizer.save_pretrained(save_dir)\nmodel.save_pretrained(save_dir)\n```\n\n### 実行結果\n\nスクリプトを実行すると、以下のような評価結果が表示されます。\n\n```bash\npython3 finetune.py\n\n{'eval_loss': 1.5970934629440308, 'eval_accuracy': 0.242, 'eval_runtime': 39.0603, 'eval_samples_per_second': 12.801, 'eval_steps_per_second': 1.613, 'epoch': 1.0}                                                                               \n{'eval_loss': 1.468526840209961, 'eval_accuracy': 0.346, 'eval_runtime': 36.1194, 'eval_samples_per_second': 13.843, 'eval_steps_per_second': 1.744, 'epoch': 2.0}                                                                                \n{'eval_loss': 1.4037985801696777, 'eval_accuracy': 0.368, 'eval_runtime': 35.7517, 'eval_samples_per_second': 13.985, 'eval_steps_per_second': 1.762, 'epoch': 3.0}                                                                               \n{'train_runtime': 467.6126, 'train_samples_per_second': 3.208, 'train_steps_per_second': 0.404, 'train_loss': 1.5324497121982474, 'epoch': 3.0}                                                                                                   \n100%|██████████████████████████████████████████████████████████████████████████████████| 189/189 [07:47\u003c00:00,  2.47s/it]\n```\n\n---\n\n## ファインチューニングスクリプトの解説\n\n以下は、ファインチューニングスクリプト `finetune.py` の各パートを詳しく解説しまとめたものです。\n\n---\n\n### 1. データセットのロード\n\n```python\ndataset = load_dataset(\"yelp_review_full\")\n```\n\n### 解説：\n\n- Hugging Faceの`datasets`ライブラリを使用して、Yelpのレビューコメントデータセットをロードします。このデータセットにはレビューコメントと1~5の評価スコアが含まれています。\n\n### ポイント：\n\n- **データセットの種類**：Hugging Faceの`load_dataset`を使えば、豊富な事前構築データセットに簡単にアクセス可能。\n- **カスタムデータの利用**：自分のデータを使いたい場合、CSVやJSON形式で読み込むことも可能です。\n\n---\n\n### 2. トークナイズ\n\n```python\ntokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\n```\n\n### 解説：\n\n- トークナイザーを使ってテキストを数値データに変換します。これにより、モデルが扱える形式に整えられます。\n- `padding=\"max_length\"`で固定長の入力に揃え、`truncation=True`で最大トークン数を超えた部分をカットします。\n\n### ポイント：\n\n- **トークナイザーの選択**：モデルに対応するトークナイザーを使用することが重要（例: BERTモデルならBERT用のトークナイザー）。\n- **効率化**：`batched=True`を指定することで、複数のデータを一度にトークナイズして処理速度を向上。\n\n---\n\n### 3. データの分割と縮小\n\n```python\nsmall_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(500))\nsmall_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(500))\n\n```\n\n### 解説：\n\n- 訓練データと評価データを分割し、ファインチューニング用にサブセット（500件）を作成します。\n- `shuffle(seed=42)`はデータをランダムに並び替えますが、同じ結果を再現するためシード値を設定しています。\n\n### ポイント：\n\n- **データサイズの調整**：学習時間やリソースの制約に合わせてデータサイズを選択できます。\n- **小規模学習のメリット**：小規模データでもモデルの動作確認や理解が可能。\n\n---\n\n### 4. モデルのロード\n\n```python\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"google-bert/bert-base-cased\",\n    num_labels=5,\n    torch_dtype=\"auto\"\n)\n```\n\n### 解説：\n\n- Hugging Faceから事前学習済みのBERTモデルをロードし、分類タスク用に調整します。\n- `num_labels=5`は分類クラスの数（Yelpの評価スコア1~5）を指定しています。\n\n### ポイント：\n\n- **事前学習モデルの再利用**：大規模な事前学習済みモデルを活用することで、少ないデータでも良い結果が得られる。\n- **モデルのカスタマイズ**：分類クラス数や出力層を調整して特定のタスクに適応。\n\n---\n\n### 5. 評価関数の設定\n\n```python\nmetric = evaluate.load(\"accuracy\")\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)\n```\n\n### 解説：\n\n- `evaluate`ライブラリを使用して、モデルの精度（accuracy）を評価する関数を定義しています。\n- 推論結果（`logits`）を`argmax`で予測ラベルに変換し、実際のラベルと比較してスコアを計算します。\n\n### ポイント：\n\n- **評価指標の選択**：分類タスクでは`accuracy`が一般的ですが、タスクに応じて`precision`や`recall`も検討すべきです。\n- **簡単な実装**：`evaluate`ライブラリを使うと、一般的な評価指標を簡単に利用可能。\n\n---\n\n### 6. 学習設定\n\n```python\ntraining_args = TrainingArguments(\n    output_dir=\"test_trainer\",\n    eval_strategy=\"epoch\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=small_train_dataset,\n    eval_dataset=small_eval_dataset,\n    compute_metrics=compute_metrics,\n)\n\n```\n\n### 解説：\n\n- `TrainingArguments`で学習パラメータを指定します。ここでは、モデル保存先（`output_dir`）と評価タイミング（`eval_strategy=\"epoch\"`）を設定。\n- `Trainer`クラスは、学習プロセスを簡略化するための高レベルAPIです。\n\n### ポイント：\n\n- **簡単な学習管理**：`Trainer`を使うと、ループの作成や勾配計算の実装を気にする必要がありません。\n- **設定の柔軟性**：学習率やバッチサイズなどの詳細設定も可能です。\n\n---\n\n### 7. モデルの保存\n\n```python\ntokenizer.save_pretrained('./finetuned/bert-base-cased')\nmodel.save_pretrained('./finetuned/bert-base-cased')\n```\n\n### 解説：\n\n- ファインチューニング後のトークナイザーとモデルを保存します。この保存済みモデルは、将来的に推論やさらなる調整に使用できます。\n\n### ポイント：\n\n- **再利用性の向上**：モデルを保存しておくことで、他のプロジェクトやデプロイメントに活用可能。\n- **Hugging Face互換**：保存形式はHugging Faceライブラリでの再利用に最適化されています。\n\n---\n\n## チューニング前後のモデル性能比較\n\nファインチューニングによる効果を確認するため、同じ入力データを使ってモデルの予測結果を比較します。\n\n### チューニング前のモデルで推論\n\n以下のスクリプトで推論を行います。\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport numpy as np\n\nmodel_path = 'google-bert/bert-base-cased'\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path)\n\ntext = \"I visit this bar at first time. Service is good. Making drinks and talking with Bartender is also good. I spend good 2 hours. I will come again next month.\"\ninputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\noutputs = model(**inputs)\npredicted_class = np.argmax(outputs.logits.detach().numpy(), axis=-1)\nprint(predicted_class)\n\n```\n\n出力結果：\n\n```bash\n[0] # 配列なので0始まり。0は評価1。\n```\n\ninputのtextからは4か5の高評価を期待しますが、評価が「1」となりました。\n\n### チューニング後のモデルで推論\n\n同じテキストを以下のスクリプトで推論します。\n\n```python\nmodel_path = './finetuned/bert-base-cased'\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path)\n\ntext = \"I visit this bar at first time. Service is good. Making drinks and talking with Bartender is also good. I spend good 2 hours. I will come again next month.\"\ninputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\noutputs = model(**inputs)\npredicted_class = np.argmax(outputs.logits.detach().numpy(), axis=-1)\nprint(predicted_class)\n\n```\n\n出力結果：\n\n```bash\n[4]　# 配列なので0始まり。4は評価5。\n```\n\nこの結果は、より正確な評価となっており、モデルが改善されたことを示しています。\n\n## まとめ\n\nこのチュートリアルでは、`transformers`ライブラリを使用してLLMのファインチューニングを行い、わずか500件のデータでもモデルの性能が向上することを確認できました。\n\n本記事で紹介した手順は、あくまで学習目的です。\n\n本格的な案件では、より大規模なデータセットや高性能なハードウェアを利用することを推奨します。\n\n### 学びのポイント\n\n1. LLMの基本操作とトークナイズの仕組みが理解できる。\n2. Hugging Faceのエコシステムを活用する方法が習得できる。\n3. 簡単なファインチューニングによるモデルの改善効果を確認できる。\n\n今後のプロジェクトや個人学習にぜひ役立ててください。\n\n---\n\n# 参考\n\n- https://huggingface.co/docs/transformers/training\n- https://huggingface.co/docs/transformers/installation\n- https://huggingface.co/datasets/Yelp/yelp_review_full\n\n---\n\n","createdAt":"2025-05-19T08:50:57.925Z","updatedAt":"2025-06-05T23:56:30.135Z","publishedAt":"2025-06-05T23:56:30.144Z","docId":"y98x06tmbaz9hb7fleb7jpiq","tags":[{"id":20,"documentId":"fbllyhmskvu2l7wbg5dzpkri","createdAt":"2025-05-19T09:48:50.341Z","updatedAt":"2025-05-19T09:48:50.341Z","publishedAt":"2025-05-19T09:48:50.348Z","name":"LLM"},{"id":4,"documentId":"zc573y83cxbfql2umdwbhot9","createdAt":"2025-05-19T09:44:33.028Z","updatedAt":"2025-05-19T09:44:33.028Z","publishedAt":"2025-05-19T09:44:33.035Z","name":"Tutorial"},{"id":30,"documentId":"d99cu6c3t9hgwynppb92lhph","createdAt":"2025-05-19T09:50:59.080Z","updatedAt":"2025-05-19T09:50:59.080Z","publishedAt":"2025-05-19T09:50:59.086Z","name":"生成AI"}],"thumbnail":[{"id":19,"documentId":"qqgjmycd7ycoo6gwkv2zp97w","name":"20250513-15.png","alternativeText":null,"caption":null,"width":1504,"height":844,"formats":{"thumbnail":{"name":"thumbnail_20250513-15.png","hash":"thumbnail_20250513_15_a017e8a63e","ext":".png","mime":"image/png","path":null,"width":245,"height":137,"size":10.45,"sizeInBytes":10451,"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/thumbnail_20250513_15_a017e8a63e.png"},"large":{"name":"large_20250513-15.png","hash":"large_20250513_15_a017e8a63e","ext":".png","mime":"image/png","path":null,"width":1000,"height":561,"size":53.11,"sizeInBytes":53109,"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/large_20250513_15_a017e8a63e.png"},"medium":{"name":"medium_20250513-15.png","hash":"medium_20250513_15_a017e8a63e","ext":".png","mime":"image/png","path":null,"width":750,"height":421,"size":38.07,"sizeInBytes":38070,"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_15_a017e8a63e.png"},"small":{"name":"small_20250513-15.png","hash":"small_20250513_15_a017e8a63e","ext":".png","mime":"image/png","path":null,"width":500,"height":281,"size":23.51,"sizeInBytes":23510,"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/small_20250513_15_a017e8a63e.png"}},"hash":"20250513_15_a017e8a63e","ext":".png","mime":"image/png","size":16.18,"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/20250513_15_a017e8a63e.png","previewUrl":null,"provider":"@strapi/provider-upload-aws-s3","provider_metadata":null,"createdAt":"2025-05-20T07:47:33.931Z","updatedAt":"2025-05-20T07:47:33.931Z","publishedAt":"2025-05-20T07:47:33.931Z"}]}},"__N_SSG":true},"page":"/articles/[id]","query":{"id":"nyg7h5f0xw60bpk88glrh4zo"},"buildId":"wdcbjCbp8DYGqTQVAi4UF","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>