<!DOCTYPE html><html><head><meta charSet="utf-8"/><link rel="icon" href="/favicon.ico"/><meta name="viewport" content="width=device-width, initial-scale=1"/><title>レイズクロス Tech Blog</title><link rel="preload" href="/hero.jpg" as="image" fetchpriority="high"/><meta name="next-head-count" content="5"/><link rel="preload" href="/_next/static/css/7d757bdfdfb985a7.css" as="style"/><link rel="stylesheet" href="/_next/static/css/7d757bdfdfb985a7.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-2c547fd4592db0a6.js" defer=""></script><script src="/_next/static/chunks/framework-e952fed463eb8e34.js" defer=""></script><script src="/_next/static/chunks/main-db60732262e3da6e.js" defer=""></script><script src="/_next/static/chunks/pages/_app-b6737859a806843a.js" defer=""></script><script src="/_next/static/chunks/61-92d26e53a2a7fcf5.js" defer=""></script><script src="/_next/static/chunks/pages/index-6c2736dbd1e44fe0.js" defer=""></script><script src="/_next/static/QTcQf_D8J2NMGF1e92-0w/_buildManifest.js" defer=""></script><script src="/_next/static/QTcQf_D8J2NMGF1e92-0w/_ssgManifest.js" defer=""></script></head><body><div id="__next"><main class="max-w-6xl mx-auto p-4 sm:p-8"><div class="mb-10"><img alt="Raisex Hero Banner" fetchpriority="high" width="1200" height="300" decoding="async" data-nimg="1" class="w-full h-64 object-cover rounded-xl shadow" style="color:transparent" src="/hero.jpg"/></div><div class="flex flex-wrap sm:flex-nowrap justify-between items-center mb-6 gap-4"><h1 class="text-3xl font-bold whitespace-nowrap">📝 レイズクロス Tech Blog</h1><input type="text" placeholder="記事検索" class="flex-grow sm:flex-grow-0 w-full sm:w-60 px-3 py-2 border rounded shadow-sm text-sm" value=""/><div class="flex"><button class="px-3 py-1 text-sm rounded-l border bg-blue-500 text-white">カード</button><button class="px-3 py-1 text-sm rounded-r border bg-gray-100 text-gray-700">リスト</button></div></div><div class="grid gap-6 sm:grid-cols-2 lg:grid-cols-3"><a class="block border rounded-lg overflow-hidden shadow-sm hover:shadow-md transition bg-white" href="/articles/spf6moyz3lontm4exno4s7of"><div class="w-full h-40 relative"><img alt="20250605記事タイトル" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250521_01_af2c532f73.png"/></div><div class="p-4"><h2 class="text-lg font-semibold text-blue-600 mb-2">20250605記事タイトル</h2><p class="text-sm text-gray-500">投稿更新日: <!-- -->2025/6/5 11:02:33</p><div class="flex flex-wrap gap-1 mt-2"><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">AWS</span></div></div></a><a class="block border rounded-lg overflow-hidden shadow-sm hover:shadow-md transition bg-white" href="/articles/bi16j40ybarpkxvrrf84ll5b"><div class="w-full h-40 relative"><img alt="【データモデリング】物理テーブル設計のチュートリアル" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_26_9537569757.png"/></div><div class="p-4"><h2 class="text-lg font-semibold text-blue-600 mb-2">【データモデリング】物理テーブル設計のチュートリアル</h2><p class="text-sm text-gray-500">投稿更新日: <!-- -->2025/6/5 10:46:34</p><div class="flex flex-wrap gap-1 mt-2"><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">Database</span><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">Tutorial</span><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">設計</span></div></div></a><a class="block border rounded-lg overflow-hidden shadow-sm hover:shadow-md transition bg-white" href="/articles/r7kw0wbuvv697hh5u5cbvsw3"><div class="w-full h-40 relative"><img alt="【データモデリング】論理テーブル設計のチュートリアル" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_25_68f5cc6f84.png"/></div><div class="p-4"><h2 class="text-lg font-semibold text-blue-600 mb-2">【データモデリング】論理テーブル設計のチュートリアル</h2><p class="text-sm text-gray-500">投稿更新日: <!-- -->2025/6/2 14:32:11</p><div class="flex flex-wrap gap-1 mt-2"><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">Database</span><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">Tutorial</span></div></div></a><a class="block border rounded-lg overflow-hidden shadow-sm hover:shadow-md transition bg-white" href="/articles/n0q7w0c5cubhhhsfmv7g75fd"><div class="w-full h-40 relative"><img alt="【データモデリング】 概念設計のチュートリアル" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_24_770ed9dea0.png"/></div><div class="p-4"><h2 class="text-lg font-semibold text-blue-600 mb-2">【データモデリング】 概念設計のチュートリアル</h2><p class="text-sm text-gray-500">投稿更新日: <!-- -->2025/6/2 14:31:55</p><div class="flex flex-wrap gap-1 mt-2"><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">Database</span><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">Tutorial</span></div></div></a><a class="block border rounded-lg overflow-hidden shadow-sm hover:shadow-md transition bg-white" href="/articles/s5f5pb3iniim1r09n51w4m3y"><div class="w-full h-40 relative"><img alt="Docker超入門 初心者でもすぐに使える基礎ガイド" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_22_6c94d9b413.png"/></div><div class="p-4"><h2 class="text-lg font-semibold text-blue-600 mb-2">Docker超入門 初心者でもすぐに使える基礎ガイド</h2><p class="text-sm text-gray-500">投稿更新日: <!-- -->2025/6/2 14:29:48</p><div class="flex flex-wrap gap-1 mt-2"><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">Docker</span></div></div></a><a class="block border rounded-lg overflow-hidden shadow-sm hover:shadow-md transition bg-white" href="/articles/y39dt5uhrmpjlphirb3u5vhb"><div class="w-full h-40 relative"><img alt="Docker Compose超入門 初心者でもすぐに使える基礎ガイド" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_23_99f792de40.png"/></div><div class="p-4"><h2 class="text-lg font-semibold text-blue-600 mb-2">Docker Compose超入門 初心者でもすぐに使える基礎ガイド</h2><p class="text-sm text-gray-500">投稿更新日: <!-- -->2025/6/2 14:24:02</p><div class="flex flex-wrap gap-1 mt-2"><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">Docker</span></div></div></a><a class="block border rounded-lg overflow-hidden shadow-sm hover:shadow-md transition bg-white" href="/articles/kgkva26cgncrrm565n6fbf3g"><div class="w-full h-40 relative"><img alt="Dockerで簡単構築！Ollamaを使ってLLMを試そう" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_21_37f2d57d1a.png"/></div><div class="p-4"><h2 class="text-lg font-semibold text-blue-600 mb-2">Dockerで簡単構築！Ollamaを使ってLLMを試そう</h2><p class="text-sm text-gray-500">投稿更新日: <!-- -->2025/6/2 14:22:30</p><div class="flex flex-wrap gap-1 mt-2"><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">LLM</span><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">Python</span><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">生成AI</span></div></div></a><a class="block border rounded-lg overflow-hidden shadow-sm hover:shadow-md transition bg-white" href="/articles/oy8vkgnlt756zh041qbas6zt"><div class="w-full h-40 relative"><img alt="テキストのトークン数を確認する方法：LLMチューニングの基礎知識" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_20_67274fed95.png"/></div><div class="p-4"><h2 class="text-lg font-semibold text-blue-600 mb-2">テキストのトークン数を確認する方法：LLMチューニングの基礎知識</h2><p class="text-sm text-gray-500">投稿更新日: <!-- -->2025/6/2 14:19:10</p><div class="flex flex-wrap gap-1 mt-2"><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">LLM</span><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">Python</span></div></div></a><a class="block border rounded-lg overflow-hidden shadow-sm hover:shadow-md transition bg-white" href="/articles/zpf2m4dks36ri1sxzpkhq91u"><div class="w-full h-40 relative"><img alt="【PDF操作比較】PyMuPDFでPDFからテキストも表も簡単抽出" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_19_a28071974b.png"/></div><div class="p-4"><h2 class="text-lg font-semibold text-blue-600 mb-2">【PDF操作比較】PyMuPDFでPDFからテキストも表も簡単抽出</h2><p class="text-sm text-gray-500">投稿更新日: <!-- -->2025/6/2 11:49:26</p><div class="flex flex-wrap gap-1 mt-2"><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">LLM</span><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">Python</span><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">RAG</span></div></div></a><a class="block border rounded-lg overflow-hidden shadow-sm hover:shadow-md transition bg-white" href="/articles/g8z0fn5ap0si8r1iheg2iwd7"><div class="w-full h-40 relative"><img alt="【PDF操作比較】pdfplumberでPDFからテキストも表も簡単抽出" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_18_7f8d875b8b.png"/></div><div class="p-4"><h2 class="text-lg font-semibold text-blue-600 mb-2">【PDF操作比較】pdfplumberでPDFからテキストも表も簡単抽出</h2><p class="text-sm text-gray-500">投稿更新日: <!-- -->2025/6/2 9:22:22</p><div class="flex flex-wrap gap-1 mt-2"><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">LLM</span><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">Python</span><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">RAG</span><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">生成AI</span></div></div></a><a class="block border rounded-lg overflow-hidden shadow-sm hover:shadow-md transition bg-white" href="/articles/i402h46inwv9yzy1mgah101z"><div class="w-full h-40 relative"><img alt="【PDF操作比較】pypdfでPDFからテキスト抽出を行う方法" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_17_1910dde1ca.png"/></div><div class="p-4"><h2 class="text-lg font-semibold text-blue-600 mb-2">【PDF操作比較】pypdfでPDFからテキスト抽出を行う方法</h2><p class="text-sm text-gray-500">投稿更新日: <!-- -->2025/6/2 9:20:03</p><div class="flex flex-wrap gap-1 mt-2"><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">LLM</span><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">Python</span><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">RAG</span></div></div></a><a class="block border rounded-lg overflow-hidden shadow-sm hover:shadow-md transition bg-white" href="/articles/n0263l12z36kcio7a5x2djsg"><div class="w-full h-40 relative"><img alt="【Ollama】ローカルでLLMを動かしてみよう！" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_16_ac3c5b1da2.png"/></div><div class="p-4"><h2 class="text-lg font-semibold text-blue-600 mb-2">【Ollama】ローカルでLLMを動かしてみよう！</h2><p class="text-sm text-gray-500">投稿更新日: <!-- -->2025/6/2 9:02:35</p><div class="flex flex-wrap gap-1 mt-2"><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">LLM</span></div></div></a><a class="block border rounded-lg overflow-hidden shadow-sm hover:shadow-md transition bg-white" href="/articles/nyg7h5f0xw60bpk88glrh4zo"><div class="w-full h-40 relative"><img alt="LLMファインチューニングのチュートリアル" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_15_a017e8a63e.png"/></div><div class="p-4"><h2 class="text-lg font-semibold text-blue-600 mb-2">LLMファインチューニングのチュートリアル</h2><p class="text-sm text-gray-500">投稿更新日: <!-- -->2025/6/2 9:00:52</p><div class="flex flex-wrap gap-1 mt-2"><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">LLM</span><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">Tutorial</span><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">生成AI</span></div></div></a><a class="block border rounded-lg overflow-hidden shadow-sm hover:shadow-md transition bg-white" href="/articles/yz9v0rgurkrgg57550p3h9ja"><div class="w-full h-40 relative"><img alt="Flowiseで始める簡単RAGチャットボット" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_14_01a75fca34.png"/></div><div class="p-4"><h2 class="text-lg font-semibold text-blue-600 mb-2">Flowiseで始める簡単RAGチャットボット</h2><p class="text-sm text-gray-500">投稿更新日: <!-- -->2025/6/2 8:59:05</p><div class="flex flex-wrap gap-1 mt-2"><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">生成AI</span></div></div></a><a class="block border rounded-lg overflow-hidden shadow-sm hover:shadow-md transition bg-white" href="/articles/w35l3o70015xpn6gwr8mgdov"><div class="w-full h-40 relative"><img alt="Flowiseを使ってAIエージェントを作ろう！" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent" src="https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_13_9c6f3f0fd3.png"/></div><div class="p-4"><h2 class="text-lg font-semibold text-blue-600 mb-2">Flowiseを使ってAIエージェントを作ろう！</h2><p class="text-sm text-gray-500">投稿更新日: <!-- -->2025/6/2 8:57:01</p><div class="flex flex-wrap gap-1 mt-2"><span class="bg-blue-100 text-blue-800 text-xs font-medium px-2 py-1 rounded">生成AI</span></div></div></a></div><div class="flex justify-center items-center mt-10 gap-4"><button class="px-3 py-1 border rounded disabled:opacity-50" disabled="">← 前へ</button><span class="text-sm text-gray-700">1<!-- --> / <!-- -->2</span><button class="px-3 py-1 border rounded disabled:opacity-50">次へ →</button></div><footer class="text-center text-gray-400 text-sm mt-12">© 2024 raisex, LLC. All rights reserved.</footer></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"articles":[{"id":228,"documentId":"spf6moyz3lontm4exno4s7of","title":"20250605記事タイトル","content":"20250605記事内容12","updatedAt":"2025-06-05T02:02:33.495Z","tags":[{"id":10,"documentId":"cxt2tbnsy05cazm17p3pp1a3","createdAt":"2025-05-19T09:46:58.860Z","updatedAt":"2025-05-19T09:46:58.860Z","publishedAt":"2025-05-19T09:46:58.868Z","name":"AWS"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250521_01_af2c532f73.png"}},{"id":223,"documentId":"bi16j40ybarpkxvrrf84ll5b","title":"【データモデリング】物理テーブル設計のチュートリアル","content":"データモデリングにおいて、論理テーブル設計が完了したら、次のステップとして物理テーブル設計を行います。本記事では、ECサイトを題材にして、MySQL を使用した物理テーブル設計の手順を詳しく解説します。\n\n## 1. シナリオの確認\n\nECサイトにおける主要な機能を整理します。\n\n- **商品一覧の表示**\n- **カートへの追加・削除**\n- **注文処理**\n- **決済処理**\n\nこの機能をもとに、エンティティ抽出とER図を作成し、論理テーブル設計を行いました。これを基に物理テーブル設計を進めます。\n\n## 2. 物理テーブル設計の考慮点\n\n物理テーブル設計では、以下の観点を考慮して実装を進めます。\n\n### 2.1 DB 製品特性・インフラ要件\n\n- **データベースの種類**\n    - MySQL, PostgreSQL, Oracle, SQL Server など、製品ごとに特性や制限が異なる。\n    - 本記事では MySQL を前提とする。\n- **インフラ環境の違い**\n    - オンプレミスかクラウド（AWS RDS, GCP Cloud SQL など）かで運用が異なる。\n    - クラウド環境では、自動バックアップやスケーリング機能を考慮。\n\n### 2.2 具体的なデータ型マッピング（MySQL）\n\n| 論理データ型 | MySQL データ型 | 説明 |\n| --- | --- | --- |\n| VARCHAR | VARCHAR(n) | 文字列（可変長） |\n| INTEGER | INT | 整数 |\n| DECIMAL | DECIMAL(p,s) | 小数点を含む数値 |\n| DATE | DATE | 日付 |\n| DATETIME | DATETIME | 日時 |\n| BOOLEAN | TINYINT(1) | 真偽値（MySQL では TINYINT を使用） |\n\n### 2.3 インデックス設計\n\n- **主キー（Primary Key, PK）**: `AUTO_INCREMENT` を設定して一意性を担保。\n- **外部キー（Foreign Key, FK）**: `ON DELETE CASCADE` などの制約を検討。\n- **検索性能向上のためのインデックス**\n    - よく検索されるカラムに `INDEX` を設定。\n    - `ORDER BY` でよく使用されるカラムには `BTREE` インデックスを検討。\n    - 複数の検索条件を考慮して `複合インデックス` を適用。\n\n### 2.4 パーティショニング / シャーディング\n\n- **パーティショニング**: 大量のデータを保持するテーブルは `RANGE PARTITION` や `LIST PARTITION` を適用。\n- **シャーディング**: ユーザー数が多い場合、`user_id` を基準に水平分割を検討。\n\n### 2.5 可用性・セキュリティ・運用設計\n\n- **レプリケーション / クラスタリング**\n    - MySQL の `Master-Slave` レプリケーションを設定し、読み込み負荷を分散。\n- **ユーザ権限**\n    - `GRANT SELECT, INSERT, UPDATE ON database.* TO 'app_user'@'%' IDENTIFIED BY 'password';`\n- **バックアップ / 監査ログ**\n    - `mysqldump` による定期バックアップ。\n    - `binlog` を有効化し、データ変更履歴を保持。\n\n## 3. 物理テーブル定義の例\n\n### 3.1 User（ユーザー）\n\n| カラム名 | データ型 | 制約 | 説明 |\n| --- | --- | --- | --- |\n| user_id | INT | PK, AUTO_INCREMENT | ユーザーの一意識別子 |\n| username | VARCHAR(255) | NOT NULL | ユーザー名 |\n| email | VARCHAR(255) | UNIQUE, NOT NULL | メールアドレス（ナチュラルキー） |\n| password | VARCHAR(255) | NOT NULL | パスワード |\n| created_at | DATETIME | DEFAULT CURRENT_TIMESTAMP | 作成日時 |\n\n### 3.2 Product（商品）\n\n| カラム名 | データ型 | 制約 | 説明 |\n| --- | --- | --- | --- |\n| product_id | INT | PK, AUTO_INCREMENT | 商品の一意識別子 |\n| product_code | VARCHAR(100) | UNIQUE, NOT NULL | 商品コード（ナチュラルキー） |\n| name | VARCHAR(255) | INDEX, NOT NULL | 商品名 |\n| price | DECIMAL(10,2) | NOT NULL | 価格 |\n| stock | INT | NOT NULL | 在庫数 |\n| created_at | DATETIME | DEFAULT CURRENT_TIMESTAMP | 作成日時 |\n\n### 3.3 Cart（カート）\n\n| カラム名 | データ型 | 制約 | 説明 |\n| --- | --- | --- | --- |\n| cart_id | INT | PK, AUTO_INCREMENT | カートの一意識別子 |\n| user_id | INT | FK (User), NOT NULL | カート所有者 |\n| created_at | DATETIME | DEFAULT CURRENT_TIMESTAMP | カート作成日時 |\n\n### 3.4 CartItem（カート内商品）\n\n| カラム名 | データ型 | 制約 | 説明 |\n| --- | --- | --- | --- |\n| cart_id | INT | PK, FK (Cart) | カートの識別子 |\n| product_id | INT | PK, FK (Product) | カート内の商品 |\n| quantity | INT | NOT NULL | 商品の個数 |\n\n### 3.5 Order（注文）\n\n| カラム名 | データ型 | 制約 | 説明 |\n| --- | --- | --- | --- |\n| order_id | INT | PK, AUTO_INCREMENT | 注文の一意識別子 |\n| user_id | INT | FK (User) | 注文したユーザー |\n| total_price | DECIMAL(10,2) | NOT NULL | 合計金額 |\n| status | VARCHAR(50) | NOT NULL | 注文ステータス（例: 確定, 発送済み） |\n| order_date | DATETIME | DEFAULT CURRENT_TIMESTAMP | 注文日時 |\n\n### 3.6 OrderItem（注文内商品）\n\n| カラム名 | データ型 | 制約 | 説明 |\n| --- | --- | --- | --- |\n| order_id | INT | PK, FK (Order) | 注文の識別子 |\n| product_id | INT | PK, FK (Product) | 注文内の商品 |\n| quantity | INT | NOT NULL | 商品の個数 |\n\n### 3.7 Payment（決済）\n\n| カラム名 | データ型 | 制約 | 説明 |\n| --- | --- | --- | --- |\n| payment_id | INT | PK, AUTO_INCREMENT | 決済の一意識別子 |\n| order_id | INT | FK (Order) | 関連する注文 |\n| method | VARCHAR(50) | NOT NULL | 決済方法（クレジットカード, 銀行振込など） |\n| status | VARCHAR(50) | NOT NULL | 決済ステータス（成功, 失敗など） |\n| payment_date | DATETIME | DEFAULT CURRENT_TIMESTAMP | 決済日時 |\n\n※パーティショニング / シャーディング、可用性・セキュリティ・運用設計についてはこのチュートリアルでは設計しない。\n\n## 4. まとめ\n\n本記事では、ECサイトを題材に MySQL を使用した物理テーブル設計を行いました。\n\n1. **データベース製品特性とインフラ要件を考慮**\n2. **論理データ型を MySQL の物理データ型へマッピング**\n3. **インデックス設計、パーティショニング、シャーディングの適用**\n4. **可用性・セキュリティ・運用設計を考慮**\n5. **実際の物理テーブル設計の例を表形式で記述**\n\nこの設計をもとに、最適なクエリ設計やパフォーマンスチューニングを検討し、運用しやすいデータベースを構築しましょう！\n\n---\n\n","updatedAt":"2025-06-05T01:46:34.318Z","tags":[{"id":6,"documentId":"bnetm5oe2jokv3u2ib1nibia","createdAt":"2025-05-19T09:45:00.761Z","updatedAt":"2025-05-19T09:45:00.761Z","publishedAt":"2025-05-19T09:45:00.769Z","name":"Database"},{"id":4,"documentId":"zc573y83cxbfql2umdwbhot9","createdAt":"2025-05-19T09:44:33.028Z","updatedAt":"2025-05-19T09:44:33.028Z","publishedAt":"2025-05-19T09:44:33.035Z","name":"Tutorial"},{"id":8,"documentId":"zj5hi5t7civny0jcsejcwiwu","createdAt":"2025-05-19T09:46:29.591Z","updatedAt":"2025-05-19T09:46:29.591Z","publishedAt":"2025-05-19T09:46:29.613Z","name":"設計"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_26_9537569757.png"}},{"id":217,"documentId":"r7kw0wbuvv697hh5u5cbvsw3","title":"【データモデリング】論理テーブル設計のチュートリアル","content":"データモデリングにおいて、エンティティ抽出とER図の作成が完了したら、次のステップとして論理テーブル設計を行います。本記事では、ECサイトを題材にして論理テーブル設計の手順を詳しく解説します。\n\n## 1. シナリオの確認\n\nECサイトにおける主要な機能を整理します。\n\n- **商品一覧の表示**\n- **カートへの追加・削除**\n- **注文処理**\n- **決済処理**\n\nこの機能をもとに、エンティティ抽出とER図を作成しました。これを基に論理テーブル設計を進めます。\n\n## 2. 論理テーブル設計の手順\n\n### 2.1 テーブル定義（エンティティ → テーブル化）\n\nエンティティをそのままテーブルとして定義し、データの構造を明確にします。多対多の関係がある場合は、中間テーブルを作成します。\n\n### 2.2 主キー・外部キー・制約の設定\n\n- **主キー（Primary Key, PK）**\n    - サロゲートキー（自動採番IDなど）またはナチュラルキー（業務上意味を持つID）を選択\n- **外部キー（Foreign Key, FK）**\n    - リレーションの参照整合性を担保\n- **制約（Constraints）**\n    - `UNIQUE`, `CHECK`, `NOT NULL` などの制約を適用\n\n### 2.3 正規化の徹底と非正規化判断\n\n- 基本は **第3正規形**（3NF）を適用\n- **性能要件** に応じて部分的に非正規化\n- **正規化のステップ**\n    - **第1正規形（1NF）**: 繰り返し要素を排除し、各列に単一値のみを格納\n    - **第2正規形（2NF）**: 1NFを満たし、部分関数従属を排除（主キーに完全依存する）\n    - **第3正規形（3NF）**: 2NFを満たし、推移的関数従属を排除（主キー以外の列が他の非キー属性に依存しない）\n\n### 2.4 論理レベルでのデータ型選定\n\n- 製品依存を避け、抽象的なデータ型を選択\n    - `VARCHAR`, `INTEGER`, `DATE`, `DECIMAL` など\n\n## 3. 論理テーブル定義の例\n\n### 3.1 User（ユーザー）\n\n| カラム名 | データ型 | 制約 | 説明 |\n| --- | --- | --- | --- |\n| user_id | INTEGER | PK, 自動採番 | ユーザーの一意識別子 |\n| username | VARCHAR(255) | NOT NULL | ユーザー名 |\n| email | VARCHAR(255) | UNIQUE, NOT NULL | メールアドレス（ナチュラルキー） |\n| password | VARCHAR(255) | NOT NULL | パスワード |\n\n### 3.2 Product（商品）\n\n| カラム名 | データ型 | 制約 | 説明 |\n| --- | --- | --- | --- |\n| product_id | INTEGER | PK, 自動採番 | 商品の一意識別子 |\n| product_code | VARCHAR(100) | UNIQUE, NOT NULL | 商品コード（ナチュラルキー） |\n| name | VARCHAR(255) | NOT NULL | 商品名 |\n| price | DECIMAL(10,2) | NOT NULL | 価格 |\n| stock | INTEGER | NOT NULL | 在庫数 |\n\n### 3.3 Cart（カート）\n\n| カラム名 | データ型 | 制約 | 説明 |\n| --- | --- | --- | --- |\n| cart_id | INTEGER | PK, 自動採番 | カートの一意識別子 |\n| user_id | INTEGER | FK (User) | カート所有者 |\n| created_at | DATE | NOT NULL | カート作成日時 |\n\n### 3.4 CartItem（カート内商品）\n\n| カラム名 | データ型 | 制約 | 説明 |\n| --- | --- | --- | --- |\n| cart_id | INTEGER | PK, FK (Cart) | カートの識別子 |\n| product_id | INTEGER | PK, FK (Product) | カート内の商品 |\n| quantity | INTEGER | NOT NULL | 商品の個数 |\n\n### 3.5 Order（注文）\n\n| カラム名 | データ型 | 制約 | 説明 |\n| --- | --- | --- | --- |\n| order_id | INTEGER | PK, 自動採番 | 注文の一意識別子 |\n| user_id | INTEGER | FK (User) | 注文したユーザー |\n| total_price | DECIMAL(10,2) | NOT NULL | 合計金額 |\n| status | VARCHAR(50) | NOT NULL | 注文ステータス（例: 確定, 発送済み） |\n| order_date | DATE | NOT NULL | 注文日時 |\n\n### 3.6 OrderItem（注文内商品）\n\n| カラム名 | データ型 | 制約 | 説明 |\n| --- | --- | --- | --- |\n| order_id | INTEGER | PK, FK (Order) | 注文の識別子 |\n| product_id | INTEGER | PK, FK (Product) | 注文内の商品 |\n| quantity | INTEGER | NOT NULL | 商品の個数 |\n\n### 3.7 Payment（決済）\n\n| カラム名 | データ型 | 制約 | 説明 |\n| --- | --- | --- | --- |\n| payment_id | INTEGER | PK, 自動採番 | 決済の一意識別子 |\n| order_id | INTEGER | FK (Order) | 関連する注文 |\n| method | VARCHAR(50) | NOT NULL | 決済方法（クレジットカード, 銀行振込など） |\n| status | VARCHAR(50) | NOT NULL | 決済ステータス（成功, 失敗など） |\n| payment_date | DATE | NOT NULL | 決済日時 |\n\n## 3. 論理テーブル設計後のER図\n\n以下のER図は、論理テーブル設計を反映したものです。\n\n```mermaid\nerDiagram\n  User {\n    INTEGER user_id\n    VARCHAR username\n    VARCHAR email\n    VARCHAR password\n  }\n  Product {\n    INTEGER product_id\n    VARCHAR product_code\n    VARCHAR name\n    DECIMAL price\n    INTEGER stock\n  }\n  Cart {\n    INTEGER cart_id\n    INTEGER user_id\n    DATE created_at\n  }\n  CartItem {\n    INTEGER cart_id\n    INTEGER product_id\n    INTEGER quantity\n  }\n  Order {\n    INTEGER order_id\n    INTEGER user_id\n    DECIMAL total_price\n    VARCHAR status\n    DATE order_date\n  }\n  OrderItem {\n    INTEGER order_id\n    INTEGER product_id\n    INTEGER quantity\n  }\n  Payment {\n    INTEGER payment_id\n    INTEGER order_id\n    VARCHAR method\n    VARCHAR status\n    DATE payment_date\n  }\n\n  User ||--o{ Cart : owns\n  User ||--o{ Order : places\n  Cart ||--o{ CartItem : contains\n  CartItem ||--|| Product : includes\n  Order ||--o{ OrderItem : contains\n  OrderItem ||--|| Product : includes\n  Order ||--o{ Payment : processes\n```\n\n## 4. まとめ\n\n本記事では、ECサイトを題材に論理テーブル設計の手順を解説しました。\n\n1. エンティティをテーブル化し、リレーションを定義\n2. 主キー・外部キー・制約を適切に設定\n3. 第3正規形を基本にしつつ、性能要件に応じて非正規化を検討\n4. 正規化の基本概念（1NF, 2NF, 3NF）を説明\n5. 抽象的なデータ型を選定し、製品依存を避ける\n6. ER図で論理テーブルの構造を視覚化\n\nこの設計をもとに、次は物理データベース設計を進め、最適なインデックスやパーティショニングの適用を検討していきましょう。\n\n---\n\n","updatedAt":"2025-06-02T05:32:11.845Z","tags":[{"id":6,"documentId":"bnetm5oe2jokv3u2ib1nibia","createdAt":"2025-05-19T09:45:00.761Z","updatedAt":"2025-05-19T09:45:00.761Z","publishedAt":"2025-05-19T09:45:00.769Z","name":"Database"},{"id":4,"documentId":"zc573y83cxbfql2umdwbhot9","createdAt":"2025-05-19T09:44:33.028Z","updatedAt":"2025-05-19T09:44:33.028Z","publishedAt":"2025-05-19T09:44:33.035Z","name":"Tutorial"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_25_68f5cc6f84.png"}},{"id":216,"documentId":"n0q7w0c5cubhhhsfmv7g75fd","title":"【データモデリング】 概念設計のチュートリアル","content":"データモデリングは、システム設計の基盤となる重要なプロセスです。\n特に、エンティティを適切に抽出することで、データの構造が明確になり、システムの拡張性や保守性が向上します。\n本記事では、ECサイトを題材にして、エンティティ抽出の手順を詳しく解説します。\n\n## 1. シナリオの設定\n\nまず、ECサイトにおける主要な機能を整理しましょう。\n\n- **商品一覧の表示**\n- **カートへの追加・削除**\n- **注文処理**\n- **決済処理**\n\nこのシナリオをもとに、データモデルの基盤となるエンティティを抽出します。\n\n## 2. エンティティ抽出の手順\n\nエンティティとは、システム内で管理すべき「データのまとまり」です。\nエンティティを抽出する際には、以下の観点からアプローチすると整理しやすくなります。\n\n### 2.1 モノとコトの視点でのエンティティ抽出\n\nエンティティは、大きく「モノ（物理的または概念的な存在）」と「コト（イベントや取引）」の2種類に分類できます。\n\n- **モノ:** ユーザー、商品 など、実態として存在するもの\n- **コト:** 注文、決済 など、システム内で発生する出来事や取引\n\nこの視点でシナリオを整理し、以下の手順でエンティティを洗い出します。\n\n1. システム内で管理する必要がある「**モノ**」を特定する\n2. システム内で発生する「**コト**」を特定する\n3. エンティティごとに**ナチュラルキー（自然キー）**を見つける\n    - ナチュラルキーとは、データを一意に識別できる属性の組み合わせ（例: ユーザー は メールアドレス、 商品 は 商品コード など）\n4. エンティティ間の関連を整理する\n\n## 3. エンティティと属性\n\n以下のようなエンティティを抽出し、それぞれの属性を定義します。\n\n| エンティティ和名 | エンティティ英名 | 区分 | 属性名 (日) | 属性名 (英) | 説明 |\n| --- | --- | --- | --- | --- | --- |\n| ユーザー | **User** | モノ | ユーザー名 | username | ユーザーの識別情報 |\n|  |  |  | メールアドレス | email | ユーザーの連絡先（ナチュラルキー） |\n|  |  |  | パスワード | password | 認証情報 |\n| 商品 | **Product** | モノ | 商品名 | name | 商品の名称 |\n|  |  |  | 商品コード | product_code | 一意に識別できる商品番号（ナチュラルキー） |\n|  |  |  | 価格 | price | 商品の販売価格 |\n|  |  |  | 在庫数 | stock | 在庫の数量 |\n| カート | **Cart** | コト | ユーザー | user | カートを持つユーザー |\n|  |  |  | 商品 | product | カートに入っている商品 |\n|  |  |  | 数量 | quantity | 選択された商品の個数 |\n|  |  |  | 追加日時 | added_at | カートに追加した日時 |\n| 注文 | **Order** | コト | 注文番号 | order_number | 一意に識別できる注文番号（ナチュラルキー） |\n|  |  |  | ユーザー | user | 注文を行ったユーザー |\n|  |  |  | 合計金額 | total_price | 注文の総額 |\n|  |  |  | ステータス | status | 注文の状態（例: 確定、発送済み） |\n|  |  |  | 注文日時 | orderd_at | 注文した日時 |\n| 決済 | **Payment** | コト | 決済番号 | payment_number | 一意に識別できる決済番号（ナチュラルキー） |\n|  |  |  | 注文 | order | 対応する注文 |\n|  |  |  | 決済方法 | method | クレジットカード、銀行振込などの支払い方法 |\n|  |  |  | ステータス | status | 決済の状態（成功、失敗など） |\n|  |  |  | 決済日時 | payment_at | 決済した日時 |\n\n## 4. エンティティ間の関係（ER図）\n\n以下のER図を使用して、エンティティ間の関係を可視化します。\n\n```mermaid\nerDiagram\n    User {\n        string username\n        string email\n        string password\n    }\n    Product {\n        string name\n        string product_code\n        float price\n        int stock\n    }\n    Cart {\n        string user\n        string product\n        int quantity\n    }\n    Order {\n        string order_number\n        string user\n        float total_price\n        string status\n    }\n    Payment {\n        string payment_number\n        string order\n        string method\n        string status\n    }\n\n    User ||--o{ Cart : has\n    User ||--o{ Order : places\n    Cart }o--|| Product : contains\n    Order }o--|| Product : includes\n    Order ||--o{ Payment : processes\n\n```\n\n### 関係の説明\n\n- **User と Cart**: 1人のユーザーが複数のカートエントリを持つ（1対多）\n- **User と Order**: 1人のユーザーが複数の注文を行う（1対多）\n- **Cart と Product**: 1つのカートには複数の商品が含まれる（多対多）\n- **Order と Product**: 1つの注文には複数の商品が含まれる（多対多）\n- **Order と Payment**: 1つの注文に対して1つの決済が行われる（1対1）\n\nここでは、エンティティの物理名やIDについては言及せず、ナチュラルキーに着目してエンティティを定義しています。\n\n## 5. まとめ\n\nエンティティ抽出は、データモデリングの第一歩です。本記事では、ECサイトの基本機能をもとに、エンティティを抽出し、それぞれの属性を定義しました。また、「モノとコト」の視点からエンティティを整理し、ナチュラルキーに着目する手法を紹介しました。\n\n次のステップとして、正規化やリレーショナルデータベースの設計へと進んでいきましょう。\n\n---\n\n","updatedAt":"2025-06-02T05:31:55.706Z","tags":[{"id":6,"documentId":"bnetm5oe2jokv3u2ib1nibia","createdAt":"2025-05-19T09:45:00.761Z","updatedAt":"2025-05-19T09:45:00.761Z","publishedAt":"2025-05-19T09:45:00.769Z","name":"Database"},{"id":4,"documentId":"zc573y83cxbfql2umdwbhot9","createdAt":"2025-05-19T09:44:33.028Z","updatedAt":"2025-05-19T09:44:33.028Z","publishedAt":"2025-05-19T09:44:33.035Z","name":"Tutorial"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_24_770ed9dea0.png"}},{"id":215,"documentId":"s5f5pb3iniim1r09n51w4m3y","title":"Docker超入門 初心者でもすぐに使える基礎ガイド","content":"近年、開発環境の構築やアプリケーションのデプロイにおいて欠かせない技術となっている **Docker**。\n\n「名前は聞いたことがあるけど、なんだか難しそう…」と感じていませんか？\n\n実はDockerは、基本さえ押さえれば誰でもすぐに使いこなせる便利なツールです！\n\n本記事では、Dockerの **基本的な使い方** を「Hello World」から **簡単なWebサーバーの作成** まで、一歩ずつ学んでいきます。\n\n**さあ、Dockerの世界に一歩踏み出しましょう！**\n\n---\n\n## **1. 事前準備：Dockerをインストールしよう！**\n\nDockerを使うためには、まず **Docker Desktop** をインストールする必要があります。\n\n以下の公式サイトから、自分のOSに合ったものをダウンロードしましょう。\n\n🔗 [Docker公式サイト](https://www.docker.com/products/docker-desktop/)\n\n### **インストールの流れ**\n\n1. **Docker Desktop** をダウンロード  \n2. インストーラーを実行してインストール  \n3. インストール後、Docker Desktopを起動  \n4. ターミナル（またはコマンドプロンプト）を開いて、以下のコマンドを実行  \n\n正しくインストールされていれば、バージョン情報が表示されます。\n\n```bash\ndocker --version\n```\n\nこれで準備完了です！\n\nでは、早速 **Dockerの基本操作** を試してみましょう。\n\n---\n\n## **2. DockerでHello Worldを実行してみよう！**\n\nDockerの基本を学ぶ第一歩として、まずは「Hello World」を実行してみます。\n\n以下のコマンドを実行してみてください。\n\n```bash\ndocker run hello-world\n```\n\nこのコマンドを実行すると、以下のような動作が行われます。\n\nまず、`hello-world` というDockerイメージ（実行可能なアプリケーションのパッケージ）がダウンロードされます。\n\n次に、ダウンロードしたイメージからコンテナ（仮想環境）が作成されます。\n\nその後、`hello-world` コンテナが起動し、次のようなメッセージを表示します。\n\n```bash\nHello from Docker!\nThis message shows that your installation appears to be working correctly.\n```\n\nコンテナは自動的に終了します。\n\nこのメッセージが表示されたら、Dockerが正常に動作している証拠です！ 🎉\n\n---\n\n## **3. Dockerの基本的な操作**\n\nDockerを使う上で **頻繁に使う基本コマンド** を紹介します。\n\nどれも重要なので、実際に試しながら覚えていきましょう！\n\n### **① コンテナの作成 \u0026 実行**\n\n```bash\ndocker run -d --name my-nginx -p 8080:80 nginx\n```\n\n- `-d` ：バックグラウンドで実行  \n- `--name my-nginx` ：コンテナに `my-nginx` という名前をつける  \n- `-p 8080:80` ：ホストの `8080` ポートをコンテナの `80` ポートにマッピング  \n- `nginx` ：使用するDockerイメージ（公式のNginx）\n\n### **② 実行中のコンテナを確認**\n\n```bash\ndocker ps\n```\n\n### **③ 停止 \u0026 削除**\n\n```bash\ndocker stop my-nginx\ndocker rm my-nginx\n```\n\n### **④ ログの確認**\n\n```bash\ndocker logs my-nginx\n```\n\n### **⑤ 利用可能なDockerイメージを確認**\n\n```bash\ndocker images\n```\n\n### **⑥ 不要なDockerイメージを削除**\n\n```bash\ndocker rmi イメージID\n```\n\n👉 **すべての未使用イメージを一括削除：**\n\n```bash\ndocker image prune -a\n```\n\n### **⑦ Dockerイメージの作成**\n\n```bash\ndocker build -t my-nginx-image .\n```\n\n---\n\n## **4. 簡単なDockerfileを作ってみよう！**\n\n### **Nginxでindex.htmlを表示するDockerイメージを作成**\n\nDockerの **真骨頂** は、「一度環境を作れば、どこでも同じ環境を再現できること」。\n\nそこで、 **Nginxを使って簡単なWebサーバーを構築** し、自分だけのDockerイメージを作ってみましょう！\n\n### **① プロジェクトフォルダを作成**\n\n```bash\nmkdir my-nginx\ncd my-nginx\n```\n\n### **② index.html を作成**\n\n```html\n\u003ch1\u003eWelcome to my Nginx Server!\u003c/h1\u003e\n```\n\n### **③ Dockerfile を作成**\n\n```docker\n# ベースイメージとしてNginxを使用\nFROM nginx:latest\n\n# 作成した index.html をNginxのデフォルトページとして配置\nCOPY index.html /usr/share/nginx/html/index.html\n\n# コンテナ起動時にNginxを実行\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n```\n\n### **④ Dockerイメージをビルド**\n\n```bash\ndocker build -t my-nginx-image .\n```\n\n### **⑤ コンテナを起動**\n\n```bash\ndocker run -d --name my-nginx-container -p 8080:80 my-nginx-image\n```\n\n### **⑥ ブラウザで確認**\n\nWebブラウザで `http://localhost:8080` にアクセスし、  \n「**Welcome to my Nginx Server!**」と表示されれば成功です！ 🎉\n\n---\n\n## **5. まとめ：Dockerの基本をマスター！**\n\n✅ Dockerのインストール  \n✅ `docker run` を使った「Hello World」の実行  \n✅ 基本的なDockerコマンド（`run`、`ps`、`stop`、`rm`、`logs`、`images`、`rmi`、`build`）  \n✅ Dockerfile を使ってオリジナルのDockerイメージを作成  \n\n---\n\nこれで、Dockerの基礎はバッチリです！！ 🚀  \n次のステップとして、**Docker Compose** や **クラウドデプロイ** にも挑戦していきましょう。\n\n---\n","updatedAt":"2025-06-02T05:29:48.958Z","tags":[{"id":2,"documentId":"zigqvzb0flgfexglvu0rhcai","createdAt":"2025-05-19T09:42:02.161Z","updatedAt":"2025-05-19T09:42:02.161Z","publishedAt":"2025-05-19T09:42:02.189Z","name":"Docker"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_22_6c94d9b413.png"}},{"id":211,"documentId":"y39dt5uhrmpjlphirb3u5vhb","title":"Docker Compose超入門 初心者でもすぐに使える基礎ガイド","content":"Dockerを使うとアプリの環境を簡単に構築できますが、複数のコンテナを扱う場合、コマンドが増えて面倒になることがあります。そんなときに役立つのが **Docker Compose** です！\n\n本記事では、Docker Composeの基本から、よく使うコマンド、実際にNginxとExpress.jsを組み合わせたアプリの作成まで、ステップバイステップで解説します。\n\n---\n\n## 1. 事前準備：DockerとDocker Composeのインストール\n\nDocker Composeを使用するには、まず **Docker Desktop** をインストールする必要があります。\n\n### **Dockerのインストール**\n\n公式サイトからDockerをインストールします。\n\n🔗 [Docker公式サイト](https://www.docker.com/products/docker-desktop/)\n\n---\n\n## 2. `docker-compose.yml` を作成してみよう\n\nまずは簡単な `docker-compose.yml` を作成し、コンテナを管理する方法を学びましょう。\n\n### **1つのサービスを定義**\n\n以下のYAMLファイルを作成し、nginxのWebサーバーを動かしてみます。\n\n```yaml\nversion: '3'\n\nservices:\n  web:\n    image: nginx\n    ports:\n      - \"80:80\"\n\n```\n\nこの例では `web` がサービス名になります。\n\n### **起動**\n\n作成したファイルがあるディレクトリで、以下のコマンドを実行します。\n\n```bash\ndocker-compose up -d\n```\n\n- `-d` はバックグラウンド実行のオプション\n- ブラウザで `http://localhost` にアクセスすると、Nginxのデフォルトページが表示されます。\n\n### **終了**\n\n```bash\ndocker-compose down\n```\n\nこれでコンテナは停止・削除されます。\n\n---\n\n## 3. Docker Composeのよく使うコマンド\n\nDocker Composeを使うと、複数のコンテナを一括で管理できます。ここでは、よく使うコマンドを順番に紹介します。\n\n### ① コンテナを起動\n\n```bash\ndocker compose up\n```\n\n`docker compose up` を実行すると、`docker-compose.yml` に記載されたサービス（コンテナ）が起動します。\n\n### ② バックグラウンドで起動\n\n```bash\ndocker compose up -d\n```\n\n- `-d` をつけるとバックグラウンドで起動し、ターミナルを占有しません。\n\n### ③ 特定のサービスのみ起動\n\n```bash\ndocker compose up サービス名\n```\n\n`docker-compose.yml` に定義されている特定のサービスだけを起動したい場合は、サービス名を指定します。\n\n### ④ コンテナを停止＆削除\n\n```bash\ndocker compose down\n```\n\n起動したコンテナを停止し、削除します。ネットワークも削除されるため、完全にクリーンな状態に戻したいときに便利です。\n\n### ⑤ コンテナを停止\n\n```bash\ndocker compose stop\n```\n\n実行中のコンテナを停止します。ただし、コンテナ自体は削除されないため、後で `docker compose start` で再開できます。\n\n### ⑥ 停止したコンテナを再開\n\n```bash\ndocker compose start\n```\n\n`docker compose stop` で停止したコンテナを再び起動します。\n\n### ⑦ コンテナを再起動\n\n```bash\ndocker compose restart\n```\n\nコンテナを再起動したいときに使います。設定を変更した場合などに便利です。\n\n### ⑧ 実行中のコンテナを確認\n\n```bash\ndocker compose ps\n```\n\n現在動作しているコンテナの状態を一覧表示します。\n\n### ⑨ コンテナのログを表示\n\n```bash\ndocker compose logs\n```\n\nコンテナの標準出力（ログ）を確認できます。\n\nリアルタイムでログを追いたい場合は `-f` をつけます。\n\n```bash\ndocker compose logs -f\n```\n\n### ⑩ 特定のサービスのコンテナを削除\n\n```bash\ndocker compose rm -fsv サービス名\n```\n\n特定のサービスのみを削除するときに使用します。\n\nオプションの意味：\n\n- `-f` 強制削除\n- `-s` ボリュームも削除\n- `-v` 名前付きボリュームも削除\n\nこれらのコマンドを覚えておけば、Docker Composeをスムーズに扱えるようになります！\n\n---\n\n## 4. NginxとExpress.jsを組み合わせたアプリを作成\n\nここからは、カスタムの `Dockerfile` と `docker-compose.yml` を作成し、 **NginxとExpress.jsを使ったHello Worldアプリ** を実装します。\n\n### **ディレクトリ構成**\n\n```bash\nmyapp/\n│── docker-compose.yml\n│── nginx/\n│   └── default.conf\n└── app/\n    ├── Dockerfile\n    ├── package.json\n    ├── server.js\n```\n\n### **1. Express.jsの準備**\n\nまず、`app/` ディレクトリを作成し、その中に `package.json` を用意します。\n\n```json\n{\n  \"name\": \"docker-express\",\n  \"version\": \"1.0.0\",\n  \"main\": \"server.js\",\n  \"dependencies\": {\n    \"express\": \"^4.17.1\"\n  }\n}\n\n```\n\n次に、`server.js` を作成します。\n\n```jsx\nconst express = require('express');\nconst app = express();\n\napp.get('/', (req, res) =\u003e {\n  res.send('Hello, World from Express.js!');\n});\n\napp.listen(3000, () =\u003e {\n  console.log('Server is running on port 3000');\n});\n\n```\n\n### **2. Express.jsのDockerfile**\n\n次に、`app/` ディレクトリ内に `Dockerfile` を作成します。\n\n```docker\nFROM node:14\nWORKDIR /app\nCOPY package.json ./\nRUN npm install\nCOPY . .\nCMD [\"node\", \"server.js\"]\nEXPOSE 3000\n\n```\n\n### **3. Nginxの設定**\n\nNginxをリバースプロキシとして動作させます。`nginx/` ディレクトリを作成し、`default.conf` を追加します。\n\n```\nserver {\n    listen 80;\n\n    location / {\n        proxy_pass http://app:3000;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n}\n```\n\n### **4. `docker-compose.yml` を作成**\n\n最後に `docker-compose.yml` をルートディレクトリに作成します。\n\n```yaml\nversion: '3'\n\nservices:\n  app:\n    build: ./app\n    ports:\n      - \"3000:3000\"\n\n  web:\n    image: nginx\n    ports:\n      - \"80:80\"\n    volumes:\n      - ./nginx/default.conf:/etc/nginx/conf.d/default.conf\n    depends_on:\n      - app\n\n```\n\n### **5. コンテナの起動**\n\n```bash\ndocker-compose up -d\n```\n\n- `http://localhost` にアクセスすると `Hello, World from Express.js!` が表示されます。\n\n---\n\n## まとめ\n\n今回は **Docker Composeの基本** から **Nginx + Express.jsのWebアプリ** を作るところまで解説しました。\n\n### **学んだポイント**\n\n✅ Docker Composeの基本的なコマンド\n\n✅ `docker-compose.yml` の書き方\n\n✅ カスタム `Dockerfile` の作成\n\n✅ NginxとExpress.jsの連携\n\nDocker Composeを使えば、 **複数のコンテナを簡単に管理できる** ようになります。ぜひ試してみてくださいね。 🚀\n\n---\n","updatedAt":"2025-06-02T05:24:02.040Z","tags":[{"id":2,"documentId":"zigqvzb0flgfexglvu0rhcai","createdAt":"2025-05-19T09:42:02.161Z","updatedAt":"2025-05-19T09:42:02.161Z","publishedAt":"2025-05-19T09:42:02.189Z","name":"Docker"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_23_99f792de40.png"}},{"id":210,"documentId":"kgkva26cgncrrm565n6fbf3g","title":"Dockerで簡単構築！Ollamaを使ってLLMを試そう","content":"最近話題の大規模言語モデル（LLM）を自分の環境で手軽に試したいと思いませんか？？\n\nこの記事では、Dockerを使って **ollama** を動かす方法を解説します。\n\n特に、CPU環境でサクッとセットアップできるので、LLM初心者やハードウェアリソースが限られている方にもおすすめです。\n\n---\n\n# 1. Ollamaを動かすための準備\n\nまずは必要なファイルを作成します。\n\n## Docker Composeファイルの作成\n\n以下の内容で `docker-compose.yml` を作成します。これにより、ollamaをDockerコンテナとして動かす設定が整います。\n\n```yaml\nservices:\n  ollama:\n    image: ollama/ollama\n    container_name: ollama\n    ports:\n      - \"11434:11434\"\n    volumes:\n      - ollama:/root/.ollama\n\nvolumes:\n  ollama:\n\n```\n\n## コンテナの起動\n\n次に、以下のコマンドを実行してコンテナを起動します。\n\n```bash\ndocker compose up -d\n```\n\nこれで、ollamaが立ち上がります。特にエラーが出なければ、次に進みましょう。\n\n---\n\n# 2. tinyllamaモデルを試す\n\n起動したコンテナ内でtinyllamaモデルを利用できるように設定します。\n\n## モデルをPullする\n\n以下のコマンドで、tinyllamaモデルを取得します。\n\n```bash\ndocker exec -it ollama ollama run tinyllama\n```\n\n取得したモデルはコンテナ内の `/root/.ollama` に保存されます。\n\n---\n\n# 3. モデルに質問してみる\n\ntinyllamaを使って質問してみましょう。以下のコマンドを実行します。\n\n## 質問コマンド例\n\n```bash\ncurl http://localhost:11434/api/generate -d '{\n  \"model\": \"tinyllama\",\n  \"prompt\": \"Why is the sky blue?\",\n  \"stream\": false\n}'\n```\n\n## サンプルレスポンス\n\n以下のようなレスポンスが返ってきます。\n\n```json\n{\n  \"model\": \"tinyllama\",\n  \"response\": \"The sky blue color that we see in the sky is due to the presence of sunlight reflected by the Earth's surface. ...\",\n  \"done\": true\n}\n```\n\nシンプルな設定でLLMを利用できましたね！\n\n---\n\n# 4. Pythonからもっと便利に使う\n\nCLIだけでなく、Pythonスクリプトからもollamaを使うことができます。\n\n## Pythonスクリプトの作成\n\n以下のコードを `ollama.py` というファイル名で保存してください。\n\n```python\nimport requests\n\n# Ollamaのエンドポイント\nurl = \"http://localhost:11434/api/generate\"\n\n# モデル名を指定\nmodel_name = \"tinyllama\"\n\n# プロンプト\nprompt = \"tell me about popular place in san diego.\"\n\n# リクエストのペイロード\npayload = {\n    \"model\": model_name,\n    \"prompt\": prompt,\n    \"stream\": False\n}\n\n# リクエストの送信\nresponse = requests.post(url, json=payload)\n\n# レスポンスの確認\nif response.status_code == 200:\n    print(\"Response:\", response.json()[\"response\"])\nelse:\n    print(\"Error:\", response.status_code, response.text)\n\n```\n\n## スクリプトを実行\n\n以下のコマンドでスクリプトを実行します。\n\n```bash\npython3 ollama.py\n```\n\n## 実行結果\n\n例えば、以下のような回答が返ってきます。\n\n```\nResponse: San Diego is a popular tourist destination known for its beautiful beaches, rich history, world-class restaurants and attractions such as the San Diego Zoo, SeaWorld, Balboa Park, La Jolla Cove, Mission Valley Farmers Market, and more. Some of the most popular places to visit in San Diego include:\n\n1) Balboa Park - home to numerous museums, gardens, and cultural attractions, such as the San Diego Museum of Art, California Museum of Photography, and the Mexican Heritage Plaza.\n\n2) San Diego Zoo - one of the largest zoo complexes in the world, featuring over 3,000 animals from more than 800 species.\n\n3) La Jolla Cove - a scenic spot located at the foot of Mount Soledad where visitors can observe sea lions, seals, and otters playfully swimming in the crystal-clear waters.\n\n4) Mission Valley Farmers Market - an outdoor market featuring fresh produce, locally grown foods, and unique artisanal goods.\n\n5) Coronado Island - a picturesque seaside village known for its charming streets lined with historic mansions, beautiful beaches, and a range of dining options.\n\n6) USS Midway Museum - a restored World War II aircraft carrier that offers interactive exhibits, live-aboard tours, and memorabilia displays.\n\n7) La Jolla Botanical Cactus Garden - an extensive collection of cacti and succulents, featuring native species from all over the world.\n\n8) Torrey Pines State Natural Reserve - a scenic coastal reserve with hiking trails, picnic areas, and stunning views of the Pacific Ocean.\n\n9) Balboa Park Golf Course - a 13-hole golf course located in San Diego's Balboa Park that offers beautiful views of the city skyline.\n\n10) Pacific Beach - a popular surfing spot known for its long beaches and stunning views of La Jolla Cove.\n\nThese are just a few examples of the many attractions and activities available in San Diego, but there's always something new to discover at any time!\n```\n\n旅行のアドバイスから、技術的な質問まで、あらゆるプロンプトに答えてくれます！\n\n---\n\n## 注意事項\n\nLLMが生成する回答は便利な一方で、必ずしも正確であるとは限りません。回答内容に誤りが含まれている場合や、曖昧な表現が使われていることがあります。そのため、重要な決定や判断を行う際には、他の信頼できる情報源と照らし合わせて確認してください。\n\n---\n\n## おわりに\n\nDockerを使えば、ollamaのセットアップはとても簡単です。tinyllamaモデルを使った質問やPythonスクリプトによる応用など、ローカル環境でLLMを自由に試せるのは魅力的ですよね。次は、さらに高度なモデルを試してみるのも良いかもしれません。\n\nぜひこの記事を参考に、LLMの世界を体験してみてください！\n\n---\n\n","updatedAt":"2025-06-02T05:22:30.824Z","tags":[{"id":20,"documentId":"fbllyhmskvu2l7wbg5dzpkri","createdAt":"2025-05-19T09:48:50.341Z","updatedAt":"2025-05-19T09:48:50.341Z","publishedAt":"2025-05-19T09:48:50.348Z","name":"LLM"},{"id":22,"documentId":"enpfq0z697dadtxijwpwwrsv","createdAt":"2025-05-19T09:49:17.862Z","updatedAt":"2025-05-19T09:49:17.862Z","publishedAt":"2025-05-19T09:49:17.870Z","name":"Python"},{"id":30,"documentId":"d99cu6c3t9hgwynppb92lhph","createdAt":"2025-05-19T09:50:59.080Z","updatedAt":"2025-05-19T09:50:59.080Z","publishedAt":"2025-05-19T09:50:59.086Z","name":"生成AI"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_21_37f2d57d1a.png"}},{"id":209,"documentId":"oy8vkgnlt756zh041qbas6zt","title":"テキストのトークン数を確認する方法：LLMチューニングの基礎知識","content":"LLM（大規模言語モデル）のチューニングでは、トレーニングデータの品質だけでなく、トークン数が重要な役割を果たします。トークン数を把握する事で、データの適切な量を判断し、過学習を防ぐことが可能になります。この記事では、トークン数を確認するための主要なツールとその使い方を解説します。\n\n---\n\n# トークン数を確認する理由\n\nトークンとは、テキストを小さな単位に分割したものです。たとえば、単語や句読点、記号などが該当します。LLMのトレーニングでは、以下のような理由でトークン数を知ることが重要です。\n\n1. **適切なトレーニング量の判断**：トークン数が少ないとモデルが十分な学習を行えず、性能が低下する可能性があります。一方、データが多すぎると計算資源を無駄に消費します。\n2. **モデルの特性に合わせたチューニング**：モデルごとに最適なトークン数が異なるため、トークン化に対応したツールを使うことで効率的な学習を実現できます。\n\n---\n\n# トークン数を確認する手軽な方法\n\n以下では、トークン数を確認するための主要な方法を紹介します。それぞれのツールは特定の用途やモデルに適しているため、目的に応じて使い分けると良いでしょう。\n\n## 1. **tiktoken**\n\n### 特徴\n\n`tiktoken`はOpenAIが提供するトークナイザーで、GPTシリーズ向けに設計されています。モデルのエンコーディング設定を変更することで、異なるモデルに対応可能です。\n\n### 使用方法\n\n**インストール**\n\n```bash\npip install tiktoken\n```\n\n**ソースコード**\n\n```python\nimport tiktoken\n\ndef count_tokens(text):\n    tokenizer = tiktoken.get_encoding(\"o200k_base\") # gpt-4oモデル向け\n    tokens = tokenizer.encode(text)\n    return len(tokens)\n\n# テキストファイルを読み込みトークン数を確認\ninput_file_path = './text.txt'\nwith open(input_file_path, 'r', encoding='utf-8') as file:\n    raw_text = file.read()\n\ntoken_len = count_tokens(raw_text)\nprint(token_len)\n```\n\n**結果例**\n\n- `o200k_base`では1143トークン\n- `cl100k_base`に変更すると1420トークン\n\n---\n\n## 2. **Transformers**\n\n### 特徴\n\nHugging Faceの`transformers`ライブラリは、多くのモデルに対応したトークナイザーを提供しています。日本語モデルにも対応しているため、多言語テキストの解析に便利です。\n\n### 使用方法\n\n**インストール**\n\n```bash\npip install transformers\n```\n\n**ソースコード**\n\n```python\nfrom transformers import AutoTokenizer\n\ndef count_tokens(text):\n    tokenizer = AutoTokenizer.from_pretrained(\"llm-jp/llm-jp-3-3.7b-instruct\")\n    tokens = tokenizer.encode(text)\n    return len(tokens)\n\n# テキストファイルを読み込みトークン数を確認\ninput_file_path = './text.txt'\nwith open(input_file_path, 'r', encoding='utf-8') as file:\n    raw_text = file.read()\n\ntoken_len = count_tokens(raw_text)\nprint(token_len)\n\n```\n\n**結果例**\n\n- `llm-jp-3-3.7b-instruct`モデルでは991トークン\n- `elyza/ELYZA-japanese-Llama-2-7b-instruct`では1556トークン\n\n---\n\n## 3. **SpaCy**\n\n### 特徴\n\n`spaCy`は汎用的なNLPツールで、日本語を含む多言語のトークン化が可能です。LLM専用ではないため、簡易的な確認に適しています。\n\n### 使用方法\n\n**インストール**\n\n```bash\npip install spacy\npython -m spacy download ja_core_news_sm\n```\n\n**ソースコード**\n\n```python\nimport spacy\n\ndef count_tokens(text):\n    nlp = spacy.load(\"ja_core_news_sm\")\n    doc = nlp(text)\n    tokens = [token.text for token in doc]\n    return len(tokens)\n\n# テキストファイルを読み込みトークン数を確認\ninput_file_path = './text.txt'\nwith open(input_file_path, 'r', encoding='utf-8') as file:\n    raw_text = file.read()\n\ntoken_len = count_tokens(raw_text)\nprint(token_len)\n\n```\n\n**結果例**\n\n- トークン数は1118\n\n---\n\n## 4. **MeCab**\n\n### 特徴\n\n`MeCab`は日本語形態素解析ツールで、`fugashi`を通じてPythonから利用できます。日本語テキストの解析に特化しており、詳細なトークン化が可能です。\n\n### 使用方法\n\n**インストール**\n\n```bash\npip install 'fugashi[unidic]'\npython -m unidic download\n```\n\n**ソースコード**\n\n```python\nimport fugashi\n\ndef count_tokens(text):\n    tagger = fugashi.Tagger()\n    tokens = [word.surface for word in tagger(text)]\n    return len(tokens)\n\n# テキストファイルを読み込みトークン数を確認\ninput_file_path = './text.txt'\nwith open(input_file_path, 'r', encoding='utf-8') as file:\n    raw_text = file.read()\n\ntoken_len = count_tokens(raw_text)\nprint(token_len)\n\n```\n\n**結果例**\n\n- トークン数は1028\n\n---\n\n# 結論：目的に応じたツール選びを\n\nトークン数を確認する際のポイントをまとめると、以下のようになります。\n\n- **LLM用のトークナイザーが必要**なら`tiktoken`や`transformers`を使用\n- **汎用的な解析**なら`spaCy`や`MeCab`が便利\n\nトークン数がわかれば、トレーニングデータをどの程度追加する必要があるかや、モデルの特性に合った学習が可能になります。\n\n手軽にトークン数を確認し、効率的なLLM開発を目指しましょう！\n\n---\n","updatedAt":"2025-06-02T05:19:10.059Z","tags":[{"id":20,"documentId":"fbllyhmskvu2l7wbg5dzpkri","createdAt":"2025-05-19T09:48:50.341Z","updatedAt":"2025-05-19T09:48:50.341Z","publishedAt":"2025-05-19T09:48:50.348Z","name":"LLM"},{"id":22,"documentId":"enpfq0z697dadtxijwpwwrsv","createdAt":"2025-05-19T09:49:17.862Z","updatedAt":"2025-05-19T09:49:17.862Z","publishedAt":"2025-05-19T09:49:17.870Z","name":"Python"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_20_67274fed95.png"}},{"id":208,"documentId":"zpf2m4dks36ri1sxzpkhq91u","title":"【PDF操作比較】PyMuPDFでPDFからテキストも表も簡単抽出","content":"PDF操作ライブラリの比較検討記事の続きです。\n\n前回までの記事はこちら\n\n- [【PDF操作比較】pypdfでPDFからテキスト抽出を行う方法](https://my-blog-frontend-jectjhrfq-raisex-hyamasakis-projects.vercel.app/articles/i402h46inwv9yzy1mgah101z)\n- [【PDF操作比較】pdfplumberでPDFからテキストも表も簡単抽出](https://my-blog-frontend-jectjhrfq-raisex-hyamasakis-projects.vercel.app/articles/g8z0fn5ap0si8r1iheg2iwd7)\n\nPDFデータの前処理において、**テキスト抽出**と**表形式データの抽出**は非常に重要な作業です。今回紹介するのは、Pythonライブラリの**PyMuPDF**を活用したPDFデータの抽出方法です。PyMuPDFは、速度と柔軟性に優れたPDF操作ライブラリで、シンプルなAPI設計が特徴です。\n\n---\n\n# PyMuPDFの特徴\n\n- **軽量で高速**: 大量のPDFファイルでも効率よく処理できます。\n- **多機能**: テキスト抽出だけでなく、表や画像の抽出、PDF編集も可能。\n- **RAGやLLMに最適**: 抽出結果を後続処理に簡単に利用できます。\n\n今回は、基本的なテキスト抽出と表抽出にフォーカスして解説します。\n\n---\n\n# PyMuPDFを使ったテキスト抽出\n\n## PyMuPDFのインストール\n\n以下のコマンドを実行してインストールします：\n\n```bash\npip install PyMuPDF\n```\n\n## サンプルコード\n\n以下のコードは、PDFからテキストを抽出し、ファイルに保存するシンプルな例です。\n\n```python\nimport os\nimport pymupdf\n\ninput_pdf_path = \"./docs/読み取りテスト文書.pdf\"\noutput_txt_path = \"./output/text_extract.txt\"\n\ndef extract_text_with_pymupdf(input_path, output_path):\n    try:\n        doc = pymupdf.open(input_path)\n        extracted_text = \"\"\n\n        for page in doc:\n            extracted_text += page.get_text()\n\n        output_dir = os.path.dirname(output_path)\n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n\n        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(extracted_text)\n\n        print(f\"テキストが正常に抽出され、以下のファイルに保存されました: {output_path}\")\n    except Exception as e:\n        print(f\"エラーが発生しました: {e}\")\n\n# 実行\nif __name__ == \"__main__\":\n    extract_text_with_pymupdf(input_pdf_path, output_txt_path)\n```\n\n## 実行方法\n\n上記コードを `text_extract.py` として保存し、以下のコマンドで実行します：\n\n```bash\npython3 text_extract.py\n```\n\n## 結果\n\n実行すると、PDFのテキストが抽出され、以下のような結果が得られます：\n\n```\n \n \n1 \n \n文書のタイトル \n見出し1 \n \n見出し1-1 \nここには見出し1-1 の本文が入ります。ここには見出し1-1 の本文が入ります。ここには見\n出し1-1 の本文が入ります。ここには見出し1-1 の本文が入ります。ここには見出し1-1 の\n本文が入ります。ここには見出し1-1 の本文が入ります。ここには見出し1-1 の本文が入り\nます。ここには見出し1-1 の本文が入ります。ここには見出し1-1 の本文が入ります。ここ\nには見出し1-1 の本文が入ります。ここには見出し1-1 の本文が入ります。 \n \n見出し1-2 \nここには見出し1-2 の本文が入ります。ここには見出し1-2 の本文が入ります。ここには見\n出し1-2 の本文が入ります。ここには見出し1-2 の本文が入ります。ここには見出し1-2 の\n本文が入ります。ここには見出し1-2 の本文が入ります。ここには見出し1-2 の本文が入り\nます。 \nここには見出し1-2 の本文が入ります。ここには見出し1-2 の本文が入ります。 \n \n \n2 \n \nここには見出し1-2 の本文が入ります。ここには見出し1-2 の本文が入ります。 \n \n見出し1-3 \nここには見出し1-3 の本文が入ります。ここには見出し1-3 の本文が入ります。 \nここには見出し1-3 の本文が入ります。ここには見出し1-3 の本文が入ります。ここには見\n出し1-3 の本文が入ります。ここには見出し1-3 の本文が入ります。ここには見出し1-3 の\n本文が入ります。ここには見出し1-3 の本文が入ります。 \n \n \n \n \n3 \n \n列1 \n列2 \n列3 \n列4 \n行1 列1 の本文が入\nります。 \n行1 列2 の本文が入\nります。 \n行1 列3 の本文が入\nります。 \n行1 列4 の本文が入\nります。 \n行2 列1 の本文が入\nります。 \n行2 列2 の本文が入\nります。 \n行2 列3 の本文が入\nります。 \n行2 列4 の本文が入\nります。 \n行3 列1 の本文が入\nります。 \n行3 列2 の本文が入\nります。 \n行3 列3 の本文が入\nります。 \n行3 列4 の本文が入\nります。 \n表1. 表1 の名前が入ります。 \n \n列1 \n列2 \n列3 \n列4 \n行1 列1 の本文が\n入ります。 \n行1 列2 の本文が\n入ります。 \n行1 列3 の本文が\n入ります。 \n行1 列4 の本文が\n入ります。 \n行2 列1 の本文が\n入ります。 \n行2 列2 の本文が\n入ります。 \n行2 列3 の本文が\n入ります。 \n行2 列4 の本文が\n入ります。 \n表2. 表2 の名前が入ります。 \n見出し1-4 \nここには見出し1-4 の本文が入ります。ここには見出し1-4 の本文が入ります。ここには見\n \n \n4 \n \n出し1-4 の本文が入ります。ここには見出し1-4 の本文が入ります。ここには見出し1-4 の\n本文が入ります。ここには見出し1-4 の本文が入ります。ここには見出し1-4 の本文が入り\nます。ここには見出し1-4 の本文が入ります。ここには見出し1-4 の本文が入ります。ここ\nには見出し1-4 の本文が入ります。 \n \n \n \n \n5 \n \n見出し2 \n \n(項目名が入ります) \n見出し2-1 ここには見出し2-1 の本文が入ります。ここには見出し2-1 の本文が入り\nます。ここには見出し2-1 の本文が入ります。ここには見出し2-1 の本文が入ります。ここ\nには見出し2-1 の本文が入ります。ここには見出し2-1 の本文が入ります。ここには見出し\n2-1 の本文が入ります。ここには見出し2-1 の本文が入ります。 \n \n(項目名が入ります) \n見出し2-2 ここには見出し2-2 の本文が入ります。ここには見出し2-2 の本文が入り\nます。ここには見出し2-2 の本文が入ります。ここには見出し2-2 の本文が入ります。ここ\nには見出し2-2 の本文が入ります。ここには見出し2-2 の本文が入ります。ここには見出し\n2-2 の本文が入ります。 \nここには見出し2-2 の本文が入ります。 \n \n以上 \n \n \n\n```\n\n---\n\n# PyMuPDFを使った表抽出\n\nPyMuPDFでは、PDF内の表をリスト形式で抽出することができます。\n\n## サンプルコード\n\n以下は、表を抽出してMarkdown形式で保存する例です：\n\n```python\nimport pymupdf\nimport os\n\ninput_pdf_path = \"./docs/読み取りテスト文書.pdf\"\noutput_txt_path = \"./output/table_extract.txt\"\n\ndef extract_tables_with_pymupdf(input_path, output_path):\n    doc = pymupdf.open(input_path)\n    for i, page in enumerate(doc, start=1):\n        tabs = page.find_tables()\n        print(f\"{len(tabs.tables)} found on {page}\")\n        if tabs.tables:\n            for table in tabs.tables:\n                extracted_text = table.to_markdown()\n\n                output_dir = os.path.dirname(output_path)\n                if not os.path.exists(output_dir):\n                    os.makedirs(output_dir)\n\n                with open(output_path, \"w\", encoding=\"utf-8\") as f:\n                    f.write(extracted_text)\n\nif __name__ == \"__main__\":\n    extract_tables_with_pymupdf(input_pdf_path, output_txt_path)\n```\n\n## 実行方法\n\nコードを `table_extract.py` として保存し、以下のコマンドで実行します：\n\n```bash\npython3 table_extract.py\n```\n\n## 結果\n\n以下のようなMarkdown形式のテーブルが出力されます：\n\n```markdown\n|列1|列2|列3|列4|\n|---|---|---|---|\n|行 1 列 1 の本文が 入ります。|行1 列 2 の本文が 入ります。|行1 列 3 の本文が 入ります。|行1 列 4 の本文が 入ります。|\n|行 2 列 1 の本文が 入ります。|行2 列 2 の本文が 入ります。|行2 列 3 の本文が 入ります。|行2 列 4 の本文が 入ります。|\n\n```\n\n---\n\n# PyMuPDF4LLMで効率化\n\nLLMやRAG向けに特化したPyMuPDFの派生ライブラリ**PyMuPDF4LLM**も非常に便利です。これを使えば、PDF全体をMarkdown形式で抽出できます。\n\n## インストール\n\n```bash\npip install pymupdf4llm\n```\n\n## サンプルコード\n\n```python\nimport pymupdf4llm\n\ninput_pdf_path = \"./docs/読み取りテスト文書.pdf\"\noutput_txt_path = \"./output/md_extract.md\"\n\ndef extract_md_with_pymupdf4llm(input_path, output_path):\n    md_text = pymupdf4llm.to_markdown(input_path)\n    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(md_text)\n\nif __name__ == \"__main__\":\n    extract_md_with_pymupdf4llm(input_pdf_path, output_txt_path)\n\n```\n\n## 実行方法\n\n以下のコマンドで実行します：\n\n```bash\npython3 md_extract.py\n```\n\n## 結果\n\nPDFの内容が見出しやテーブル付きでMarkdown形式に変換されます：\n\n```markdown\n# 文書のタイトル\n\n## 見出し1\n\n### 見出し1-1\n\nここには見出し1-1 の本文が入ります。ここには見出し1-1 の本文が入ります。ここには見\n\n出し1-1 の本文が入ります。ここには見出し1-1 の本文が入ります。ここには見出し1-1 の\n\n本文が入ります。ここには見出し1-1 の本文が入ります。ここには見出し1-1 の本文が入り\n\nます。ここには見出し1-1 の本文が入ります。ここには見出し1-1 の本文が入ります。ここ\n\nには見出し1-1 の本文が入ります。ここには見出し1-1 の本文が入ります。\n\n### 見出し1-2\n\nここには見出し1-2 の本文が入ります。ここには見出し1-2 の本文が入ります。ここには見\n\n出し1-2 の本文が入ります。ここには見出し1-2 の本文が入ります。ここには見出し1-2 の\n\n本文が入ります。ここには見出し1-2 の本文が入ります。ここには見出し1-2 の本文が入り\n\nます。\n\nここには見出し1-2 の本文が入ります。ここには見出し1-2 の本文が入ります。\n\n1\n\n-----\n\nここには見出し1-2 の本文が入ります。ここには見出し1-2 の本文が入ります。\n\n### 見出し1-3\n\nここには見出し1-3 の本文が入ります。ここには見出し1-3 の本文が入ります。\n\nここには見出し1-3 の本文が入ります。ここには見出し1-3 の本文が入ります。ここには見\n\n出し1-3 の本文が入ります。ここには見出し1-3 の本文が入ります。ここには見出し1-3 の\n\n本文が入ります。ここには見出し1-3 の本文が入ります。\n\n2\n\n-----\n\n|列1|列2|列3|列4|\n|---|---|---|---|\n|行1 列1 の本文が入 ります。|行1 列2 の本文が入 ります。|行1 列3 の本文が入 ります。|行1 列4 の本文が入 ります。|\n|行2 列1 の本文が入 ります。|行2 列2 の本文が入 ります。|行2 列3 の本文が入 ります。|行2 列4 の本文が入 ります。|\n|行3 列1 の本文が入 ります。|行3 列2 の本文が入 ります。|行3 列3 の本文が入 ります。|行3 列4 の本文が入 ります。|\n\n表1. 表1 の名前が入ります。\n\n列1 列2 列3 列4\n\n行1 列1 の本文が 行1 列2 の本文が 行1 列3 の本文が 行1 列4 の本文が\n\n入ります。 入ります。 入ります。 入ります。\n\n行2 列1 の本文が 行2 列2 の本文が 行2 列3 の本文が 行2 列4 の本文が\n\n入ります。 入ります。 入ります。 入ります。\n\n表2. 表2 の名前が入ります。\n\n### 見出し1-4\n\nここには見出し1-4 の本文が入ります。ここには見出し1-4 の本文が入ります。ここには見\n\n3\n\n|列1|列2|列3|列4|\n|---|---|---|---|\n|行 1 列 1 の本文が 入ります。|行1 列 2 の本文が 入ります。|行1 列 3 の本文が 入ります。|行1 列 4 の本文が 入ります。|\n|行 2 列 1 の本文が 入ります。|行2 列 2 の本文が 入ります。|行2 列 3 の本文が 入ります。|行2 列 4 の本文が 入ります。|\n\n-----\n\n出し1-4 の本文が入ります。ここには見出し1-4 の本文が入ります。ここには見出し1-4 の\n\n本文が入ります。ここには見出し1-4 の本文が入ります。ここには見出し1-4 の本文が入り\n\nます。ここには見出し1-4 の本文が入ります。ここには見出し1-4 の本文が入ります。ここ\n\nには見出し1-4 の本文が入ります。\n\n4\n\n-----\n\n## 見出し2\n\n(項目名が入ります)\n\n### 見出し2-1 ここには見出し2-1 の本文が入ります。ここには見出し2-1 の本文が入り\n\nます。ここには見出し2-1 の本文が入ります。ここには見出し2-1 の本文が入ります。ここ\n\nには見出し2-1 の本文が入ります。ここには見出し2-1 の本文が入ります。ここには見出し\n\n2-1 の本文が入ります。ここには見出し2-1 の本文が入ります。\n\n(項目名が入ります)\n\n### 見出し2-2 ここには見出し2-2 の本文が入ります。ここには見出し2-2 の本文が入り\n\nます。ここには見出し2-2 の本文が入ります。ここには見出し2-2 の本文が入ります。ここ\n\nには見出し2-2 の本文が入ります。ここには見出し2-2 の本文が入ります。ここには見出し\n\n2-2 の本文が入ります。\n\nここには見出し2-2 の本文が入ります。\n\n以上\n\n5\n\n-----\n\n```\n\n---\n\n## PyMuPDFのメリットと活用方法\n\n- **テキストと表を統合的に扱える**。\n- **高速かつ効率的**に処理可能。\n- **Markdown形式での出力**に対応しており、RAGやLLMに最適。\n\nPyMuPDFを活用して、PDFデータの前処理を効率化し、プロジェクトの生産性を向上させましょう！\n\n---\n\n","updatedAt":"2025-06-02T02:49:26.645Z","tags":[{"id":20,"documentId":"fbllyhmskvu2l7wbg5dzpkri","createdAt":"2025-05-19T09:48:50.341Z","updatedAt":"2025-05-19T09:48:50.341Z","publishedAt":"2025-05-19T09:48:50.348Z","name":"LLM"},{"id":22,"documentId":"enpfq0z697dadtxijwpwwrsv","createdAt":"2025-05-19T09:49:17.862Z","updatedAt":"2025-05-19T09:49:17.862Z","publishedAt":"2025-05-19T09:49:17.870Z","name":"Python"},{"id":24,"documentId":"l1dya7wtq2ct0n1dxm41pl7j","createdAt":"2025-05-19T09:49:40.953Z","updatedAt":"2025-05-19T09:49:40.953Z","publishedAt":"2025-05-19T09:49:40.961Z","name":"RAG"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_19_a28071974b.png"}},{"id":207,"documentId":"g8z0fn5ap0si8r1iheg2iwd7","title":"【PDF操作比較】pdfplumberでPDFからテキストも表も簡単抽出","content":"PDF操作ライブラリの比較検討記事の続きです。\n\n前回の記事はこちら\n\n- [【PDF操作比較】pypdfでPDFからテキスト抽出を行う方法](https://my-blog-frontend-jectjhrfq-raisex-hyamasakis-projects.vercel.app/articles/i402h46inwv9yzy1mgah101z)\n\nPDFファイルから**テキスト**や**表データ**を抽出する作業は、データ前処理において重要な役割を果たします。特に、**LLM（大規模言語モデル）のチューニング**や**RAG（Retrieval-Augmented Generation）の文書前処理**では、PDFデータの扱いやすさが効率を左右します。\n\n今回ご紹介するのは、Pythonライブラリの**pdfplumber**を使ったテキストと表データの抽出方法です。このライブラリは、テキストだけでなく複雑な表形式データにも対応しており、非常に便利です！\n\n---\n\n## pdfplumberの概要\n\n**pdfplumber**は、PDFから以下のようなデータを簡単に抽出できるライブラリです：\n\n- テキスト\n- 表（表形式データ）\n- 画像や図\n\n---\n\n# pdfplumberの基本的な使い方\n\n以下では、**テキスト抽出**と**表抽出**の方法をそれぞれ紹介します。\n\nPDFは前回の記事で使ったものと同じものを使います。\n\n---\n\n## テキストの抽出\n\n### 必要な準備\n\nまずは、pdfplumberをインストールします。\n\n```bash\npip install pdfplumber\n```\n\n### テキスト抽出のコード例\n\n以下のコードを使えば、PDFからテキストを抽出してファイルに保存できます。\n\n```python\nimport os\nimport pdfplumber\n\ninput_pdf_path = \"./docs/読み取りテスト文書.pdf\"\noutput_txt_path = \"./output/text_extract.txt\"\n\ndef extract_text_with_pdfplumber(input_path, output_path):\n    try:\n        with pdfplumber.open(input_path) as pdf:\n            extracted_text = \"\"\n\n            for page in pdf.pages:\n                extracted_text += page.extract_text()\n\n        output_dir = os.path.dirname(output_path)\n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n\n        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(extracted_text)\n\n        print(f\"テキストが正常に抽出され、以下のファイルに保存されました: {output_path}\")\n    except Exception as e:\n        print(f\"エラーが発生しました: {e}\")\n\nif __name__ == \"__main__\":\n    extract_text_with_pdfplumber(input_pdf_path, output_txt_path)\n\n```\n\n### 実行方法\n\nコードを `text_extract.py` というファイル名で保存し、以下のコマンドで実行します：\n\n```bash\npython3 text_extract.py\n```\n\n### 結果\n\n実際にPDFから抽出したテキストは以下のようになります：\n\n```\n文書のタイトル\n見出し 1\n見出し 1-1\nここには見出し1-1の本文が入ります。ここには見出し1-1の本文が入ります。ここには見\n出し1-1の本文が入ります。ここには見出し1-1の本文が入ります。ここには見出し1-1の\n本文が入ります。ここには見出し1-1の本文が入ります。ここには見出し1-1の本文が入り\nます。ここには見出し1-1の本文が入ります。ここには見出し1-1の本文が入ります。ここ\nには見出し1-1の本文が入ります。ここには見出し1-1の本文が入ります。\n見出し 1-2\nここには見出し1-2の本文が入ります。ここには見出し1-2の本文が入ります。ここには見\n出し1-2の本文が入ります。ここには見出し1-2の本文が入ります。ここには見出し1-2の\n本文が入ります。ここには見出し1-2の本文が入ります。ここには見出し1-2の本文が入り\nます。\nここには見出し1-2の本文が入ります。ここには見出し1-2の本文が入ります。\n1ここには見出し1-2の本文が入ります。ここには見出し1-2の本文が入ります。\n見出し 1-3\nここには見出し1-3の本文が入ります。ここには見出し1-3の本文が入ります。\nここには見出し1-3の本文が入ります。ここには見出し1-3の本文が入ります。ここには見\n出し1-3の本文が入ります。ここには見出し1-3の本文が入ります。ここには見出し1-3の\n本文が入ります。ここには見出し1-3の本文が入ります。\n2列1 列2 列3 列4\n行1列1の本文が入 行1列2の本文が入 行1列3の本文が入 行1列4の本文が入\nります。 ります。 ります。 ります。\n行2列1の本文が入 行2列2の本文が入 行2列3の本文が入 行2列4の本文が入\nります。 ります。 ります。 ります。\n行3列1の本文が入 行3列2の本文が入 行3列3の本文が入 行3列4の本文が入\nります。 ります。 ります。 ります。\n表1. 表1の名前が入ります。\n列1 列2 列3 列4\n行 1列 1の本文が 行1列 2の本文が 行1列 3の本文が 行1列 4の本文が\n入ります。 入ります。 入ります。 入ります。\n行 2列 1の本文が 行2列 2の本文が 行2列 3の本文が 行2列 4の本文が\n入ります。 入ります。 入ります。 入ります。\n表2. 表2の名前が入ります。\n見出し 1-4\nここには見出し1-4の本文が入ります。ここには見出し1-4の本文が入ります。ここには見\n3出し1-4の本文が入ります。ここには見出し1-4の本文が入ります。ここには見出し1-4の\n本文が入ります。ここには見出し1-4の本文が入ります。ここには見出し1-4の本文が入り\nます。ここには見出し1-4の本文が入ります。ここには見出し1-4の本文が入ります。ここ\nには見出し1-4の本文が入ります。\n4見出し 2\n(項目名が入ります)\n見出し 2-1\nここには見出し2-1の本文が入ります。ここには見出し2-1の本文が入り\nます。ここには見出し2-1の本文が入ります。ここには見出し2-1の本文が入ります。ここ\nには見出し2-1の本文が入ります。ここには見出し2-1の本文が入ります。ここには見出し\n2-1の本文が入ります。ここには見出し2-1の本文が入ります。\n(項目名が入ります)\n見出し 2-2\nここには見出し2-2の本文が入ります。ここには見出し2-2の本文が入り\nます。ここには見出し2-2の本文が入ります。ここには見出し2-2の本文が入ります。ここ\nには見出し2-2の本文が入ります。ここには見出し2-2の本文が入ります。ここには見出し\n2-2の本文が入ります。\nここには見出し2-2の本文が入ります。\n以上\n5\n```\n\nこのように、PDFのレイアウトに沿ったテキストが抽出されます。\n\n---\n\n## 表の抽出\n\npdfplumberでは表の内容をリスト形式で取り出せるため、後続処理が簡単です。\n\n### 表抽出のコード例\n\n次のコードは、PDFから表を抽出し、タブ区切り形式でファイルに保存する例です。\n\n```python\nimport os\nimport pdfplumber\n\ninput_pdf_path = \"./docs/読み取りテスト文書.pdf\"\noutput_txt_path = \"./output/table_extract.txt\"\n\ndef extract_tables_with_pdfplumber(input_path, output_path):\n    try:\n        with pdfplumber.open(input_path) as pdf:\n            extracted_table = \"\"\n\n            for i, page in enumerate(pdf.pages, start=1):\n                tables = page.extract_tables()\n                if tables:\n                    for table in tables:\n                        for row in table:\n                            extracted_table += \"\\t\".join(row) + \"\\n\"\n                        extracted_table += \"\\n\"  # テーブル間に空行を追加\n\n        output_dir = os.path.dirname(output_path)\n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n\n        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(extracted_table)\n\n        print(f\"テーブルデータが正常に抽出され、以下のファイルに保存されました: {output_path}\")\n    except Exception as e:\n        print(f\"エラーが発生しました: {e}\")\n\n# 実行\nif __name__ == \"__main__\":\n    extract_tables_with_pdfplumber(input_pdf_path, output_txt_path)\n\n```\n\n### 実行方法\n\nコードを `table_extract.py` として保存し、以下のコマンドで実行します：\n\n```bash\npython3 table_extract.py\n```\n\n### 結果\n\n抽出した表の例：\n\n```\n列1\t列2\t列3\t列4\n行1列1の本文が入\nります。\t行1列2の本文が入\nります。\t行1列3の本文が入\nります。\t行1列4の本文が入\nります。\n行2列1の本文が入\nります。\t行2列2の本文が入\nります。\t行2列3の本文が入\nります。\t行2列4の本文が入\nります。\n行3列1の本文が入\nります。\t行3列2の本文が入\nります。\t行3列3の本文が入\nります。\t行3列4の本文が入\nります。\n\n列1\t列2\t列3\t列4\n行 1列 1の本文が\n入ります。\t行1列 2の本文が\n入ります。\t行1列 3の本文が\n入ります。\t行1列 4の本文が\n入ります。\n行 2列 1の本文が\n入ります。\t行2列 2の本文が\n入ります。\t行2列 3の本文が\n入ります。\t行2列 4の本文が\n入ります。\n\n```\n\nこのように、PDFの表が整った形式で抽出されます。\n\n---\n\n### 3. 抽出データの後処理\n\npdfplumberで抽出した表データは、リスト形式で取得されます。このデータをさらに加工する場合、**pandas**を活用すると便利です。\n\n### PandasでのExcel出力例\n\n```python\nimport pandas as pd\n\n# 抽出した表データをリスト形式にする（例）\ndata = [\n    [\"列1\", \"列2\", \"列3\", \"列4\"],\n    [\"行1列1\", \"行1列2\", \"行1列3\", \"行1列4\"],\n    [\"行2列1\", \"行2列2\", \"行2列3\", \"行2列4\"]\n]\n\n# データフレームとして作成\ndf = pd.DataFrame(data[1:], columns=data[0])\n\n# Excelファイルとして保存\ndf.to_excel(\"./output/extracted_table.xlsx\", index=False)\nprint(\"表データがExcelファイルに保存されました！\")\n\n```\n\n---\n\n## pdfplumberの活用ポイント\n\n1. **テキスト抽出に加え、表データも簡単に処理可能**。\n2. **後続処理との組み合わせが簡単**（例：pandasでExcel出力）。\n3. **複雑なレイアウトでも精度高く抽出**。\n\n---\n\nこれで、PDFからテキストや表を抽出する方法はバッチリです！ぜひ、pdfplumberを使って、プロジェクトの効率化に役立ててください。\n\n次はPyMuPDFのライブラリについても調べていきます。更新をお楽しみに！\n\n---\n\n","updatedAt":"2025-06-02T00:22:22.052Z","tags":[{"id":20,"documentId":"fbllyhmskvu2l7wbg5dzpkri","createdAt":"2025-05-19T09:48:50.341Z","updatedAt":"2025-05-19T09:48:50.341Z","publishedAt":"2025-05-19T09:48:50.348Z","name":"LLM"},{"id":22,"documentId":"enpfq0z697dadtxijwpwwrsv","createdAt":"2025-05-19T09:49:17.862Z","updatedAt":"2025-05-19T09:49:17.862Z","publishedAt":"2025-05-19T09:49:17.870Z","name":"Python"},{"id":24,"documentId":"l1dya7wtq2ct0n1dxm41pl7j","createdAt":"2025-05-19T09:49:40.953Z","updatedAt":"2025-05-19T09:49:40.953Z","publishedAt":"2025-05-19T09:49:40.961Z","name":"RAG"},{"id":30,"documentId":"d99cu6c3t9hgwynppb92lhph","createdAt":"2025-05-19T09:50:59.080Z","updatedAt":"2025-05-19T09:50:59.080Z","publishedAt":"2025-05-19T09:50:59.086Z","name":"生成AI"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_18_7f8d875b8b.png"}},{"id":206,"documentId":"i402h46inwv9yzy1mgah101z","title":"【PDF操作比較】pypdfでPDFからテキスト抽出を行う方法","content":"PDF形式の文書は情報共有や保存に便利ですが、その中のテキストデータを直接操作したい場合、少々手間がかかることがあります。特に、**LLM（大規模言語モデル）のチューニングデータ作成**や、**RAG（Retrieval-Augmented Generation）の文書前処理**では、PDFデータのテキスト抽出が不可欠です。\n\nそこで、この記事では **PythonのPDF操作ライブラリ「pypdf」**を使って、PDFからテキストを抽出する方法を詳しく解説します。\n\n---\n\n# PDF操作ライブラリの選定\n\nPDFのテキストや表を抽出する為のライブラリは複数存在します。比較するのは以下の3つです：\n\n- **pypdf**：軽量でシンプルなPDF操作ライブラリ。テキスト抽出機能を備えています。\n- **pdfplumber**：表や図なども抽出できる高機能ライブラリ。\n- **PyMuPDF（fitz）**：高速かつ多機能なライブラリで、テキスト抽出やPDF編集が可能。\n\n今回は、軽量で簡単に扱える**pypdf**にフォーカスして、基本的な使い方をご紹介します。\n\n---\n\n# pypdfでPDFテキスト抽出を試してみよう！\n\nまずは、簡単なテスト用PDFを用意しましょう。ここでは、Wordで文書を作成し、PDF形式で保存したファイルを使用します。\n\n[読み取りテスト文書.pdf](https://my-blog-frontend-two.vercel.app/docs/読み取りテスト文書.pdf)\n\n# 必要な準備\n\n## pypdfのインストール\n\npypdfはPythonのライブラリとして簡単にインストール可能です。以下のコマンドを実行してください：\n\n```bash\npip install pypdf\n\n```\n\n## 使用するソースコード\n\n以下のPythonコードを使えば、指定したPDFからテキストを抽出し、テキストファイルとして保存することができます。\n\n```python\nimport os\nfrom PyPDF2 import PdfReader\n\ninput_pdf_path = \"./docs/読み取りテスト文書.pdf\"\noutput_txt_path = \"./output/text_extract.txt\"\n\ndef extract_text_from_pdf(input_path, output_path):\n    try:\n        reader = PdfReader(input_path)\n\n        extracted_text = \"\"\n        for page in reader.pages:\n            extracted_text += page.extract_text()\n\n        output_dir = os.path.dirname(output_path)\n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n\n        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(extracted_text)\n\n        print(f\"テキストが正常に抽出され、以下のファイルに保存されました: {output_path}\")\n    except Exception as e:\n        print(f\"エラーが発生しました: {e}\")\n\nif __name__ == \"__main__\":\n    extract_text_from_pdf(input_pdf_path, output_txt_path)\n```\n\n---\n\n## 実行方法\n\n1. 上記コードを `text_extract.py` という名前で保存します。\n2. ターミナルやコマンドプロンプトで以下のコマンドを実行します：\n\n```bash\npython3 text_extract.py\n```\n\nこれで、指定したPDFファイルからテキストが抽出され、`output/text_extract.txt` に保存されます。\n\n---\n\n## 実行結果\n\n実際にPDFを読み取った結果は以下の通りです：\n\n```\n   \n \n 1  \n 文書のタイトル  \n見出し 1 \n \n見出し 1-1 \nここには見出し 1-1の本文が入ります。ここには見出し 1-1の本文が入ります。ここには見\n出し1-1の本文が入ります。 ここには見出し 1-1の本文が入ります。 ここには見出し 1-1の\n本文が入ります。ここには見出し 1-1の本文が入ります。ここには見出し 1-1の本文が入り\nます。ここには見出し 1-1の本文が入ります。ここには見出し 1-1の本文が入ります。ここ\nには見出し 1-1の本文が入ります。ここには見出し 1-1の本文が入ります。  \n \n見出し 1-2 \nここには見出し 1-2の本文が入ります。ここには見出し 1-2の本文が入ります。ここには見\n出し1-2の本文が入ります。 ここには見出し 1-2の本文が入ります。 ここには見出し 1-2の\n本文が入ります。ここには見出し 1-2の本文が入ります。ここには見出し 1-2の本文が入り\nます。  \nここには見出し 1-2の本文が入ります。ここには見出し 1-2の本文が入ります。     \n \n 2  \n ここには見出し 1-2の本文が入ります。ここには見出し 1-2の本文が入ります。  \n \n見出し 1-3 \nここには見出し 1-3の本文が入ります。ここには見出し 1-3の本文が入ります。  \nここには見出し 1-3の本文が入ります。ここには見出し 1-3の本文が入ります。ここには見\n出し1-3の本文が入ります。 ここには見出し 1-3の本文が入ります。 ここには見出し 1-3の\n本文が入ります。ここには見出し 1-3の本文が入ります。  \n     \n \n 3  \n 列1 列2 列3 列4 \n行1列1の本文が入\nります。  行1列2の本文が入\nります。  行1列3の本文が入\nります。  行1列4の本文が入\nります。  \n行2列1の本文が入\nります。  行2列2の本文が入\nります。  行2列3の本文が入\nります。  行2列4の本文が入\nります。  \n行3列1の本文が入\nります。  行3列2の本文が入\nります。  行3列3の本文が入\nります。  行3列4の本文が入\nります。  \n表1. 表1の名前が入ります。  \n \n列1 列2 列3 列4 \n行1列1の本文が\n入ります。  行1列2の本文が\n入ります。  行1列3の本文が\n入ります。  行1列4の本文が\n入ります。  \n行2列1の本文が\n入ります。  行2列2の本文が\n入ります。  行2列3の本文が\n入ります。  行2列4の本文が\n入ります。  \n表2. 表2の名前が入ります。  \n見出し 1-4 \nここには見出し 1-4の本文が入ります。ここには見出し 1-4の本文が入ります。ここには見   \n \n 4  \n 出し1-4の本文が入ります。 ここには見出し 1-4の本文が入ります。 ここには見出し 1-4の\n本文が入ります。ここには見出し 1-4の本文が入ります。ここには見出し 1-4の本文が入り\nます。ここには見出し 1-4の本文が入ります。ここには見出し 1-4の本文が入ります。ここ\nには見出し 1-4の本文が入ります。  \n     \n \n 5  \n 見出し 2 \n \n(項目名が入ります ) \n見出し 2-1 ここには見出し 2-1の本文が入ります。 ここには見出し 2-1の本文が入り\nます。ここには見出し 2-1の本文が入ります。ここには見出し 2-1の本文が入ります。ここ\nには見出し 2-1の本文が入ります。ここには見出し 2-1の本文が入ります。ここには見出し\n2-1の本文が入ります。ここには見出し 2-1の本文が入ります。  \n \n(項目名が入ります ) \n見出し 2-2 ここには見出し 2-2の本文が入ります。 ここには見出し 2-2の本文が入り\nます。ここには見出し 2-2の本文が入ります。ここには見出し 2-2の本文が入ります。ここ\nには見出し 2-2の本文が入ります。ここには見出し 2-2の本文が入ります。ここには見出し\n2-2の本文が入ります。  \nここには見出し 2-2の本文が入ります。  \n \n以上 \n \n \n```\n\nシンプルなPDFなら問題なく読み取れることが分かります。\n\n---\n\n## pypdfの特徴と限界\n\n### メリット\n\n- **軽量で高速**：小規模なPDF処理に最適。\n- **簡単なインストールと利用方法**：コードもシンプルでわかりやすい。\n- **オープンソース**：自由にカスタマイズ可能。\n\n### デメリット\n\n- **表や図の抽出は苦手**：pypdfはテキストの抽出には強いものの、複雑なレイアウトや表形式のデータには非対応です。\n\n---\n\n今回の内容をもとに、ぜひpypdfを活用してみてください！あなたのプロジェクトが一歩進む手助けになれば幸いです。\n\npdfplumberとPyMuPDFのライブラリについても調べていきます。更新をお楽しみに。\n\n---\n\n","updatedAt":"2025-06-02T00:20:03.600Z","tags":[{"id":20,"documentId":"fbllyhmskvu2l7wbg5dzpkri","createdAt":"2025-05-19T09:48:50.341Z","updatedAt":"2025-05-19T09:48:50.341Z","publishedAt":"2025-05-19T09:48:50.348Z","name":"LLM"},{"id":22,"documentId":"enpfq0z697dadtxijwpwwrsv","createdAt":"2025-05-19T09:49:17.862Z","updatedAt":"2025-05-19T09:49:17.862Z","publishedAt":"2025-05-19T09:49:17.870Z","name":"Python"},{"id":24,"documentId":"l1dya7wtq2ct0n1dxm41pl7j","createdAt":"2025-05-19T09:49:40.953Z","updatedAt":"2025-05-19T09:49:40.953Z","publishedAt":"2025-05-19T09:49:40.961Z","name":"RAG"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_17_1910dde1ca.png"}},{"id":204,"documentId":"n0263l12z36kcio7a5x2djsg","title":"【Ollama】ローカルでLLMを動かしてみよう！","content":"AIの進化に伴い、ローカル環境でLLM（大規模言語モデル）を利用することが注目されています。その中でも、Metaが提供する **Ollama** は非常に手軽でパワフルなツールです。\n\nこの記事では、Ollamaを使ってローカル環境でLLMを実行する方法や、その魅力について紹介します。\n\n---\n\n## Ollamaって何？\n\nOllamaは、ローカルでLLMを動作させるためのプラットフォームです。これにより、インターネット接続が不要な環境でもAIを活用でき、プライバシーの面でも安心です。また、ローカル実行のため応答速度が非常に速いのが特徴です。\n\n公式リポジトリはこちら → [Ollama GitHub](https://github.com/ollama/ollama)\n\n---\n\n## 必要なスペックは？\n\nREADMEによると以下のメモリが推奨されています：\n\n```\nYou should have at least 8 GB of RAM available to run the 7B models, 16 GB to run the 13B models, and 32 GB to run the 33B models.\n```\n\n例えば、16GBメモリ搭載のM2 MacBook Proであれば、**7Bモデル**を快適に実行できます。\n\n---\n\n## インストール方法\n\n※Macでの手順です。\n\n1. **公式サイトからインストーラーをダウンロード**\n→ [ダウンロードページ](https://ollama.com/download)\n2. ダウンロードしたZIPファイルを解凍し、アプリケーションフォルダにドラッグ＆ドロップ。\n3. アプリを起動してセットアップを進めます。\n\nセットアップ画面は非常に直感的で、クリックするだけで完了します。以下に画面キャプチャも掲載しておきます。\n\n### スクリーンショット\n\n- 起動直後\n    \n    ![スクリーンショット](https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/2024_12_28_14_38_27_ea32a8eefe.png)\n    \n- インストール中\n    \n    ![スクリーンショット](https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/2024_12_28_14_39_34_b7d049d148.png\n)\n    \n- コマンドラインのインストール完了\n    \n    ![スクリーンショット](https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/2024_12_28_14_40_13_dc5f32b781.png)\n\n---\n\n## モデルのロードと実行\n\nインストール後、コマンドラインからモデルを操作します。以下は実際の手順です。\n\n### 1. インストール確認\n\nまずはインストールされたバージョンを確認。\n\n```bash\nollama --version\nollama version is 0.5.4\n```\n\n### 2. モデルをロード\n\nここでは `llama3.2` をロードしてみます。\n\n```bash\nollama run llama3.2\n```\n\nロード中はモデルデータをダウンロードします。ダウンロードが完了すれば、すぐに使用可能です。\n\n---\n\n## 実際にチャットをしてみる\n\nモデルが起動したら、チャットを始められます。以下はサンプルのやり取りです。\n\n```bash\n\u003e\u003e\u003e hello llama.\nHello! It's nice to meet you. I hope you're having a great day! Is there anything I can help you with or would you like to chat?\n\n```\n\n日本語でのやり取りも可能です。\n\n```bash\n\u003e\u003e\u003e 日本語で回答してください。大晦日の過し方のアイデアください。\n大晦日は、日本では12月31日を表す日です。この日は、年の余りを振り返って、新しい年が始まる前夜に過ごすためによく行われています。...\n\n```\n\nモデルによって日本語の精度は異なりますが、実用レベルで十分なレスポンスを得られます。\n\n---\n\n## 使用モデルごとの特徴とメモリ使用量\n\n以下にいくつかのモデルを試した結果をまとめました。\n\n| モデル | メモリ使用量 | 日本語対応 | 特徴 |\n| --- | --- | --- | --- |\n| llama3.2 | 約13GB | 良い | 応答速度が速く、会話が自然 |\n| mistral | 約15GB | 普通 | 日本語の文法や内容がやや怪しい |\n| gemma | 約15GB | 良い | 日本語の精度が高く自然 |\n\n---\n\n## コマンドの便利な使い方\n\n- **ヘルプを表示**\n    \n    `\u003e\u003e\u003e /?` で利用可能なコマンド一覧を確認。\n    \n- **モデル情報を表示**\n    \n    `\u003e\u003e\u003e /show info` で現在ロードしているモデルの詳細を確認。\n    \n- **セッションを終了**\n    \n    `\u003e\u003e\u003e /bye` でセッションを終了。\n    \n\n---\n\n## Ollamaを使うメリット\n\n1. **セキュリティ**\n    \n    モデルをローカルにロードするため、データが外部に流出する心配がありません。\n    \n2. **コスト**\n    \n    クラウドサービスを利用しないため、運用コストを抑えられます。\n    \n3. **スピード**\n    \n    ローカル環境での推論なので、応答速度が非常に速いです。\n    \n4. **モデル切り替えが簡単**\n    \n    コマンド一つで複数のモデルを試せるのは大きな魅力です。\n    \n\n---\n\n## まとめ\n\nOllamaを使えば、手軽にローカル環境でLLMを活用できます。特に、セキュリティやコストが気になるプロジェクトでの利用に最適です。日本語対応やメモリ使用量など、いくつか注意点はありますが、個人利用から業務用途まで幅広く活用できるツールです。\n\nぜひ一度試してみてください！\n\n---\n\n\n\n","updatedAt":"2025-06-02T00:02:35.161Z","tags":[{"id":20,"documentId":"fbllyhmskvu2l7wbg5dzpkri","createdAt":"2025-05-19T09:48:50.341Z","updatedAt":"2025-05-19T09:48:50.341Z","publishedAt":"2025-05-19T09:48:50.348Z","name":"LLM"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_16_ac3c5b1da2.png"}},{"id":203,"documentId":"nyg7h5f0xw60bpk88glrh4zo","title":"LLMファインチューニングのチュートリアル","content":"近年、自然言語処理（NLP）の分野では大規模言語モデル（LLM）の活用が急速に進んでいます。特に、特定のタスク向けにモデルの性能を向上させる「ファインチューニング」は、プロジェクトでの需要が増えつつあります。\n\n本記事では、初心者の方でも理解しやすいように、ファインチューニングの基本的な流れを体験できるチュートリアルを用意しました。\n\n---\n\n# 環境設定と事前準備\n\nこのチュートリアルは、macOS環境（例: M2 MacBook Pro）をベースにしています。以下のコマンドで仮想環境を作成し、必要なライブラリをインストールしましょう。\n\n### 仮想環境のセットアップ\n\n```bash\npython -m venv .env\nsource .env/bin/activate\n```\n\n### 必要なライブラリのインストール\n\n以下のコマンドを実行して、必要なPythonライブラリをインストールします。\n\n```bash\npip install transformers datasets evaluate accelerate scikit-learn torch\n\n```\n\n### 動作確認\n\nライブラリが正しくインストールされたか確認するために、以下のテストコードを実行します。\n\n```bash\npython -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))\"\n\n```\n\n期待される出力：\n\n```bash\n[{'label': 'POSITIVE', 'score': 0.9998704195022583}]\n\n```\n---\n\n# ファインチューニングスクリプトの作成と実行\n\nファインチューニングの手順を示したPythonスクリプト（`finetune.py`）を以下に示します。このスクリプトでは、[Yelpレビューのデータセット](https://huggingface.co/datasets/Yelp/yelp_review_full)を使用します。\n\n### `finetune.py`\n\n```python\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\nimport numpy as np\nimport evaluate\n\n# データセットの準備\ndataset = load_dataset(\"yelp_review_full\")\n\n# トークナイザーによるトークナイズ\ntokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\n\n# 学習データとテストデータ作成\nsmall_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(500))\nsmall_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(500))\n\n# モデルのロード\nmodel = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\", num_labels=5, torch_dtype=\"auto\")\n\n# 評価関数\nmetric = evaluate.load(\"accuracy\")\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)\n\n# 学習設定\ntraining_args = TrainingArguments(output_dir=\"test_trainer\", eval_strategy=\"epoch\")\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=small_train_dataset,\n    eval_dataset=small_eval_dataset,\n    compute_metrics=compute_metrics,\n)\n\n# 学習の実行\ntrainer.train()\n\n# モデルとトークナイザーの保存\nsave_dir = './finetuned/bert-base-cased'\ntokenizer.save_pretrained(save_dir)\nmodel.save_pretrained(save_dir)\n```\n\n### 実行結果\n\nスクリプトを実行すると、以下のような評価結果が表示されます。\n\n```bash\npython3 finetune.py\n\n{'eval_loss': 1.5970934629440308, 'eval_accuracy': 0.242, 'eval_runtime': 39.0603, 'eval_samples_per_second': 12.801, 'eval_steps_per_second': 1.613, 'epoch': 1.0}                                                                               \n{'eval_loss': 1.468526840209961, 'eval_accuracy': 0.346, 'eval_runtime': 36.1194, 'eval_samples_per_second': 13.843, 'eval_steps_per_second': 1.744, 'epoch': 2.0}                                                                                \n{'eval_loss': 1.4037985801696777, 'eval_accuracy': 0.368, 'eval_runtime': 35.7517, 'eval_samples_per_second': 13.985, 'eval_steps_per_second': 1.762, 'epoch': 3.0}                                                                               \n{'train_runtime': 467.6126, 'train_samples_per_second': 3.208, 'train_steps_per_second': 0.404, 'train_loss': 1.5324497121982474, 'epoch': 3.0}                                                                                                   \n100%|██████████████████████████████████████████████████████████████████████████████████| 189/189 [07:47\u003c00:00,  2.47s/it]\n```\n\n---\n\n## ファインチューニングスクリプトの解説\n\n以下は、ファインチューニングスクリプト `finetune.py` の各パートを詳しく解説しまとめたものです。\n\n---\n\n### 1. データセットのロード\n\n```python\ndataset = load_dataset(\"yelp_review_full\")\n```\n\n### 解説：\n\n- Hugging Faceの`datasets`ライブラリを使用して、Yelpのレビューコメントデータセットをロードします。このデータセットにはレビューコメントと1~5の評価スコアが含まれています。\n\n### ポイント：\n\n- **データセットの種類**：Hugging Faceの`load_dataset`を使えば、豊富な事前構築データセットに簡単にアクセス可能。\n- **カスタムデータの利用**：自分のデータを使いたい場合、CSVやJSON形式で読み込むことも可能です。\n\n---\n\n### 2. トークナイズ\n\n```python\ntokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\n```\n\n### 解説：\n\n- トークナイザーを使ってテキストを数値データに変換します。これにより、モデルが扱える形式に整えられます。\n- `padding=\"max_length\"`で固定長の入力に揃え、`truncation=True`で最大トークン数を超えた部分をカットします。\n\n### ポイント：\n\n- **トークナイザーの選択**：モデルに対応するトークナイザーを使用することが重要（例: BERTモデルならBERT用のトークナイザー）。\n- **効率化**：`batched=True`を指定することで、複数のデータを一度にトークナイズして処理速度を向上。\n\n---\n\n### 3. データの分割と縮小\n\n```python\nsmall_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(500))\nsmall_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(500))\n\n```\n\n### 解説：\n\n- 訓練データと評価データを分割し、ファインチューニング用にサブセット（500件）を作成します。\n- `shuffle(seed=42)`はデータをランダムに並び替えますが、同じ結果を再現するためシード値を設定しています。\n\n### ポイント：\n\n- **データサイズの調整**：学習時間やリソースの制約に合わせてデータサイズを選択できます。\n- **小規模学習のメリット**：小規模データでもモデルの動作確認や理解が可能。\n\n---\n\n### 4. モデルのロード\n\n```python\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"google-bert/bert-base-cased\",\n    num_labels=5,\n    torch_dtype=\"auto\"\n)\n```\n\n### 解説：\n\n- Hugging Faceから事前学習済みのBERTモデルをロードし、分類タスク用に調整します。\n- `num_labels=5`は分類クラスの数（Yelpの評価スコア1~5）を指定しています。\n\n### ポイント：\n\n- **事前学習モデルの再利用**：大規模な事前学習済みモデルを活用することで、少ないデータでも良い結果が得られる。\n- **モデルのカスタマイズ**：分類クラス数や出力層を調整して特定のタスクに適応。\n\n---\n\n### 5. 評価関数の設定\n\n```python\nmetric = evaluate.load(\"accuracy\")\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)\n```\n\n### 解説：\n\n- `evaluate`ライブラリを使用して、モデルの精度（accuracy）を評価する関数を定義しています。\n- 推論結果（`logits`）を`argmax`で予測ラベルに変換し、実際のラベルと比較してスコアを計算します。\n\n### ポイント：\n\n- **評価指標の選択**：分類タスクでは`accuracy`が一般的ですが、タスクに応じて`precision`や`recall`も検討すべきです。\n- **簡単な実装**：`evaluate`ライブラリを使うと、一般的な評価指標を簡単に利用可能。\n\n---\n\n### 6. 学習設定\n\n```python\ntraining_args = TrainingArguments(\n    output_dir=\"test_trainer\",\n    eval_strategy=\"epoch\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=small_train_dataset,\n    eval_dataset=small_eval_dataset,\n    compute_metrics=compute_metrics,\n)\n\n```\n\n### 解説：\n\n- `TrainingArguments`で学習パラメータを指定します。ここでは、モデル保存先（`output_dir`）と評価タイミング（`eval_strategy=\"epoch\"`）を設定。\n- `Trainer`クラスは、学習プロセスを簡略化するための高レベルAPIです。\n\n### ポイント：\n\n- **簡単な学習管理**：`Trainer`を使うと、ループの作成や勾配計算の実装を気にする必要がありません。\n- **設定の柔軟性**：学習率やバッチサイズなどの詳細設定も可能です。\n\n---\n\n### 7. モデルの保存\n\n```python\ntokenizer.save_pretrained('./finetuned/bert-base-cased')\nmodel.save_pretrained('./finetuned/bert-base-cased')\n```\n\n### 解説：\n\n- ファインチューニング後のトークナイザーとモデルを保存します。この保存済みモデルは、将来的に推論やさらなる調整に使用できます。\n\n### ポイント：\n\n- **再利用性の向上**：モデルを保存しておくことで、他のプロジェクトやデプロイメントに活用可能。\n- **Hugging Face互換**：保存形式はHugging Faceライブラリでの再利用に最適化されています。\n\n---\n\n## チューニング前後のモデル性能比較\n\nファインチューニングによる効果を確認するため、同じ入力データを使ってモデルの予測結果を比較します。\n\n### チューニング前のモデルで推論\n\n以下のスクリプトで推論を行います。\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport numpy as np\n\nmodel_path = 'google-bert/bert-base-cased'\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path)\n\ntext = \"I visit this bar at first time. Service is good. Making drinks and talking with Bartender is also good. I spend good 2 hours. I will come again next month.\"\ninputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\noutputs = model(**inputs)\npredicted_class = np.argmax(outputs.logits.detach().numpy(), axis=-1)\nprint(predicted_class)\n\n```\n\n出力結果：\n\n```bash\n[0] # 配列なので0始まり。0は評価1。\n```\n\ninputのtextからは4か5の高評価を期待しますが、評価が「1」となりました。\n\n### チューニング後のモデルで推論\n\n同じテキストを以下のスクリプトで推論します。\n\n```python\nmodel_path = './finetuned/bert-base-cased'\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path)\n\ntext = \"I visit this bar at first time. Service is good. Making drinks and talking with Bartender is also good. I spend good 2 hours. I will come again next month.\"\ninputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\noutputs = model(**inputs)\npredicted_class = np.argmax(outputs.logits.detach().numpy(), axis=-1)\nprint(predicted_class)\n\n```\n\n出力結果：\n\n```bash\n[4]　# 配列なので0始まり。4は評価5。\n```\n\nこの結果は、より正確な評価となっており、モデルが改善されたことを示しています。\n\n## まとめ\n\nこのチュートリアルでは、`transformers`ライブラリを使用してLLMのファインチューニングを行い、わずか500件のデータでもモデルの性能が向上することを確認できました。\n\n本記事で紹介した手順は、あくまで学習目的です。\n\n本格的な案件では、より大規模なデータセットや高性能なハードウェアを利用することを推奨します。\n\n### 学びのポイント\n\n1. LLMの基本操作とトークナイズの仕組みが理解できる。\n2. Hugging Faceのエコシステムを活用する方法が習得できる。\n3. 簡単なファインチューニングによるモデルの改善効果を確認できる。\n\n今後のプロジェクトや個人学習にぜひ役立ててください！\n\n---\n\n# 参考\n\n- https://huggingface.co/docs/transformers/training\n- https://huggingface.co/docs/transformers/installation\n- https://huggingface.co/datasets/Yelp/yelp_review_full\n\n---\n\n","updatedAt":"2025-06-02T00:00:52.772Z","tags":[{"id":20,"documentId":"fbllyhmskvu2l7wbg5dzpkri","createdAt":"2025-05-19T09:48:50.341Z","updatedAt":"2025-05-19T09:48:50.341Z","publishedAt":"2025-05-19T09:48:50.348Z","name":"LLM"},{"id":4,"documentId":"zc573y83cxbfql2umdwbhot9","createdAt":"2025-05-19T09:44:33.028Z","updatedAt":"2025-05-19T09:44:33.028Z","publishedAt":"2025-05-19T09:44:33.035Z","name":"Tutorial"},{"id":30,"documentId":"d99cu6c3t9hgwynppb92lhph","createdAt":"2025-05-19T09:50:59.080Z","updatedAt":"2025-05-19T09:50:59.080Z","publishedAt":"2025-05-19T09:50:59.086Z","name":"生成AI"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_15_a017e8a63e.png"}},{"id":202,"documentId":"yz9v0rgurkrgg57550p3h9ja","title":"Flowiseで始める簡単RAGチャットボット","content":"生成AIとRAG（Retrieval-Augmented Generation）を活用したチャットボットは、ユーザーの特定の質問に対して文脈に基づいた正確な回答を提供する強力なツールです。\n\n今回は、FlowiseとDocumentStoreを使った簡単なチャットボット構築方法をご紹介します。\n\n---\n\n# **DocumentStoreにドキュメントを保存する**\n\nまず、チャットボットに利用するドキュメントをFlowiseに登録します。以下のステップでPDFファイルをロードし、DocumentStoreに保存します。\n\nFlowiseにはドキュメントローダーが用意されています。この例では、PDF Fileローダーを使用して3つのPDFファイルを追加しています。\n\nDocumentStoreにPDFを登録した際の操作画面です。\n\n![スクリーンショット](https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/2024_12_25_21_54_38_872fa91201.png)\n\n---\n\n# **チャットフローの作成**\n\nFlowiseのエディターで、以下のようにDocument Storeノードを選択し、Vector Storeノードに接続します。\n\n![スクリーンショット](https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/2024_12_25_22_38_42_90dc100b60.png\n)\n\nそしてUpsert操作を実行すると、PDFの内容がVector Storeに保存されます。\n\n![スクリーンショット](https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/2024_12_25_22_33_26_0f00cc51cc.png)\n\n---\n\n# **チャット機能のテスト**\n\n完成したフローを使って、実際にチャットを試してみます。ユーザーが質問を送信すると、該当するドキュメントのチャンクを参照しながら回答が生成されます。\n\n![スクリーンショット](https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/2024_12_25_22_39_55_f71b695056.png)\n![スクリーンショット](https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/2024_12_25_22_40_03_8f49b331f2.png\n)\n\nさらに、回答生成時に参照された具体的なドキュメントの部分も確認できます。\n\n![スクリーンショット](https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/2024_12_25_22_40_11_fd0ac5007b.png)\n\n---\n\n## **おまけ: ドキュメントの格納場所**\n\nデフォルトではドキュメントはローカルに保存されますが、AWS S3などのクラウドストレージに切り替えることも可能です。\n\n### **ローカル保存の場合**\n\n保存場所は以下のパスになります:\n\n```\n/root/.flowise/storage/docustore\n\n```\n\n### **AWS S3での保存**\n\nS3を使用する場合は、`docker-compose.yml`ファイルに環境変数を設定します。\n\n```yaml\nversion: '3.1'\n\nservices:\n    flowise:\n        image: flowiseai/flowise\n        restart: always\n        environment:\n            - STORAGE_TYPE=${STORAGE_TYPE}\n            - S3_STORAGE_BUCKET_NAME=${S3_STORAGE_BUCKET_NAME}\n            - S3_STORAGE_ACCESS_KEY_ID=${S3_STORAGE_ACCESS_KEY_ID}\n            - S3_STORAGE_SECRET_ACCESS_KEY=${S3_STORAGE_SECRET_ACCESS_KEY}\n            - S3_STORAGE_REGION=${S3_STORAGE_REGION}\n\n```\n\nそして、`.env`ファイルに以下のように記述します。\n\n| 環境変数 | 設定内容 |\n| --- | --- |\n| STORAGE_TYPE | s3 |\n| S3_STORAGE_BUCKET_NAME | バケット名 |\n| S3_STORAGE_ACCESS_KEY_ID | AWS Access Key |\n| S3_STORAGE_SECRET_ACCESS_KEY | AWS Secret Key |\n| S3_STORAGE_REGION | リージョン |\n\nFlowiseを使えば、初心者でも簡単にRAGを利用したチャットボットを構築できます。この機会にぜひ試してみてください！\n\n---\n\n","updatedAt":"2025-06-01T23:59:05.798Z","tags":[{"id":30,"documentId":"d99cu6c3t9hgwynppb92lhph","createdAt":"2025-05-19T09:50:59.080Z","updatedAt":"2025-05-19T09:50:59.080Z","publishedAt":"2025-05-19T09:50:59.086Z","name":"生成AI"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_14_01a75fca34.png"}},{"id":201,"documentId":"w35l3o70015xpn6gwr8mgdov","title":"Flowiseを使ってAIエージェントを作ろう！","content":"AIエージェントを構築するオープンソースツール「Flowise」を知っていますか？\n\nFlowiseは、ノーコードに近い操作感でAIエージェントを構築できる強力なツールです。\n\nこの記事では、Dockerでの環境構築と開発者向けの利用方法を中心に、Flowiseの魅力と実際の使い方をお伝えします。\n\n公式サイト：[Flowise](https://flowiseai.com/)\n\n公式ドキュメント：[Getting Started](https://docs.flowiseai.com/getting-started)\n\n---\n\n## Flowiseの環境構築：Docker編\n\nDockerを使用すると、Flowiseを簡単かつ迅速にセットアップできます。公式ドキュメント通りに進めれば、数分で利用可能です！\n\n### 手順\n\n1. **リポジトリをクローン**\n    \n    ```bash\n    git clone https://github.com/FlowiseAI/Flowise.git\n    ```\n    \n2. **`docker`ディレクトリに移動**\n    \n    ```bash\n    cd Flowise/docker\n    ```\n    \n3. **環境設定ファイルを準備**\n    \n    `.env.example` をコピーして `.env` に名前を変更します。\n    \n    ```bash\n    cp .env.example .env\n    ```\n    \n4. **Dockerを起動**\n    \n    ```bash\n    docker compose up -d\n    ```\n    \n5. **アクセス**\n    \n    ブラウザで [`http://localhost:3000`](http://localhost:3000/) を開きます。\n    \n\n---\n\n## 開発者向けセットアップ\n\nFlowiseをローカル環境でカスタマイズしたい開発者には、こちらの方法がおすすめです。\n\n### 事前準備\n\nまずは、必要なツール「pnpm」をインストールします。\n\n```bash\nnpm i -g pnpm\n```\n\n### 手順\n\n1. **リポジトリのルートに移動**\n    \n    ```bash\n    cd Flowise\n    ```\n    \n2. **依存関係をインストール**\n    \n    ```bash\n    pnpm install\n    ```\n    \n3. **ビルド**\n    \n    ```bash\n    pnpm build\n    ```\n    \n4. **Flowiseを起動**\n    \n    ```bash\n    pnpm start\n    ```\n    \n5. **アクセス**\n    \n    [`http://localhost:3000`](http://localhost:3000/) をブラウザで開きます。\n    \n\n---\n\n## チャットフローの作成：チュートリアル\n\nFlowiseを使えば、AIエージェントのやり取りを視覚的に構築する「チャットフロー」を簡単に作成できます。以下は、具体的な例を使った作成手順です。\n\nここではOpenAI APIを使用する想定で進めます。\n\n### 1. Credentialsの設定\n\n使用するAPIに応じてCredential（認証情報）を設定します。例えば、OpenAIのAPIを利用する場合、以下のように設定します。\n\n1. Credentialsのタブに移動\n    \n    ![スクリーンショット 2024-07-03 午後6.39.48.png](https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/2024_07_03_6_39_48_94388196fb.png)\n    \n2. **「Add Credential」ボタン**をクリック\n    \n    ![スクリーンショット 2024-07-03 午後6.52.25.png](https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/2024_07_03_6_52_25_1cf1c81e07.png)\n    \n3. 「OpenAI API」を選択し、クレデンシャルの名前とAPIキーを入力して保存\n    \n    ![スクリーンショット 2024-07-03 午後6.53.31.png](https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/2024_07_03_6_53_31_8d27857708.png)\n    \n\n### 2. テンプレートを利用したチャットフロー作成\n\nFlowiseはテンプレートも提供しており、それをカスタマイズすることで効率的にフローを構築できます。\n\n1. **テンプレートを選択**\n    \n    Marketplaceで好きなテンプレート（例：Flowise Docs QnA）を選択し、「Use Template」をクリック。\n    \n    ![スクリーンショット 2024-07-03 午後11.39.31.png](https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/2024_07_03_11_39_31_75919d7cc9.png)\n    \n2. クレデンシャルの設定\n    \n    「ChatOpenAI」というノードや　「OpenAI Embedding」には上記で設定したcredentialを選択します。\n    \n    ![スクリーンショット 2024-07-03 午後11.43.14.png](https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/2024_07_03_11_43_14_78b1227740.png)\n    \n3. **ノードをカスタマイズ**\n    \n    ノードをドラッグ＆ドロップで編集可能。例えば、「Githubノード」を「Plain Textノード」に置き換えることも簡単です。\n    \n    ![スクリーンショット 2024-07-03 午後11.48.53.png](https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/2024_07_03_11_48_53_f708a365ce.png)\n    \n4. **データを保存**\n    \n    「Plain Text」ノードに適当な公開情報を記入し、ヘッダー右側の保存ボタンからチャットフローを保存します。\n    \n    ![スクリーンショット 2024-07-03 午後11.55.38.png](https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/2024_07_03_11_55_38_fe6c53cc19.png)\n    \n    編集画面右上の緑のボタンでVectorstore（ベクトルデータベース）にデータを保存することで、問い合わせ可能な状態にします。\n    \n    ![スクリーンショット 2024-07-03 午後11.58.03.png](https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/2024_07_03_11_58_03_1aa9b4a69f.png\n)\n    \n5. 右上のメッセージボタンを押すとチャットのポップアップが表示されます。AIへの問い合わせのテストができます。\n    \n    ![スクリーンショット 2024-12-24 11.34.35.png](https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/2024_12_24_11_34_35_a94480944a.png)\n    \n\n---\n\n## Chainとは？\n\nFlowiseでは、やり取りの流れを「Chain（チェーン）」と呼びます。この構造によって、AIエージェントは会話の文脈を理解し、一貫性のある応答を生成します。\n\n詳細は[こちらの解説](https://www.notion.so/8b0882226a934699b989b35c1028d790?pvs=21)をご覧ください。\n\n---\n\n## RAG（Retrieval-Augmented Generation）とは？\n\nFlowiseは、外部情報を検索して生成に活用する「RAG（Retrieval-Augmented Generation）」もサポートしています。これにより、大規模言語モデル（LLM）の回答精度を向上させることが可能です。\n\n---\n\n## APIとして利用する方法\n\nFlowiseは、構築したエージェントをAPIとして活用することも可能です。\n\n右上のコードアイコンをクリックすると、APIの使い方が表示されます。これを参考にウェブアプリや他のシステムに組み込むことができます。\n\n![スクリーンショット 2024-07-04 午前12.20.11.png](https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/2024_07_04_12_20_11_5a2a1430bb.png)\n\n---\n\n詳しくはYoutubeでも解説されているのでぜひ確認してみてください。\n\n[Flowise AI (2024) Tutorial](https://youtube.com/playlist?list=PL4HikwTaYE0H7wBxhvQqxYcKOkZ4O3zXh\u0026si=pGLRAokPrNY2kI6f)\n\n## まとめ\n\nFlowiseは、ノーコードでも高機能なAIエージェントを構築できる強力なツールです。この記事で紹介したDockerでの簡単セットアップや、開発者向けのカスタマイズ方法を活用して、ぜひFlowiseの可能性を最大限引き出してください。\n\nFlowiseで作ったAIエージェントがどのような未来を切り拓くのか、楽しみですね！\n\n---\n\n","updatedAt":"2025-06-01T23:57:01.948Z","tags":[{"id":30,"documentId":"d99cu6c3t9hgwynppb92lhph","createdAt":"2025-05-19T09:50:59.080Z","updatedAt":"2025-05-19T09:50:59.080Z","publishedAt":"2025-05-19T09:50:59.086Z","name":"生成AI"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_13_9c6f3f0fd3.png"}},{"id":200,"documentId":"lvazy668vfdl9p758u63i57n","title":"同期処理におけるAWS Lambda関数タイムアウトのハンドリング検討","content":"# 背景\n\n弊社ではサーバーレスアーキテクチャを活用した開発を進めており、AWS Lambdaも多くのプロジェクトで利用しています。しかし、Lambda関数のタイムアウトが発生した場合のハンドリングが不十分で、サービスの一時的な停止や、顧客体験の低下に繋がる事例が発生しました。本記事では、Lambda関数のタイムアウトに対する適切なハンドリング方法を検討し、より信頼性の高いシステム構築を目指します。\n\n---\n\n# 検証概要\n\n1. **API Gateway + Lambda構成**\n    - クライアント(frontend)からのリクエスト時にタイムアウトするケースを想定し、ハンドリングを検討\n2. **Lambda関数から同期で他のLambda関数を実行**\n    - バックエンドでの実行時にタイムアウトするケースを想定し、ハンドリングを検討\n\n---\n\n## 検証1: API Gateway + Lambda構成\n\n### 再現するタイムアウトの設定\n\n以下のLambda関数を30秒のタイムアウト設定で実装しました。この関数は、45秒間スリープするため確実にタイムアウトが発生します。\n\n```python\nimport json\nimport time\n\ndef lambda_handler(event, context):\n    print('=====sleep start=====')\n    time.sleep(45)\n    print('=====sleep end=====')\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Hello from Lambda!')\n    }\n\n```\n\n### 実験内容\n\nこの関数をAPI Gatewayで `GET /time-out` エンドポイントとして公開し、以下のコマンドでリクエストを実行しました。\n\n```bash\ncurl https://your.domain/time-out -i\n\n```\n\n### 結果\n\nタイムアウトが発生した場合、以下のレスポンスが返ってきました。\n\n```bash\nHTTP/2 504 \ndate: Sat, 07 Dec 2024 12:51:53 GMT\ncontent-type: application/json\ncontent-length: 41\nx-amzn-requestid: de0b98ff-54cb-46af-acb3-d3d3f08dd189\nx-amzn-errortype: InternalServerErrorException\nx-amz-apigw-id: Ca-v-EJmoAMEpqw=\n\n{\"message\": \"Endpoint request timed out\"}\n```\n\n### クライアント側の対応策\n\nタイムアウトに対してクライアント側で考えられる対応策は以下の通りです。\n\n1. **リトライの実装**\n    \n    タイムアウトが一時的である可能性があるため、504エラー時にリトライを実施する。\n    \n2. **調査用情報の活用**\n    - `x-amzn-requestid` と `x-amz-apigw-id` を取得し、ログや通知システムに保存。これらの情報はCloudWatch Logsでの調査に役立つ。\n3. **アラート設定**\n    \n    頻繁にタイムアウトが発生する場合にはアラートを送信し、開発チームに早期対応を促す。\n    \n\n---\n\n## 検証2: Lambda関数から同期で他のLambda関数を実行\n\n### 呼び出し元関数\n\n以下の呼び出し元関数を1分のタイムアウト設定で実装しました。この関数から、タイムアウトが設定された別のLambda関数を同期的に実行します。\n\n```python\nimport json\nimport boto3\n\ndef lambda_handler(event, context):\n    lambda_client = boto3.client('lambda')\n    function_name = 'TimeOut'\n    response = lambda_client.invoke(FunctionName=function_name)\n\n    print('=====print response start=====')\n    print(response)\n    print('=====print response end=====')\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Hello from Lambda!')\n    }\n\n```\n\n### 実験結果\n\n呼び出し先のLambda関数がタイムアウトすると、以下のようなレスポンスが返りました。\n\n```python\n{\n  'ResponseMetadata': {\n    'RequestId': '36337419-d972-4d5b-b08e-b5f125859dcb',\n    'HTTPStatusCode': 200,\n    'HTTPHeaders': {\n      'x-amzn-requestid': '36337419-d972-4d5b-b08e-b5f125859dcb',\n      'x-amz-function-error': 'Unhandled',\n      'x-amzn-trace-id': 'Root=1-675449fe-3bb52bbf04bfa28c7dc64c26'\n    }\n  },\n  'FunctionError': 'Unhandled',\n  'Payload': {'errorMessage': 'Task timed out after 30.02 seconds'}\n}\n\n```\n\n### 呼び出し元の対応策\n\n1. **エラー情報のチェック**\n    \n    `FunctionError` の存在や `Payload` を解析し、タイムアウトが原因かを判断する。タイムアウトが原因の場合、リトライ処理を検討する。\n    \n2. **ログの活用**\n    - `x-amzn-requestid` をエラー情報として記録。呼び出し先関数のログ調査時に役立つ。\n    - `x-amzn-trace-id` を記録。X-Rayを活用したトレーシングでシステム全体の動作を追跡可能。\n3. **アラート設定**\n    \n    タイムアウトの頻度が高い場合、アラートを設定し、異常検知の迅速化を図る。\n    \n\n---\n\n# 結論\n\nAWS Lambdaのタイムアウト問題は、適切にハンドリングすることでシステムの信頼性を高めることができます。本記事で紹介した方法を参考に、以下のポイントを意識した対策を行いましょう。\n\n1. **リトライ戦略の実装**\n    \n    一時的な問題であれば、リトライで解決する場合があります。\n    \n2. **ログの充実化**\n    \n    調査に役立つリクエストIDやトレースIDをエラーログとして記録。\n    \n3. **アラートと通知**\n    \n    問題が発生した際には迅速に開発チームが対応できるような仕組みを構築。\n    \n4. **設計の見直し**\n    \n    タイムアウトの根本原因（処理時間が長すぎるなど）を分析し、コードやシステム構成の改善も検討する。\n    \n\nAWS Lambdaの柔軟性を活かしつつ、堅牢で信頼性の高いシステムを構築していきましょう。\n\n---\n\n","updatedAt":"2025-06-01T23:54:20.067Z","tags":[{"id":10,"documentId":"cxt2tbnsy05cazm17p3pp1a3","createdAt":"2025-05-19T09:46:58.860Z","updatedAt":"2025-05-19T09:46:58.860Z","publishedAt":"2025-05-19T09:46:58.868Z","name":"AWS"},{"id":12,"documentId":"c3lesvkdvjiq7y5zfx9mx0tu","createdAt":"2025-05-19T09:47:14.973Z","updatedAt":"2025-05-19T09:47:14.973Z","publishedAt":"2025-05-19T09:47:14.980Z","name":"Backend"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_12_449ae1295c.png"}},{"id":199,"documentId":"emdhy55xuistlcq9aeunyxyz","title":"DynamoDBの並列Scan","content":"前回の記事「 [DynamoDBからの全データ取得におけるプラクティス](https://my-blog-frontend-two.vercel.app/articles/o0cmjsrwp73fm9jd2i3s0d80)  」では、**パーティション分散と並列Query**を活用した全データ取得の効果を検証しました。\n\n今回の記事では、もう一つの手法である**並列Scan**について取り上げ、どのような効果が得られるのかを実験します。\n\n---\n\n# 並列Scanとは？\n\n**並列Scan**は、DynamoDBのパーティション分散を利用し、データのスキャン処理を複数のセグメント（Segment）に分割して並列で実行する方法です。\n\n通常のScan操作は1つのプロセスで順次処理を行うため、データ量が増えるほど時間がかかります。\n\n一方、並列Scanでは複数のワーカーを用いて並列処理を行うため、大量データのスキャンを効率化できます。\n\n## 基本動作\n\n- **Segment**: データを分割する単位。\n- **TotalSegments**: 全体の分割数。\n- 各ワーカーが指定されたSegmentを担当し、全体のデータセットを並列に処理します。\n\n---\n\n# 実験内容\n\n以下の条件で並列Scanを実施し、処理時間を測定しました。\n\n- データ量: 3万件、10万件\n- メモリ量: 512MB、2048MB\n- セグメント数: 2, 3, 4, 5, 10\n\n### ソースコード\n\n以下は実験に使用したAWS Lambda用のPythonコードです。\n\n```python\nimport boto3\nimport os\nfrom concurrent.futures import ThreadPoolExecutor\n\ndynamodb = boto3.resource('dynamodb')\ntable = dynamodb.Table('test_datas')\n\n# 最大ワーカー数\nmax_workers = min(32, os.cpu_count() * 5)\n\ndef parallel_scan(segment, total_segments):\n    print(f'segment = {segment}, total_segments = {total_segments}')\n    items = []\n    options = {\n        'Segment': segment,\n        'TotalSegments': total_segments\n    }\n    done = False\n\n    while True:\n        response = table.scan(**options)\n        next_token = response.get('LastEvaluatedKey', None)\n        items.extend(response['Items'])\n        if next_token:\n            options['ExclusiveStartKey'] = next_token\n        else:\n            break\n    return items\n\ndef lambda_handler(event, context):\n    total_segments = 2  # 並列度を調整\n\n    # ThreadPoolExecutorを使用して並列スキャンを実行\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        futures = [executor.submit(parallel_scan, segment, total_segments) for segment in range(total_segments)]\n        results = []\n        for future in futures:\n            results.extend(future.result())\n\n        print(f'{len(results)}件')\n    return {\n        'StatusCode': 200\n    }\n\n```\n\n---\n\n## 実験結果\n\n### データ量: 3万件\n\n| メモリ量 | セグメント数 | 処理時間 |\n| --- | --- | --- |\n| 512MB | 2 | 15秒 |\n|  | 3 | 14.4秒 |\n|  | 4 | 14.6秒 |\n|  | 5 | 14.4秒 |\n|  | 10 | 14.3秒 |\n| 2048MB | 2 | 4秒 |\n|  | 3 | 4.3秒 |\n|  | 4 | 4.1秒 |\n|  | 5 | 4秒 |\n|  | 10 | 4.3秒 |\n\n---\n\n### データ量: 10万件\n\n| メモリ量 | セグメント数 | 処理時間 |\n| --- | --- | --- |\n| 512MB | 2 | 49秒 |\n|  | 3 | 49秒 |\n|  | 4 | 52.3秒 |\n|  | 5 | 53秒 |\n|  | 10 | 52秒 |\n| 2048MB | 2 | 13.1秒 |\n|  | 3 | 14秒 |\n|  | 4 | 13.6秒 |\n|  | 5 | 14.6秒 |\n|  | 10 | 14.2秒 |\n\n---\n\n## まとめ\n\n### パフォーマンス\n\n- **メモリ量の影響**:\nメモリを2048MBに増加させると処理時間が大幅に短縮。\n- **セグメント数の影響**:\nセグメント数の増加による処理時間の改善は限定的。\n\n### コストと効率\n\n- **普通のScanと比較**:\nメモリ量を増やした並列Scanの方が高速。ただし、メモリ量を増やす分、コストが増加する点には注意が必要です。\n- **並列Queryと比較**:\nパーティションキーを活用した並列Queryの方がさらに高速で効率的。並列Scanは特定のユースケース（例: パーティションキーが不明、全件取得が必要）で有効です。\n\n---\n\n## 結論\n\n**並列Scanは特定の状況で有効な手法ですが、パフォーマンス最適化を考えるなら、並列Queryの方がより効果的です。**\n\n次のような場合に並列Scanを検討してください:\n\n- 全データをスキャンする必要がある。\n- パーティションキーの設計が不十分でQueryが使えない。\n\n効率的なDynamoDB運用の為には、データモデル設計を見直し、並列Queryを優先することをおすすめします！\n\n---\n\n","updatedAt":"2025-06-01T23:52:36.485Z","tags":[{"id":10,"documentId":"cxt2tbnsy05cazm17p3pp1a3","createdAt":"2025-05-19T09:46:58.860Z","updatedAt":"2025-05-19T09:46:58.860Z","publishedAt":"2025-05-19T09:46:58.868Z","name":"AWS"},{"id":12,"documentId":"c3lesvkdvjiq7y5zfx9mx0tu","createdAt":"2025-05-19T09:47:14.973Z","updatedAt":"2025-05-19T09:47:14.973Z","publishedAt":"2025-05-19T09:47:14.980Z","name":"Backend"},{"id":14,"documentId":"ufw8l9386d4flb8sddy84mft","createdAt":"2025-05-19T09:47:52.868Z","updatedAt":"2025-05-19T09:47:52.868Z","publishedAt":"2025-05-19T09:47:52.876Z","name":"DynamoDB"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_11_bfd0628b18.png"}},{"id":198,"documentId":"o0cmjsrwp73fm9jd2i3s0d80","title":"DynamoDBからの全データ取得におけるプラクティス","content":"弊社は、サーバーレスアーキテクチャの開発を得意としており、Amazon DynamoDBやAWS Lambda等のサービスを活用した効率的でスケーラブルなシステム設計を提供しています。\n\nその中で、アプリケーション開発において「画面に全データを一覧表示する」という仕様はよく見られるものの、NoSQLデータベースでは適切なアプローチを選ばないとパフォーマンスやコストの課題が発生します。\n\n本記事では、DynamoDBから全データを取得する方法と、その実験結果をもとにした設計上の注意点について解説します。\n\n---\n\n# **全データ取得の課題**\n\nDynamoDBはスケーラビリティに優れたデータベースですが、設計次第で処理性能が大きく変化します。\n\n特に以下の点に注意が必要です:\n\n- **Scanのリスク**:\nScanはテーブル全体をフルスキャンするため、膨大なデータ量の場合に時間がかかり、コストも増加します。\n- **Queryの可能性**:\n適切に設計されたパーティションキーとソートキーを利用することで、特定のデータセットを効率的に取得できます。\n\n---\n\n# **実験概要**\n\nDynamoDBで3万件、10万件のデータを用意し、ScanとQueryの処理時間を比較しました。以下の2つのアプローチを検証しています。\n\n1. **全データを単一パーティションにまとめる**\n2. **データを複数パーティションに分散させる**\n\nデータはAWS公式サンプルリポジトリ [aws-samples/csv-to-dynamodb](https://github.com/aws-samples/csv-to-dynamodb) のtestfile.csvを使用。\n\n実験のパターンごとに少しデータを修正し、投入します。\n\n---\n\n## **実験1: 単一パーティションにまとめる**\n\n### **手法**\n\n- **パーティションキー**: 固定値（例: `DATA`）を設定するGSIを作成。\n- **目的**: 単一パーティションにデータを格納し、Queryで効率的に全データを取得する。\n\n**データ構造例:**\n\n| DataType (PK) | uuid | Country | ItemType |\n| --- | --- | --- | --- |\n| DATA | 535113847 | Azerbaijan | Snacks |\n| DATA | 874708545 | Panama | Cosmetics |\n\nQueryのソースコード(AWS Lambda用)\n\n```python\nimport boto3\nfrom boto3.dynamodb.conditions import Key\n\ndef lambda_handler(event, context):\n    table_name = 'test_datas'\n    region = 'us-east-1'\n    gsi_name = 'DataType-index'\n\n    # DynamoDBクライアントの初期化\n    dynamodb = boto3.resource('dynamodb', region_name=region)\n    table = dynamodb.Table(table_name)\n\n    # クエリ条件 DataType が DATA\n    key_condition_expression = Key('DataType').eq('DATA')\n\n    try:\n        options = {\n            'IndexName': gsi_name,\n            'KeyConditionExpression': key_condition_expression,\n            'ReturnConsumedCapacity': 'TOTAL'\n        }\n        while True:\n            response = table.query(**options)\n            next_token = response.get('LastEvaluatedKey', None)\n            print(next_token)\n\n            if next_token:\n                options['ExclusiveStartKey'] = next_token\n            else:\n                break\n\n        return {\n            'statusCode': 200\n        }\n    except Exception as e:\n        print('エラー:', e)\n        return {\n            'statusCode': 500,\n            'body': 'サーバーエラーが発生しました'\n        }\n\n```\n\nScanのソースコード(AWS Lambda用)\n\n```python\nimport boto3\n\ndef lambda_handler(event, context):\n    table_name = 'test_datas_'\n    region = 'us-east-1'\n\n    # DynamoDBクライアントの初期化\n    dynamodb = boto3.resource('dynamodb', region_name=region)\n    table = dynamodb.Table(table_name)\n\n    try:\n        options = {\n            'ReturnConsumedCapacity': 'TOTAL'\n        }\n        while True:\n            response = table.scan(**options)\n            next_token = response.get('LastEvaluatedKey', None)\n            print(next_token)\n\n            if next_token:\n                options['ExclusiveStartKey'] = next_token\n            else:\n                break\n\n        return {\n            'statusCode': 200\n        }\n    except Exception as e:\n        print('エラー:', e)\n        return {\n            'statusCode': 500,\n            'body': 'サーバーエラーが発生しました'\n        }\n\n```\n\n### **結果(Lambdaのウォームスタート)**\n\n| データ量 | メモリ (MB) | Query (秒) | Scan (秒) |\n| --- | --- | --- | --- |\n| 3万件 | 512 | 15 | 15 |\n|  | 2048 | 4 | 5 |\n| 10万件 | 512 | 50 | 50 |\n|  | 2048 | 13 | 15 |\n\n### **考察**\n\n- 全データ取得という観点ではScanもQueryもあまり処理時間の違いはないことがわかります。\n- データ量が増えると取得時間が数十秒かかるため、ユーザー体験の悪化が懸念されます。\n- メモリを増やすことで処理時間が短縮されますが、それでも数万件以上では非同期処理や別の工夫が必要です。\n\n---\n\n## **実験2: データを複数パーティションに分散する**\n\n### **手法**\n\n- **パーティションキー**: シャード番号やランダム識別子を付加。\n- **目的**: データを複数のパーティションに分散し、並列処理で取得速度を向上させる。\n\n**データ構造例:**\n\n| ItemCategory (PK) | uuid | DataType | Country | ItemType |\n| --- | --- | --- | --- | --- |\n| ItemCategory#11 | 535113847 | DATA | Azerbaijan | Snacks |\n| ItemCategory#5 | 874708545 | DATA | Panama | Cosmetics |\n\n並列でクエリを実行するソースコード(AWS Lambda用)\n\n```python\nimport boto3\nimport os\nfrom botocore.config import Config\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\n# DynamoDB テーブル名\nTABLE_NAME = \"test_datas\"\nSHARD_COUNT = 12  # シャードの数\n\ncustom_config = Config(\n    max_pool_connections=12\n)\n# DynamoDB クライアントの作成\ndynamodb = boto3.client('dynamodb', config=custom_config)\n\n# 最大ワーカー数\nmax_workers = min(32, os.cpu_count() * 5)\n\ndef query_shard(partition_key):\n    \"\"\"指定されたシャードをクエリする関数\"\"\"\n    try:\n        items = []\n        options = {\n            'TableName': TABLE_NAME,\n            'IndexName': 'ItemCategory-index',\n            'KeyConditionExpression': \"ItemCategory = :pk\",\n            'ExpressionAttributeValues': {\":pk\": {\"S\": partition_key}}\n        }\n        while True:\n            response = dynamodb.query(**options)\n            items.extend(response.get(\"Items\", []))\n            next_token = response.get('LastEvaluatedKey', None)\n            if next_token:\n                options['ExclusiveStartKey'] = next_token\n            else:\n                break\n        print(f\"{partition_key}: {len(items)}件\")\n        return items\n    except Exception as e:\n        print(f\"Error querying {partition_key}: {e}\")\n        return []\n\ndef query_all_shards():\n    \"\"\"すべてのシャードを並列でクエリする\"\"\"\n    print(f'max_workers: {max_workers}')\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        # シャードごとにクエリを実行\n        futures = {\n            executor.submit(query_shard, f\"ItemCategory#{shard_number}\"): shard_number\n            for shard_number in range(1, SHARD_COUNT + 1)\n        }\n        \n        # 結果を集約\n        results = []\n        for future in as_completed(futures):\n            try:\n                shard_result = future.result()\n                results.extend(shard_result)\n            except Exception as e:\n                print(f\"Error in shard {futures[future]}: {e}\")\n        \n        return results\n\ndef lambda_handler(event, context):\n    \"\"\"Lambda 関数のエントリポイント\"\"\"\n    results = query_all_shards()\n    print(f'{len(results)}件')\n    return {\n        \"statusCode\": 200,\n        \"body\": {\n        }\n    }\n```\n\n### **結果(Lambdaのウォームスタート)**\n\n| データ量 | メモリ (MB) | Query (秒) |\n| --- | --- | --- |\n| 3万件 | 512 | 11 |\n|  | 2048 | 3.3 |\n| 10万件 | 512 | Out of memory Error |\n|  | 2048 | 10 |\n\n### **考察**\n\n- パーティション分散により取得速度が向上しました。\n- データ量が増えるとOut of Memoryエラーが発生する可能性があるため、クエリ方法やメモリ管理の工夫が必要です。\n\n---\n\n# **まとめ**\n\nDynamoDBで全データを取得する際のベストプラクティスは以下の通りです。\n\n1. **データ量が少ない場合**: 単一パーティションでQueryを使用しても問題ありません。\n2. **データ量が多い場合**: パーティションを分散し、並列でQueryを実行することで効率的にデータを取得可能です。\n3. **非同期処理**: データ量が多い場合は同期処理ではなく、非同期でデータを取得する設計を検討しましょう。\n4. **仕様の再検討**: 全データを一覧表示する代わりに、条件を絞り込んで表示する仕様に変更できないかをまず検討するべきでしょう。\n\n効率的なデータ取得には、データ設計とアプリケーション設計のバランスが欠かせません。本記事を参考に、DynamoDBを活用したパフォーマンスの高いアプリケーションを構築してください。\n\n---\n\n","updatedAt":"2025-06-01T23:46:48.939Z","tags":[{"id":10,"documentId":"cxt2tbnsy05cazm17p3pp1a3","createdAt":"2025-05-19T09:46:58.860Z","updatedAt":"2025-05-19T09:46:58.860Z","publishedAt":"2025-05-19T09:46:58.868Z","name":"AWS"},{"id":12,"documentId":"c3lesvkdvjiq7y5zfx9mx0tu","createdAt":"2025-05-19T09:47:14.973Z","updatedAt":"2025-05-19T09:47:14.973Z","publishedAt":"2025-05-19T09:47:14.980Z","name":"Backend"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_10_4b5734cef6.png"}},{"id":197,"documentId":"tzc5uo0i37zs1nzgp3hljh77","title":"DynamoDB Scan vs Query: パフォーマンスとコストの比較","content":"弊社では、API Gateway + Lambda + DynamoDBを利用したサーバーレスアーキテクチャでの開発を多く行っています。\n\nその中で、度々パフォーマンス問題が発生する事がありますが、特にDynamoDBのScan操作に起因するケースが目立ちます。\n\nこの記事では、**Scan**と**Query**のパフォーマンスとコストの違いについて、実際のデータを用いた検証結果をもとに解説します。\n\n---\n\n## 事前準備\n\nDynamoDBに10万件のサンプルデータを投入し、ScanとQueryの動作を比較します。\n\n### データ準備手順\n\n1. **CSVからデータ投入**:\n    \n    AWS公式サンプルリポジトリ [aws-samples/csv-to-dynamodb](https://github.com/aws-samples/csv-to-dynamodb) を利用。\n    \n    投入手順は [こちらの記事](https://dev.classmethod.jp/articles/csv-import-to-dynamodb-table/) を参照。\n    \n2. **データ件数確認**:\nDynamoDB CLIを用いてデータ件数を確認します。\n    \n    ```bash\n    aws dynamodb scan --table-name test_datas --select COUNT\n    \n    ```\n    \n    結果:\n    \n    ```json\n    {\n        \"Count\": 100000,\n        \"ScannedCount\": 100000,\n        \"ConsumedCapacity\": null\n    }\n    ```\n    \n    10万件のデータが投入されました。\n    \n\n---\n\n## 実験1: Scan\n\n### 実装コード\n\n以下のLambda関数を使用してDynamoDBのScan操作を実行します。\n\n```python\nimport boto3\nfrom boto3.dynamodb.conditions import Attr\n\ndef lambda_handler(event, context):\n    table_name = 'test_datas'\n    region = 'us-east-1'\n\n    dynamodb = boto3.resource('dynamodb', region_name=region)\n    table = dynamodb.Table(table_name)\n\n    filter_expression = Attr('Country').eq('Australia')\n\n    try:\n        options = {\n            'FilterExpression': filter_expression,\n            'Limit': 1000,\n            'ReturnConsumedCapacity': 'TOTAL'\n        }\n        while True:\n            response = table.scan(**options)\n            print(response['Items'])\n            print(response['ConsumedCapacity'])\n            next_token = response.get('LastEvaluatedKey', None)\n            print(next_token)\n\n            if next_token:\n                options['ExclusiveStartKey'] = next_token\n            else:\n                break\n\n        return {'statusCode': 200}\n    except Exception as e:\n        print('エラー:', e)\n        return {'statusCode': 500, 'body': 'サーバーエラーが発生しました'}\n\n```\n\n### 実行結果\n\nウォームスタートでの実行結果:\n\n- **実行時間**: 約5秒\n- **消費キャパシティユニット**: 62\n\nログの一部:\n\n```json\nFunction Logs:\n'3/30/15', 'Region': 'Australia and Oceania', 'TotalRevenue': '58517.76', 'ShipDate': '5/8/15', 'SalesChannel': 'Offline', 'UnitCost': '6.92', 'uuid': '757149684', 'TotalCost': '43402.24'}, {'ItemType': 'Snacks', 'TotalProfit': '206885.28', 'UnitsSold': '3752', 'UnitPrice': '152.58', 'Country': 'Australia', 'OrderPriority': 'C', 'OrderDate': '4/19/10', 'Region': 'Australia and Oceania', 'TotalRevenue': '572480.16', 'ShipDate': '6/5/10', 'SalesChannel': 'Offline', 'UnitCost': '97.44', 'uuid': '340443837', 'TotalCost': '365594.88'}, {'ItemType': 'Snacks', 'TotalProfit': '313912.02', 'UnitsSold': '5693', 'UnitPrice': '152.58', 'Country': 'Australia', 'OrderPriority': 'M', 'OrderDate': '9/12/12', 'Region': 'Australia and Oceania', 'TotalRevenue': '868637.94', 'ShipDate': '10/27/12', 'SalesChannel': 'Online', 'UnitCost': '97.44', 'uuid': '892960441', 'TotalCost': '554725.92'}, {'ItemType': 'Meat', 'TotalProfit': '462061.6', 'UnitsSold': '8078', 'UnitPrice': '421.89', 'Country': 'Australia', 'OrderPriority': 'M', 'OrderDate': '8/23/13', 'Region': 'Australia and Oceania', 'TotalRevenue': '3408027.42', 'ShipDate': '8/27/13', 'SalesChannel': 'Offline', 'UnitCost': '364.69', 'uuid': '543180644', 'TotalCost': '2945965.82'}, {'ItemType': 'Beverages', 'TotalProfit': '152559.72', 'UnitsSold': '9742', 'UnitPrice': '47.45', 'Country': 'Australia', 'OrderPriority': 'L', 'OrderDate': '1/27/16', 'Region': 'Australia and Oceania', 'TotalRevenue': '462257.9', 'ShipDate': '2/14/16', 'SalesChannel': 'Offline', 'UnitCost': '31.79', 'uuid': '671733558', 'TotalCost': '309698.18'}]\n{'TableName': 'test_datas', 'CapacityUnits': 28.5}\n{'uuid': '147039830'}\n[{'ItemType': 'Cosmetics', 'TotalProfit': '919076.82', 'UnitsSold': '5286', 'UnitPrice': '437.2', 'Country': 'Australia', 'OrderPriority': 'M', 'OrderDate': '5/12/14', 'Region': 'Australia and Oceania', 'TotalRevenue': '2311039.2', 'ShipDate': '5/31/14', 'SalesChannel': 'Online', 'UnitCost': '263.33', 'uuid': '746805799', 'TotalCost': '1391962.38'}, {'ItemType': 'Vegetables', 'TotalProfit': '273731.68', 'UnitsSold': '4336', 'UnitPrice': '154.06', 'Country': 'Australia', 'OrderPriority': 'L', 'OrderDate': '11/20/15', 'Region': 'Australia and Oceania', 'TotalRevenue': '668004.16', 'ShipDate': '12/21/15', 'SalesChannel': 'Online', 'UnitCost': '90.93', 'uuid': '964156997', 'TotalCost': '394272.48'}, {'ItemType': 'Cosmetics', 'TotalProfit': '734253.01', 'UnitsSold': '4223', 'UnitPrice': '437.2', 'Country': 'Australia', 'OrderPriority': 'C', 'OrderDate': '5/30/10', 'Region': 'Australia and Oceania', 'TotalRevenue': '1846295.6', 'ShipDate': '7/12/10', 'SalesChannel': 'Offline', 'UnitCost': '263.33', 'uuid': '182464730', 'TotalCost': '1112042.59'}, {'ItemType': 'Cosmetics', 'TotalProfit': '398683.91', 'UnitsSold': '2293', 'UnitPrice': '437.2', 'Country': 'Australia', 'OrderPriority': 'C', 'OrderDate': '5/24/15', 'Region': 'Australia and Oceania', 'TotalRevenue': '1002499.6', 'ShipDate': '5/25/15', 'SalesChannel': 'Offline', 'UnitCost': '263.33', 'uuid': '841381347', 'TotalCost': '603815.69'}, {'ItemType': 'Household', 'TotalProfit': '251743.87', 'UnitsSold': '1519', 'UnitPrice': '668.27', 'Country': 'Australia', 'OrderPriority': 'C', 'OrderDate': '1/3/14', 'Region': 'Australia and Oceania', 'TotalRevenue': '1015102.13', 'ShipDate': '1/25/14', 'SalesChannel': 'Online', 'UnitCost': '502.54', 'uuid': '351520287', 'TotalCost': '763358.26'}, {'ItemType': 'Household', 'TotalProfit': '1447485.82', 'UnitsSold': '8734', 'UnitPrice': '668.27', 'Country': 'Australia', 'OrderPriority': 'C', 'OrderDate': '1/29/14', 'Region': 'Australia and Oceania', 'TotalRevenue': '5836670.18', 'ShipDate': '2/2/14', 'SalesChannel': 'Offline', 'UnitCost': '502.54', 'uuid': '391825520', 'TotalCost': '4389184.36'}]\n{'TableName': 'test_datas', 'CapacityUnits': 28.5}\n{'uuid': '690726172'}\n[]\n{'TableName': 'test_datas', 'CapacityUnits': 0.5}\nNone\nEND RequestId: f6e29395-105a-4388-ae4b-a15905769f51\nREPORT RequestId: f6e29395-105a-4388-ae4b-a15905769f51\tDuration: 4904.22 ms\tBilled Duration: 4905 ms\tMemory Size: 128 MB\tMax Memory Used: 77 MB\n```\n\n---\n\n## 実験2: Query\n\n### GSI（グローバルセカンダリインデックス）作成\n\n`Country` を条件にQueryを実行するため、以下の条件でGSIを作成しました。\n\n- **GSI名**: Country-index\n- **パーティションキー**: Country（文字列）\n\n### 実装コード\n\n以下のLambda関数を使用してDynamoDBのQuery操作を実行します。\n\n```python\nimport boto3\nfrom boto3.dynamodb.conditions import Key\n\ndef lambda_handler(event, context):\n    table_name = 'test_datas'\n    region = 'us-east-1'\n\n    dynamodb = boto3.resource('dynamodb', region_name=region)\n    table = dynamodb.Table(table_name)\n\n    key_condition_expression = Key('Country').eq('Australia')\n\n    try:\n        options = {\n            'KeyConditionExpression': key_condition_expression,\n            'Limit': 1000,\n            'ReturnConsumedCapacity': 'TOTAL'\n        }\n        while True:\n            response = table.query(**options)\n            print(response['Items'])\n            print(response['ConsumedCapacity'])\n            next_token = response.get('LastEvaluatedKey', None)\n            print(next_token)\n\n            if next_token:\n                options['ExclusiveStartKey'] = next_token\n            else:\n                break\n\n        return {'statusCode': 200}\n    except Exception as e:\n        print('エラー:', e)\n        return {'statusCode': 500, 'body': 'サーバーエラーが発生しました'}\n\n```\n\n### 実行結果\n\nウォームスタートでの実行結果:\n\n- **実行時間**: 約1.1秒\n- **消費キャパシティユニット**: 16.5\n\nログの一部:\n\n```json\nFunction Logs:\nItemType': 'Fruits', 'TotalProfit': '15115.52', 'UnitsSold': '6272', 'Country': 'Australia', 'UnitPrice': '9.33', 'OrderPriority': 'H', 'OrderDate': '3/30/15', 'Region': 'Australia and Oceania', 'TotalRevenue': '58517.76', 'ShipDate': '5/8/15', 'SalesChannel': 'Offline', 'UnitCost': '6.92', 'uuid': '757149684', 'TotalCost': '43402.24'}, {'ItemType': 'Snacks', 'TotalProfit': '206885.28', 'UnitsSold': '3752', 'Country': 'Australia', 'UnitPrice': '152.58', 'OrderPriority': 'C', 'OrderDate': '4/19/10', 'Region': 'Australia and Oceania', 'TotalRevenue': '572480.16', 'ShipDate': '6/5/10', 'SalesChannel': 'Offline', 'UnitCost': '97.44', 'uuid': '340443837', 'TotalCost': '365594.88'}, {'ItemType': 'Snacks', 'TotalProfit': '313912.02', 'UnitsSold': '5693', 'Country': 'Australia', 'UnitPrice': '152.58', 'OrderPriority': 'M', 'OrderDate': '9/12/12', 'Region': 'Australia and Oceania', 'TotalRevenue': '868637.94', 'ShipDate': '10/27/12', 'SalesChannel': 'Online', 'UnitCost': '97.44', 'uuid': '892960441', 'TotalCost': '554725.92'}, {'ItemType': 'Meat', 'TotalProfit': '462061.6', 'UnitsSold': '8078', 'Country': 'Australia', 'UnitPrice': '421.89', 'OrderPriority': 'M', 'OrderDate': '8/23/13', 'Region': 'Australia and Oceania', 'TotalRevenue': '3408027.42', 'ShipDate': '8/27/13', 'SalesChannel': 'Offline', 'UnitCost': '364.69', 'uuid': '543180644', 'TotalCost': '2945965.82'}, {'ItemType': 'Beverages', 'TotalProfit': '152559.72', 'UnitsSold': '9742', 'Country': 'Australia', 'UnitPrice': '47.45', 'OrderPriority': 'L', 'OrderDate': '1/27/16', 'Region': 'Australia and Oceania', 'TotalRevenue': '462257.9', 'ShipDate': '2/14/16', 'SalesChannel': 'Offline', 'UnitCost': '31.79', 'uuid': '671733558', 'TotalCost': '309698.18'}, {'ItemType': 'Cosmetics', 'TotalProfit': '919076.82', 'UnitsSold': '5286', 'Country': 'Australia', 'UnitPrice': '437.2', 'OrderPriority': 'M', 'OrderDate': '5/12/14', 'Region': 'Australia and Oceania', 'TotalRevenue': '2311039.2', 'ShipDate': '5/31/14', 'SalesChannel': 'Online', 'UnitCost': '263.33', 'uuid': '746805799', 'TotalCost': '1391962.38'}, {'ItemType': 'Vegetables', 'TotalProfit': '273731.68', 'UnitsSold': '4336', 'Country': 'Australia', 'UnitPrice': '154.06', 'OrderPriority': 'L', 'OrderDate': '11/20/15', 'Region': 'Australia and Oceania', 'TotalRevenue': '668004.16', 'ShipDate': '12/21/15', 'SalesChannel': 'Online', 'UnitCost': '90.93', 'uuid': '964156997', 'TotalCost': '394272.48'}, {'ItemType': 'Cosmetics', 'TotalProfit': '734253.01', 'UnitsSold': '4223', 'Country': 'Australia', 'UnitPrice': '437.2', 'OrderPriority': 'C', 'OrderDate': '5/30/10', 'Region': 'Australia and Oceania', 'TotalRevenue': '1846295.6', 'ShipDate': '7/12/10', 'SalesChannel': 'Offline', 'UnitCost': '263.33', 'uuid': '182464730', 'TotalCost': '1112042.59'}, {'ItemType': 'Cosmetics', 'TotalProfit': '398683.91', 'UnitsSold': '2293', 'Country': 'Australia', 'UnitPrice': '437.2', 'OrderPriority': 'C', 'OrderDate': '5/24/15', 'Region': 'Australia and Oceania', 'TotalRevenue': '1002499.6', 'ShipDate': '5/25/15', 'SalesChannel': 'Offline', 'UnitCost': '263.33', 'uuid': '841381347', 'TotalCost': '603815.69'}, {'ItemType': 'Household', 'TotalProfit': '251743.87', 'UnitsSold': '1519', 'Country': 'Australia', 'UnitPrice': '668.27', 'OrderPriority': 'C', 'OrderDate': '1/3/14', 'Region': 'Australia and Oceania', 'TotalRevenue': '1015102.13', 'ShipDate': '1/25/14', 'SalesChannel': 'Online', 'UnitCost': '502.54', 'uuid': '351520287', 'TotalCost': '763358.26'}, {'ItemType': 'Household', 'TotalProfit': '1447485.82', 'UnitsSold': '8734', 'Country': 'Australia', 'UnitPrice': '668.27', 'OrderPriority': 'C', 'OrderDate': '1/29/14', 'Region': 'Australia and Oceania', 'TotalRevenue': '5836670.18', 'ShipDate': '2/2/14', 'SalesChannel': 'Offline', 'UnitCost': '502.54', 'uuid': '391825520', 'TotalCost': '4389184.36'}]\n{'TableName': 'test_datas', 'CapacityUnits': 16.5}\nNone\nEND RequestId: 902e8513-28db-4e25-9a4e-df9cba5f9410\nREPORT RequestId: 902e8513-28db-4e25-9a4e-df9cba5f9410\tDuration: 1158.68 ms\tBilled Duration: 1159 ms\tMemory Size: 128 MB\tMax Memory Used: 82 MB\n```\n\n---\n\n## 比較結果\n\n| 操作方法 | 実行時間 | 消費キャパシティユニット |\n| --- | --- | --- |\n| Scan | 約5秒 | 62 |\n| Query | 約1.1秒 | 16.5 |\n\n### 考察\n\n1. **パフォーマンス**:\nQueryはScanよりも4倍以上高速。指定したパーティションキーに基づいて効率的にデータを取得できるためです。\n2. **コスト効率**:\n消費キャパシティユニットもScanの約4分の1。大量データの操作では大幅なコスト削減が見込めます。\n3. **使用ケース**:\nデータを効率的に取得したい場合や条件検索が必要な場合は**Query**を使用すべき。一方、条件に合致するパーティションキーがない場合や全件検索が必要な場合に限り、**Scan**を検討します。\n\n---\n\n## まとめ\n\nデータ件数10万件の実験結果から、**Query**は**Scan**よりも圧倒的に高速かつ低コストであることが確認できました。\n\n**結論**:\n\n- DynamoDBのパフォーマンス最適化を考えるなら、**Queryを優先的に使用**。\n- 特に、必要なデータに応じたパーティションキーやGSI設計を行うことが重要です。\n\nこれからDynamoDBを使った開発を行う方は、この結果を参考に、効率的なデータ操作を実現してください！\n\n---\n\n","updatedAt":"2025-06-01T23:39:34.700Z","tags":[{"id":10,"documentId":"cxt2tbnsy05cazm17p3pp1a3","createdAt":"2025-05-19T09:46:58.860Z","updatedAt":"2025-05-19T09:46:58.860Z","publishedAt":"2025-05-19T09:46:58.868Z","name":"AWS"},{"id":12,"documentId":"c3lesvkdvjiq7y5zfx9mx0tu","createdAt":"2025-05-19T09:47:14.973Z","updatedAt":"2025-05-19T09:47:14.973Z","publishedAt":"2025-05-19T09:47:14.980Z","name":"Backend"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_09_0f6287835c.png"}},{"id":196,"documentId":"a4m16knr39pl1td3e22hc0xz","title":"ReactでsetIntervalを扱う方法","content":"ReactのWebアプリで一定間隔でカウントアップする処理を実装した際に直面した課題と、その解決策について解説します。\n\nこの方法を理解すれば、Reactで `setInterval` を適切に扱う技術が身に付きます。\n\nその課題と解決策について、実例を交えながら解説します。\n\n---\n\n# 課題：`setInterval`の扱いによる問題\n\nあるアプリで、特定条件を満たす場合にカウントアップし、条件を満たさない場合はカウントをリセットする機能を実装しました。\n\n以下がそのコード例です。\n\n## 問題のコード\n\n```tsx\nimport React, { useState, useEffect, useRef } from 'react';\n\nconst App = () =\u003e {\n    const [timer, setTimer] = useState(0);\n    const intervalRef = useRef(null);\n    const [condition, setCondition] = useState([]);\n    \n    // 別のuseEffectでupdateConditionが実行される\n    const updateCondition = (data) =\u003e {\n        setCondition((prev) =\u003e [...data, {hoge: data.hoge, fuga: data.fuga}])\n    }\n    \n    const countUpTimer = () =\u003e {\n        return setInterval(() =\u003e {\n            setTimer((prevTimer) =\u003e prevTimer + 1);\n        }, 1000)\n    }\n\n    // 特定の条件でカウントアップ開始\n    useEffect(() =\u003e {\n        if (condition.length \u003e 1) {\n            if (!intervalRef.current) {\n                intervalRef.current = countUpTimer()\n            }\n        } else {\n            clearInterval(intervalRef.current);\n            intervalRef.current = null;\n            setTimer(0);\n        }\n\n        return () =\u003e clearInterval(intervalRef.current);\n    }, [condition]);\n\n    // その他の処理は省略\n\n    return (\n        \u003cdiv\u003e\n            \u003ch1\u003eTimer: {timer}\u003c/h1\u003e\n        \u003c/div\u003e\n    );\n}\n```\n\n## 問題点\n\n`useEffect`で `condition` の状態が変わるたびに、`setInterval`のコールバックが停止する問題が発生しました。この現象は、`setInterval`がクロージャの内部で古い`state`を参照してしまうために起こります。\n\n---\n\n# 解決策：`useInterval`カスタムフックの実装\n\nこの問題を解決するには、`setInterval`を再利用可能な形でカプセル化し、最新の`state`を正しく参照できるようにするカスタムフックを作成します。\n\n## `useInterval.js`の実装\n\n以下のように、`useInterval`カスタムフックを実装します。\n\n```tsx\nimport { useEffect, useRef } from 'react';\n\nexport function useInterval(callback, delay) {\n    const savedCallback = useRef();\n\n    // 最新のコールバックを保存\n    useEffect(() =\u003e {\n        savedCallback.current = callback;\n    }, [callback]);\n\n    useEffect(() =\u003e {\n        function func() {\n            savedCallback.current();\n        }\n        if (delay !== null) {\n            let id = setInterval(func, delay);\n            return () =\u003e clearInterval(id);\n        }\n    }, [delay]);\n}\n\n```\n\n- `callback`: 実行したい処理\n- `delay`: 実行間隔（ミリ秒）。`null`の場合は実行を停止します。\n\n`useInterval`を使用すると、タイマーのロジックが簡潔になり、依存関係の管理がし易くなります。\n\n---\n\n## `useInterval`の利用例\n\nカスタムフックを活用すると、アプリのロジックがシンプルになります。\n\n```tsx\nimport React, { useState, useEffect } from 'react';\nimport { useInterval } from './useInterval';\n\nconst App = () =\u003e {\n    const [timer, setTimer] = useState(0);\n\n    const condition = () =\u003e {\n        // 別のstateを使って条件の計算（例: 特定の状態かどうか）\n    };\n\n    useInterval(() =\u003e {\n        setTimer((prevTimer) =\u003e prevTimer + 1);\n    }, condition ? 1000 : null);\n\n    useEffect(() =\u003e {\n        if (!condition) {\n            setTimer(0);\n        }\n    }, [condition]);\n\n    // その他の処理は省略\n\n    return (\n        \u003cdiv\u003e\n            \u003ch1\u003eTimer: {timer}\u003c/h1\u003e\n        \u003c/div\u003e\n    );\n};\n\n```\n\n### 主なポイント\n\n- `useInterval`を利用することで、`setInterval`の管理が明示的かつ安全になります。\n- `condition`が`false`の場合は`delay`が`null`になるため、カウントアップが停止し、カウンタをリセットします。\n\n---\n\n# まとめ\n\n`setInterval`をReactで適切に扱うには、クロージャや依存関係の管理に注意が必要です。\n\n今回紹介した`useInterval`カスタムフックを使用することで、コードの可読性と再利用性を高めることができます。\n\nReact開発の中で`setInterval`を安全かつ効率的に使用する方法を学び、より洗練されたコードを書けるようにしていきましょう！！\n\n---\n\n# 参考資料\n\nhttps://overreacted.io/making-setinterval-declarative-with-react-hooks/\n\nhttps://www.geeksforgeeks.org/reactjs-useinterval-custom-hook/\n\nhttps://usehooks-ts.com/react-hook/use-interval\n\n---\n\n","updatedAt":"2025-06-01T23:37:47.615Z","tags":[{"id":16,"documentId":"zg5iwdiznwk0mb2s77f9xta3","createdAt":"2025-05-19T09:48:07.933Z","updatedAt":"2025-05-19T09:48:07.933Z","publishedAt":"2025-05-19T09:48:07.940Z","name":"Frontend"},{"id":26,"documentId":"koshlmrejvmni8nxdnq7cir3","createdAt":"2025-05-19T09:50:01.361Z","updatedAt":"2025-05-19T09:50:01.361Z","publishedAt":"2025-05-19T09:50:01.379Z","name":"React"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_08_a7cf147e40.png"}},{"id":195,"documentId":"dh9ikac9n442nsn2afohpy4s","title":"AWS CLIでのSSO認証","content":"企業におけるクラウド活用が一般化する中、適切なユーザ管理とセキュアな認証の仕組みが重要になっています。\n\nAWSのIAM Identity Centerを利用すると、効率的にユーザ管理とシングルサインオン（SSO）認証を実現できます。\n\n本記事では、IAM Identity Centerを使ったユーザ管理、AWS CLIでのSSO設定手順を詳しく解説します。\n\n---\n\n# IAM Identity Centerとは？\n\nIAM Identity Center（旧AWS SSO）は、AWSの各種サービスやアカウントへのアクセスを一元管理できるサービスです。以下のような特徴があります：\n\n- ユーザとグループの管理を一元化\n- アクセス許可の簡易設定\n- AWSアカウントやサードパーティアプリケーションへのSSOをサポート\n\nこれにより、ユーザ体験を向上させるとともに、セキュリティリスクを軽減することができます。\n\n---\n\n# ユーザ登録とSSO準備\n\nIAM Identity Centerを使用するには、まずユーザ登録が必要です。\n\nユーザ登録が完了すると、AWSアクセスポータルにログインできる状態になります。このポータルを通じて、各AWSアカウントへのアクセスがシームレスになります。\n\n---\n\n# AWS CLIでのSSO設定\n\nAWS CLIを利用して業務を効率化する場合、CLIにSSOを設定する必要があります。以下に手順を示します。\n\n## 1. 認証情報の確認\n\nAWSアクセスポータルにログインし、自分の認証情報を確認します。この情報は設定ファイル作成時に必要です。\n\n![スクリーンショット 2024-12-02 17.48.50.png](https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/2024_12_02_17_48_50_d8a6782947.png\n)\n\n---\n\n## 2. `~/.aws/config` ファイルの作成\n\n以下のように設定ファイルを作成します。エディタで`~/.aws/config`を開き、次の内容を追加してください：\n\n```bash\n[profile your_profile]\nsso_session = session_name\nsso_account_id = xxxxxxxxxx\nsso_role_name = PowerUserAccess\nregion = ap-northeast-1\noutput = json\n\n[sso-session session_name]\nsso_start_url = https://randomId.awsapps.com/start/#\nsso_region = ap-northeast-1\nsso_registration_scopes = sso:account:access\n\n```\n\n### ポイント\n\n- `profile` 名は分かりやすい名前にしましょう（例：アカウント名やロール名を基にする）。\n- `sso_start_url` はIAM Identity Centerで設定されたURLを指定します。\n\n---\n\n## 3. SSOログイン\n\n1. ターミナルで次のコマンドを実行し、SSOログインを行います：\n\n```bash\naws sso login --profile your_profile\n```\n\nコマンド実行後、ブラウザが自動で開き、AWSアクセスポータルへ移動します。\n\nターミナルではこのような内容が出力されます。\n\n```bash\nAttempting to automatically open the SSO authorization page in your default browser.\nIf the browser does not open or you wish to use a different device to authorize this request, open the following URL:\n\nhttps://device.sso.ap-northeast-1.amazonaws.com/\n\nThen enter the code:\n\nMJKM-RHLP\n```\n\n1. AWSアクセスポータルで認証が開始、ターミナルに出力されたコードと一致しているかを確認します。\n    \n    ![スクリーンショット 2024-12-02 17.29.37.png](https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/2024_12_02_17_29_37_f54c533215.png)\n    \n2. Confirm and continueをクリックします。\n    \n    ![スクリーンショット 2024-12-02 17.29.55.png](https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/2024_12_02_17_29_55_d1a031be60.png)\n    \n3. アクセス許可をクリックします。\n    \n    ![スクリーンショット 2024-12-02 17.30.06.png](https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/2024_12_02_17_30_06_ac709b6131.png)\n    \n\n認証が完了しました。\n\n1. ターミナルに以下のメッセージが表示されればSSOログイン完了です:\n\n```bash\nSuccessfully logged into Start URL: https://randomId.awsapps.com/start/#\n```\n\n---\n\n## 4. AWS CLIコマンドの実行\n\nSSOで認証されたプロファイルを利用してAWS CLIコマンドを実行できます。例えば、S3バケットを確認する場合：\n\n```bash\naws s3 ls --profile your_profile\n\n```\n\nこれで、設定したSSOプロファイルを利用してAWSサービスにアクセスできます。\n\n---\n\n# まとめ\n\nIAM Identity Centerを利用する事で、複数アカウントやユーザのアクセス管理が大幅に簡素化されます。特にAWS CLIと組み合わせることで、業務効率の向上が期待できます。設定に少し手間はかかりますが、一度設定すれば簡単にSSO認証を利用できるようになります。\n\nこれを機に、IAM Identity Centerを活用してセキュアで効率的な環境を構築してみてはいかがですか？\n\n---\n","updatedAt":"2025-06-01T23:29:39.390Z","tags":[{"id":10,"documentId":"cxt2tbnsy05cazm17p3pp1a3","createdAt":"2025-05-19T09:46:58.860Z","updatedAt":"2025-05-19T09:46:58.860Z","publishedAt":"2025-05-19T09:46:58.868Z","name":"AWS"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_07_7d3532e9bb.png"}},{"id":194,"documentId":"kguyis0515443ldlyq7w24kx","title":"AWS CDKプロジェクトの始め方","content":"クラウド環境の構築や管理を効率的に行う方法として、 **Infrastructure as Code (IaC)** が注目されています。\n\nその中でも、AWSが提供する **AWS Cloud Development Kit (AWS CDK)** は、開発者にとって非常に強力なツールです。\n\n弊社でもAWS CDKを採用しており、その理由は以下のメリットにあります。\n\n- **クラウド環境のセットアップが容易**：コードベースでインフラを管理する為、手作業を減らせます。\n- **全体像の把握がしやすい**：コードとして記述されているため、インフラ構成が明確になります。\n- **Gitで差分管理が可能**：コードの変更を簡単に追跡・レビューできます。\n\n今回はAWS CDKの導入方法をステップごとに解説します。ぜひ参考にしてください！\n\n# **AWS CDKの使い方を学ぶための基本ステップ**\n\n## **1. CLIのインストール**\n\nAWS CDKを使うには、まずCLI（コマンドラインインターフェース）のインストールが必要です。以下のコマンドを実行してインストールしてください。\n\n```bash\nnpm install -g aws-cdk\n```\n\nインストール後、以下のコマンドでバージョンを確認します。\n\n```bash\ncdk --version\n```\n\n例:\n\n2.156.0 (build 2966832)\n\n## **2. プロジェクトの開始**\n\nまずは、プロジェクト用のディレクトリを作成します。\n\n```bash\nmkdir sample_project\ncd sample_project\n```\n\n次に、作成したディレクトリでCDKプロジェクトを初期化します。\n\n```bash\ncdk init app --language javascript\n```\n\n--languageオプションを使うことで、希望するプログラミング言語を指定できます。サポートされている言語を確認するには以下のコマンドを実行してください。\n\n```bash\ncdk init --help\n```\n\n## **3. AWS環境のブートストラッピング**\n\nAWS CDKでは、一部のスタックをデプロイする前にブートストラッピングが必要です。これにより、デプロイ先のAWS環境が準備されます。\n\n```bash\ncdk bootstrap aws://{your_aws_account_id}/{aws_region}\n```\n\n- {your_aws_account_id}にはAWSアカウントIDを入力します。\n- {aws_region}にはデプロイするAWSリージョンを指定します（例: us-east-1）。\n\n## **4. CloudFormationテンプレートの合成**\n\nAWS CDKはCloudFormationの抽象化ツールです。cdk synthコマンドを使うと、記述したコードからCloudFormationテンプレートを生成できます。\n\n```bash\ncdk synth\n```\n\n## **5. デプロイ**\n\n構成が完了したら、いよいよデプロイです。以下のコマンドを使用してスタックをデプロイします。\n\n```bash\ncdk deploy\n```\n\nすべてのスタックをデプロイしたい場合は、--allオプションを付けます。\n\n```bash\ncdk deploy --all\n```\n\n特定のスタックをデプロイする場合は、スタック名を指定します。\n\n```bash\ncdk deploy [stack_name..]\n```\n\n## **6. 差分の確認**\n\nコードの変更内容を反映する前に、cdk diffコマンドで差分を確認できます。これにより、変更内容の影響を把握できます。\n\n```bash\ncdk diff\n```\n\n## **7. スタックの破棄**\n\n不要になったスタックを破棄する場合は、以下のコマンドを使います。\n\n```bash\ncdk destroy\n```\n\nすべてのスタックを削除する場合は、--allオプションを付けます。\n\n```bash\ncdk destroy --all\n```\n\n特定のスタックを削除する場合は、スタック名を指定します。\n\n```bash\ncdk destroy [stack_name..]\n```\n\n# **まとめ**\n\nAWS CDKを利用することで、以下のようなメリットが得られます。\n\n- **コードによる環境構築の自動化**：手作業のミスを防ぎ、迅速な環境構築が可能です。\n- **簡単な変更管理**：Gitを活用してインフラコードの変更を追跡できます。\n- **効率的な開発**：環境の構築や破棄が簡単に実施できるため、開発スピードが向上します。\n\n初めてAWS CDKを使う方も、この記事を参考にしてプロジェクトをスタートしてみてください。クラウド環境の構築・管理が飛躍的に楽になりますよ！\n\n---\n","updatedAt":"2025-06-01T23:28:04.223Z","tags":[{"id":10,"documentId":"cxt2tbnsy05cazm17p3pp1a3","createdAt":"2025-05-19T09:46:58.860Z","updatedAt":"2025-05-19T09:46:58.860Z","publishedAt":"2025-05-19T09:46:58.868Z","name":"AWS"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_06_05cd01084c.png"}},{"id":193,"documentId":"oqg4cauzlhjjvlgo80qbb0lb","title":"SNSサブスクリプションフィルターの活用","content":"AWS SNS（Simple Notification Service）は、アプリケーション間でメッセージをやり取りするための強力なサービスです。SNSの特徴の一つに、特定の条件に基づいてメッセージをフィルタリングするサブスクリプションフィルタがあります。これにより、受信側でメッセージを効率的に振り分ける事が可能です。\n\nこの記事では、SNSサブスクリプションフィルターを使ったシステム構成と、そのフィルタリング方法について解説します。\n\n---\n\n# 1. 構成\n\nSNSサブスクリプションフィルターを活用したシンプルな構成の例です。\n\n- SNS → SQS → Lambda\n\nここでのポイントは、SNSが複数のSQSにメッセージを配信し、それぞれ異なるLambda関数がそのメッセージを処理するということです。SQSのキューにメッセージを送る際、SNSのサブスクリプションフィルターを使うことで、特定の属性や条件に基づいたメッセージの配信をコントロールできます。\n\n---\n\n# 2. メッセージ属性でのフィルタリング\n\nSNSのメッセージ属性を利用して、特定の属性値を持つメッセージだけを特定のSQSに配送するように設定できます。\n\n### サブスクリプションフィルターポリシー例\n\n次のポリシーでは、`filterType`という属性が「1」の場合にのみメッセージを受信します。\n\n```json\n{\n  \"filterType\": [\"1\"]\n}\n\n```\n\n### Lambda関数の例\n\nLambda関数からSNSにメッセージを送信する際に、フィルタリング対象となる属性を指定します。\n\n```python\nimport json\nimport boto3\n\ndef lambda_handler(event, context):\n    sns = boto3.client('sns')\n    message = {\n        'type': '1',\n        'message': 'Hello from Lambda!',\n        'key1': 'val1',\n        'key2': 'val2',\n        'result': {\n            'alertType': 'warn'\n        }\n    }\n    message_attributes = {\n        'filterType': {'DataType': 'String', 'StringValue': '1'}\n    }\n\n    response = sns.publish(\n        TopicArn='arn:aws:sns:us-east-1:9999999999:MyTopic',  # SNSトピックのARNを指定\n        Message=json.dumps(message),  # メッセージ本文\n        Subject='Test message from Lambda',  # メッセージのタイトル（オプション）\n        MessageAttributes=message_attributes\n    )\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Hello from Lambda!')\n    }\n\n```\n\nこの例では、`filterType`が「1」であるメッセージがSNSに送信され、そのメッセージ属性に基づいてフィルタリングが行われます。\n\n---\n\n# 3. メッセージ本文でのフィルタリング\n\nSNSではメッセージ本文の内容に基づいてもフィルタリングが可能です。次の例では、メッセージ本文内の`result.alertType`が「warn」または「error」の場合にのみメッセージを受信します。\n\n### サブスクリプションフィルターポリシー例\n\n```json\n{\n  \"result\": {\n    \"alertType\": [\n      \"error\",\n      \"warn\"\n    ]\n  }\n}\n\n```\n\n### Lambda関数の例\n\nLambda関数からメッセージを送信する際に、メッセージ本文の内容に基づいたフィルタリングが行われます。\n\n```python\nimport json\nimport boto3\n\ndef lambda_handler(event, context):\n    sns = boto3.client('sns')\n    message = {\n        'type': '1',\n        'message': 'Hello from Lambda!',\n        'key1': 'val1',\n        'key2': 'val2',\n        'result': {\n            'alertType': 'warn'\n        }\n    }\n    message_attributes = {\n        'filterType': {'DataType': 'String', 'StringValue': '1'}\n    }\n\n    response = sns.publish(\n        TopicArn='arn:aws:sns:us-east-1:9999999999:MyTopic',  # SNSトピックのARNを指定\n        Message=json.dumps(message),  # メッセージ本文\n        Subject='Test message from Lambda',  # メッセージのタイトル（オプション）\n        MessageAttributes=message_attributes\n    )\n\n    print('PublishToSns end')\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Hello from Lambda!')\n    }\n\n```\n\nこの例では、`alertType`が「warn」であるため、このメッセージはサブスクリプションポリシーで定義されたフィルターを通過します。\n\n---\n\n# 4. まとめ\n\nSNSサブスクリプションフィルターは、特定のメッセージ属性や本文の内容に基づいて、メッセージをフィルタリングする強力なツールです。この機能を利用することで、例えば特定の警告やエラーが発生した際にのみアラートを発生させるなど、効率的な通知システムを構築できます。\n\nこの仕組みを活用することで、無駄なメッセージの受信を減らし、システムのパフォーマンスや管理の効率を向上させることが可能です。AWSのサーバーレスアーキテクチャの一環として、ぜひSNSサブスクリプションフィルターを使いこなしてみてください！\n\n---\n","updatedAt":"2025-06-01T23:26:29.810Z","tags":[{"id":10,"documentId":"cxt2tbnsy05cazm17p3pp1a3","createdAt":"2025-05-19T09:46:58.860Z","updatedAt":"2025-05-19T09:46:58.860Z","publishedAt":"2025-05-19T09:46:58.868Z","name":"AWS"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_05_6c940be6e0.png"}},{"id":192,"documentId":"rpm3wekiymj1tbbqgdgy7xfm","title":"AWSアカウントの確認方法","content":"AWSのアカウント情報を確認したい場合、AWS CLIを使うと簡単に取得できます。\n\nアカウントID、ディスプレイ名、そしてARN（Amazon Resource Name）は、AWSのリソースやユーザーを識別するために重要な情報です。この記事では、AWS CLIを使ってこれらの情報を取得する方法を紹介します。\n\n---\n\n# 1. AWSアカウント情報を取得するコマンド\n\nAWSアカウントの詳細を取得するために使用する基本的なコマンドは、`aws sts get-caller-identity`です。このコマンドを実行すると、現在設定されている認証情報に基づいて、アカウントに関する情報を取得し、JSON形式で出力します。\n\n### コマンド例\n\n```bash\n$ aws sts get-caller-identity\n```\n\n実行すると、以下の様なJSON形式のレスポンスが返ってきます。\n\n```json\n{\n    \"UserId\": \"xxxxxxxx\",\n    \"Account\": \"xxxxxxxxxx\",\n    \"Arn\": \"arn:aws:iam::{your account id}:user/{user name}\"\n}\n```\n\n### 各項目の説明\n\n- **UserId**: 現在のIAMユーザーまたはロールのID。これは、そのユーザーやロールを一意に識別するための文字列です。\n- **Account**: AWSアカウントID。AWSのリソースを管理するために使用される一意のアカウント番号です。\n- **Arn**: Amazon Resource Name（ARN）は、AWS内のリソースを一意に識別するための文字列です。この場合は、IAMユーザーまたはロールのARNが表示されます。\n\n---\n\n# 2. `get-caller-identity`コマンドの使いどころ\n\nこのコマンドは、AWS CLIを使用している際に、現在自分がどのAWSアカウントにアクセスしているのかを確認するために非常に便利です。特に、複数のAWSアカウントやIAMロールを使用している場合、間違ったアカウントにアクセスしてしまうリスクを軽減できます。\n\nたとえば、開発環境と本番環境で異なるAWSアカウントを使っている場合、このコマンドを実行することで、どちらのアカウントに接続しているかをすぐに確認できます。\n\n---\n\n# 3. プロファイルを使ったAWSアカウント情報の取得\n\n前回の記事でも紹介したように、複数のプロファイルを設定している場合、`--profile`オプションを使うことで、異なるAWSアカウント情報を簡単に切り替えて確認できます。\n\n### プロファイルを指定したコマンド例\n\n```bash\n$ aws sts get-caller-identity --profile profile_name\n```\n\nこれにより、特定のプロファイルに関連付けられたAWSアカウントの情報を取得できます。\n\n---\n\n# まとめ\n\nAWSアカウント情報の確認は、特に複数のアカウントを使い分ける場合や、アクセス権限を確認したい場合に非常に役立ちます。`aws sts get-caller-identity`コマンドを使えば、現在のAWSアカウントIDやユーザーに関する情報を簡単に取得でき、作業のミスを防ぐことができます。\n\nAWS環境を安全かつ効率的に管理するために、ぜひこのコマンドを活用してください！！\n\n---","updatedAt":"2025-06-01T11:14:15.332Z","tags":[{"id":10,"documentId":"cxt2tbnsy05cazm17p3pp1a3","createdAt":"2025-05-19T09:46:58.860Z","updatedAt":"2025-05-19T09:46:58.860Z","publishedAt":"2025-05-19T09:46:58.868Z","name":"AWS"},{"id":28,"documentId":"g250gp73dhyj31yn9639otwk","createdAt":"2025-05-19T09:50:38.186Z","updatedAt":"2025-05-19T09:50:38.186Z","publishedAt":"2025-05-19T09:50:38.193Z","name":"クラウド"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_04_8df97275ae.png"}},{"id":191,"documentId":"xu5pb2ete2c6srmb0yfp3t6n","title":"AWSプロファイル切り替え","content":"AWS CLIを使用する際、複数のアカウントや環境を使い分けたい場合があります。例えば、開発環境や本番環境、もしくは異なるプロジェクトにおけるアクセスキーを使い分けたい時です。この記事では、AWS CLIでプロファイルを切り替える方法について、基本的な設定から具体的に使い分ける方法までを紹介します。\n\n---\n\n# 1. ローカルのAWSプロファイル設定\n\nまず、AWS CLIをインストールした後、初めて使用する際には`aws configure`コマンドでAWSの認証情報を設定します。このコマンドで設定されるプロファイルは、デフォルトで「`default`」という名前で保存されます。\n\n### コマンド例\n\n```bash\n$ aws configure\nAWS Access Key ID [None]: xxxxxxxxxx\nAWS Secret Access Key [None]: xxxxxxxxxx\nDefault region name [None]: ap-northeast-1\nDefault output format [None]: json\n```\n\nこの操作により、指定した認証情報が`~/.aws/credentials`ファイルに保存され、リージョン情報などが`~/.aws/config`ファイルに記録されます。\n\n### プロファイル確認\n\n設定内容は以下のようにファイルを直接確認できます。\n\n```bash\n$ cat ~/.aws/credentials\n[default]\naws_access_key_id = xxxxxxxxxx\naws_secret_access_key = xxxxxxxxxx\n```\n\n```bash\n$ cat ~/.aws/config\n[default]\nregion = ap-northeast-1\noutput = json\n```\n\n---\n\n# 2. 複数プロファイルの設定\n\n複数のAWSアカウントやプロジェクトにアクセスするためには、異なるプロファイルを設定する必要があります。これを実現するためには、`--profile`オプションを使用します。\n\n### プロファイル設定の例\n\n```bash\n$ aws configure --profile profile_name1\nAWS Access Key ID [None]: xxxxxxxxxx\nAWS Secret Access Key [None]: xxxxxxxxxx\nDefault region name [None]: ap-northeast-1\nDefault output format [None]: json\n```\n\n上記のコマンドでは、`profile_name1`という名前のプロファイルが設定されます。さらに別のプロファイルを追加したい場合は、同様に以下のコマンドを実行します。\n\n```bash\n$ aws configure --profile profile_name2\nAWS Access Key ID [None]: xxxxxxxxxx\nAWS Secret Access Key [None]: xxxxxxxxxx\nDefault region name [None]: ap-northeast-1\nDefault output format [None]: json\n```\n\nこれにより、複数のプロファイルが`~/.aws/credentials`ファイルに追加されます。\n\n---\n\n# 3. 複数プロファイルの使い分け方法\n\nAWS CLIで複数のプロファイルを設定した後、以下の2つの方法で使い分けることが可能です。\n\n## 方法1: コマンドに `-profile` オプションを付ける\n\n各コマンドに対して、使用したいプロファイルを`--profile`オプションで指定します。これにより、設定した特定のプロファイルを使用してコマンドを実行できます。\n\n```bash\n$ aws s3 ls --profile profile_name1\n```\n\nこの方法は、単一のコマンド実行時に特定のプロファイルを明示的に指定する場合に便利です。\n\n## 方法2: 環境変数を使用してプロファイルを切り替える\n\nもし、コマンドごとに`--profile`オプションを指定するのが手間だと感じる場合、環境変数`AWS_PROFILE`を設定することで、デフォルトプロファイルを一時的に変更できます。\n\n```bash\n$ export AWS_PROFILE=profile_name2\n$ aws s3 ls\n```\n\n環境変数を設定しておけば、同じシェルセッション内ではすべてのAWS CLIコマンドがそのプロファイルを使用するため、毎回`--profile`オプションを指定する必要がなくなります。\n\n---\n\n# まとめ\n\nAWS CLIを使って複数のプロファイルを使い分けることで、異なるプロジェクトや環境に簡単にアクセスできます。`--profile`オプションを使う方法と、環境変数を利用してプロファイルを切り替える方法は、それぞれの用途に応じて使い分けましょう。\n\nAWSを効果的に使いこなすためには、こうしたプロファイル管理のスキルが非常に重要です。日々の業務で複数のAWS環境を操作することが多い方は、ぜひ試してみてください！\n\n---\n\n","updatedAt":"2025-06-01T08:23:55.260Z","tags":[{"id":10,"documentId":"cxt2tbnsy05cazm17p3pp1a3","createdAt":"2025-05-19T09:46:58.860Z","updatedAt":"2025-05-19T09:46:58.860Z","publishedAt":"2025-05-19T09:46:58.868Z","name":"AWS"},{"id":28,"documentId":"g250gp73dhyj31yn9639otwk","createdAt":"2025-05-19T09:50:38.186Z","updatedAt":"2025-05-19T09:50:38.186Z","publishedAt":"2025-05-19T09:50:38.193Z","name":"クラウド"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_03_0767e419b3.png"}},{"id":190,"documentId":"djth9w62up34lhpj72glog69","title":"レイズクロスの技術スタックをご紹介","content":"今日のビジネス環境では、技術の選択が企業の成功に直接的な影響を及ぼします。特にBtoB業務系システムの構築においては、セキュリティ・拡張性・運用のし易さが重要視されます。\n\nこの記事では、レイズクロスがこれまでのプロジェクトで使用し、実績を上げてきた技術スタックについて紹介します。\n\n# クラウド技術の実績\n\nレイズクロスでは、クラウドコンピューティング技術として**AWS（Amazon Web Services）**を中心に用いています。AWSを用いることで、柔軟なサーバレスアーキテクチャやマイクロサービスアーキテクチャを実現しています。\n\n- **サーバレスアーキテクチャ**:\n    - **Lambda, DynamoDB, S3, SNS, SQS, Amplify**などのサービスを駆使し、サーバー管理の負担を軽減しながらスケーラビリティとコスト効率の高いシステムを実現しています。\n- **コンテナ運用によるマイクロサービスアーキテクチャ**:\n    - **ECS (Elastic Container Service), EKS (Elastic Kubernetes Service), Aurora, DocumentDB**を活用して、開発の柔軟性と運用の効率性を高めたアーキテクチャを構築しています。\n    \n\n# プログラミング言語の実績\n\nレイズクロスのプロジェクトでは、以下のプログラミング言語が広く使用されています。\n\n- **Java, Kotlin, Groovy**: エンタープライズレベルのアプリケーション開発に適しており、堅牢なシステム構築に貢献。\n- **PHP**: Web開発のスピードと柔軟性を求めるプロジェクトで活躍。\n- **Python**: AIやデータ分析、バックエンドの開発で選ばれることが多い。\n- **Javascript, Typescript**: フロントエンドの開発に不可欠で、モダンなウェブアプリケーションの構築に寄与。\n\n# フレームワークの実績\n\nプロジェクトの効率性と品質を保証するために、以下のフレームワークが採用されています。\n\n- **Spring Boot**: Javaのエコシステムで安定したバックエンドサービスを構築。\n- **Laravel**: PHPでの迅速な開発と保守性の高いコードベースの構築に貢献。\n- **Flask, FastAPI**: Pythonでの軽量ながら強力なAPI開発に適しています。\n- **Vue.js, Nuxt.js, React.js, Next.js**: インタラクティブでユーザーフレンドリーなフロントエンド開発を可能に。\n\nレイズクロスはこれらの技術を駆使して、クライアントのビジネスニーズに合わせたカスタムソリューションを提供しておりセキュリティ、拡張性、運用のしやすさを重視したシステム構築が可能です。\n\nBtoBの業務系システム構築を検討している企業様はレイズクロスの豊富な実績と確かな技術力をぜひご利用ください。\n\n---\n\n\n","updatedAt":"2025-06-01T08:22:41.181Z","tags":[{"id":10,"documentId":"cxt2tbnsy05cazm17p3pp1a3","createdAt":"2025-05-19T09:46:58.860Z","updatedAt":"2025-05-19T09:46:58.860Z","publishedAt":"2025-05-19T09:46:58.868Z","name":"AWS"},{"id":12,"documentId":"c3lesvkdvjiq7y5zfx9mx0tu","createdAt":"2025-05-19T09:47:14.973Z","updatedAt":"2025-05-19T09:47:14.973Z","publishedAt":"2025-05-19T09:47:14.980Z","name":"Backend"},{"id":16,"documentId":"zg5iwdiznwk0mb2s77f9xta3","createdAt":"2025-05-19T09:48:07.933Z","updatedAt":"2025-05-19T09:48:07.933Z","publishedAt":"2025-05-19T09:48:07.940Z","name":"Frontend"},{"id":18,"documentId":"oz2hcaa7jn3y1vpydeqf86tq","createdAt":"2025-05-19T09:48:26.375Z","updatedAt":"2025-05-19T09:48:26.375Z","publishedAt":"2025-05-19T09:48:26.381Z","name":"Info"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_02_1eed1667d3.png"}},{"id":189,"documentId":"qtwtzhni4fsse7anq8qivmgk","title":"Tech Blog始めます","content":"こんにちは、レイズクロス代表の石橋です。\n\nこの度、技術に関する知識や経験を共有し、更に学びを深めるための場としてテックブログを始める事にしました。\n\nこのブログでは、最新の技術トレンド、プログラミング、ソフトウェア開発、ツールのレビュー、プロジェクト管理等についての考察を中心にお届けする予定です。\n\nこのブログを通じて技術に関する知見を深め、読者の皆さんと共に成長していければと思います。宜しくお願いします。","updatedAt":"2025-06-01T08:22:16.186Z","tags":[{"id":18,"documentId":"oz2hcaa7jn3y1vpydeqf86tq","createdAt":"2025-05-19T09:48:26.375Z","updatedAt":"2025-05-19T09:48:26.375Z","publishedAt":"2025-05-19T09:48:26.381Z","name":"Info"}],"thumbnail":{"url":"https://stg-raisex-tech-blog.s3.ap-northeast-1.amazonaws.com/medium_20250513_01_70a902d330.png"}}]},"__N_SSG":true},"page":"/","query":{},"buildId":"QTcQf_D8J2NMGF1e92-0w","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>